[{"path":[]},{"path":[]},{"path":"https://eriqande.github.io/rubias/TODO.html","id":"overarching-package-issues","dir":"","previous_headings":"Package","what":"Overarching Package Issues","title":"Things to do to finish the package/paper/project","text":"Puzzle BH approach gave different results Alewife SNPs vanilla MCMC--add-em-approach. Ben check see misassignment factor still . , might nice remove can check removing BH stuff. BEN Unless good reason , think remove BH stuff three four high level functions. , Eric wants make sure giving results summing MCMC. (see next item) Re-run alewife SNP stuff. ERIC main functions users deal infer_mixture(), simulate_and_assess_reference() (maybe shorten assess_reference_loo()), assess_bp_bias_correction(), need one self_assign(), assess_reference_mccv() spit tidy data, extent possible. try expose functions. Clean code CRAN compliant. Run Check see problems. get lot NOTEs number WARNINGs. ERIC Use (getRversion() >= \"2.15.1\") utils::globalVariables(c(\"my_var\")) keep CRAN checks creating notes variable my_var used dplyr context. variables create NOTEs ERIC Deprecate old “pipeline functions” superseded ones eca_funcs.R. Use .Deprecated Just internalize . BEN function . want keep around iterations getting results paper, lot paper stuff needed come . BEN Update documentation reflect deprecation, update documentation main functions Discuss transferring “ownership” repo Eric’s GitHub account. Set Travis-CI automatically run CRAN checks. ERIC Write README.Rmd shows different uses package easy, step--step, beginner’s mind way. eventually turn vignette. ERIC BEN. Minimize number functions exported , hence, exposes user. roxygen block functions add line: #' @keywords internal keep function documentation help files (users aren’t going use directly, reason .) BEN.","code":""},{"path":"https://eriqande.github.io/rubias/TODO.html","id":"specific-functions-and-issues","dir":"","previous_headings":"Package","what":"Specific Functions and Issues","title":"Things to do to finish the package/paper/project","text":"going lines . looks like dynamite, potentially—rearranging factor levels things already factor. just decide take either factor string input columns always return characters output? Hmmm….Eric looked now seems must decided internally calculations particular ordering data. , careful things factors input get returned levels order. need simple function take reference data set return tidy-formatted output includes self-assignment log-likelihoods posterior probabilities tidy format. Let’s call self_assign(). nice modify infer_mixture multiple different mixture samples can specified single data frame input. really large baselines, vast majority time function spent processing data, counting alleles, etc., shame time want analyze different mixture sample. ’m sure go , Ben might! BEN looked , start new version Try make almost user-exposed functions return tidy data. example infer_mixture returns list moment. Can cleaned . ERIC really use way users control simulation parameters—just setting alpha pretty limited. nice users explicitly give proportions (maybe even actual counts). need spend time thinking elegantly. ERIC BEN: assess_bp_bias_correction spits nice tidy data point. looks like: , need + [x] remove rho_bh calculation rho_bh column output. + [x] include true_n column output, gives actual number individuals sampled population iteration. Figure happens simulation breaks Monte Carlo cross validation. BEN need Monte Carlo cross-validation function. inputs outputs like assess_reference, Eric still needs clean bit. Ben eric pulls together loo version Prune EM-stuff `assess_reference. ERIC","code":"# A tibble: 700 × 6     iter     repunit   true_rho   rho_mcmc     rho_bh     rho_pb    <int>      <fctr>      <dbl>      <dbl>      <dbl>      <dbl> 1      1         CAN 0.04573827 0.06489907 0.04550360 0.06226238 2      1         NNE 0.06962820 0.07385272 0.05886538 0.06360804 3      1          MB 0.14588315 0.21344097 0.21242781 0.22291767 4      1         NUN 0.46891013 0.14646259 0.35338886 0.24710874 5      1         BIS 0.06644381 0.09336929 0.15767998 0.08005169 6      1         LIS 0.15719031 0.35012560 0.11664560 0.27002139 7      1 MidAtlantic 0.04620614 0.05784975 0.05548877 0.05403009 8      2         CAN 0.02751659 0.02866411 0.02224521 0.02645824 9      2         NNE 0.23190134 0.27633524 0.20446014 0.26219858 10     2          MB 0.16320168 0.07701908 0.17914736 0.11657221"},{"path":"https://eriqande.github.io/rubias/TODO.html","id":"paper","dir":"","previous_headings":"","what":"Paper","title":"Things to do to finish the package/paper/project","text":"Eric needs talk Eric P. possibility using alewife SNP data example. parametric bootstrapping data sets show doesn’t break anything, usually improves .","code":""},{"path":"https://eriqande.github.io/rubias/articles/rubias-fully-bayesian.html","id":"running-the-model-with-baseline-resampling","dir":"Articles","previous_headings":"","what":"Running the Model with Baseline Resampling","title":"Using the Fully Bayesian Model in rubias","text":"Load required packages first: basic way invoke fully Bayesian model use infer_mixture function method option set “BR” (“baseline resampling”). NOTE: use reps take much time checking package CRAN. use … Note output generated “BR” still list four tidy data frames, bootstrapped_proportions data frame methods “MCMC” “PB” replaced allele_frequencies data frame. data frame contains posterior mean allele frequencies (theta) population, updated based allocations mixture individuals throughout MCMC. first three columns specify mixture collection, locus allele question, subsequent columns report frequency particular population. Also note log-likelihoods Z-scores included indiv_posteriors output data frame calculated using reference allele counts prior MCMC, utilize full model results. Let’s compare results conditional model:  two methods largely agreement small test set.","code":"library(rubias) library(tidyverse) ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union full_model <- infer_mixture(   reference = small_chinook_ref,    mixture = small_chinook_mix,    gen_start_col = 5,    method = \"BR\",   reps = 100,   burn_in = 35   ) ## Collating data; compiling reference allele frequencies, etc.   time: 0.11 seconds ## Computing reference locus specific means and variances for computing mixture z-scores   time: 0.01 seconds ## Working on mixture collection: rec3 with 29 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##   performing 100 sweeps of method \"BR\", 35 sweeps of which are burn-in.   time: 0.03 seconds ##   tidying output into a tibble. ## Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if ## `.name_repair` is omitted as of tibble 2.0.0. ## ℹ Using compatibility `.name_repair`. ## ℹ The deprecated feature was likely used in the rubias package. ##   Please report the issue at <https://github.com/eriqande/rubias/issues>. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. ##    time: 0.13 seconds ## Working on mixture collection: rec1 with 36 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##   performing 100 sweeps of method \"BR\", 35 sweeps of which are burn-in.   time: 0.03 seconds ##   tidying output into a tibble.   time: 0.10 seconds ## Working on mixture collection: rec2 with 35 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##   performing 100 sweeps of method \"BR\", 35 sweeps of which are burn-in.   time: 0.03 seconds ##   tidying output into a tibble.   time: 0.10 seconds full_model$allele_frequencies ## # A tibble: 546 × 9 ##    mixture_collection locus   allele Deer_Cr_sp Feather_H_fa Sacramento_H  Eel_R ##    <chr>              <chr>   <chr>       <dbl>        <dbl>        <dbl>  <dbl> ##  1 rec3               AldB1.… 2          0.836       0.916        0.900   0.937  ##  2 rec3               AldB1.… 4          0.164       0.0840       0.100   0.0628 ##  3 rec3               AldoB4… 1          0.0308      0.00180      0.00101 0.0478 ##  4 rec3               AldoB4… 4          0.969       0.998        0.999   0.952  ##  5 rec3               OTNAML… 1          0.225       0.209        0.455   0.247  ##  6 rec3               OTNAML… 3          0.775       0.791        0.545   0.753  ##  7 rec3               Ots_10… 2          0.105       0.101        0.127   0.650  ##  8 rec3               Ots_10… 4          0.895       0.899        0.873   0.350  ##  9 rec3               Ots_10… 2          0.542       0.545        0.425   0.901  ## 10 rec3               Ots_10… 4          0.458       0.455        0.575   0.0994 ## # ℹ 536 more rows ## # ℹ 2 more variables: Klamath_IGH_fa <dbl>, Umpqua_sp <dbl> set.seed(15) cond_model <- infer_mixture(   reference = small_chinook_ref,    mixture = small_chinook_mix,    gen_start_col = 5,    method = \"MCMC\"   ) ## Collating data; compiling reference allele frequencies, etc.   time: 0.10 seconds ## Computing reference locus specific means and variances for computing mixture z-scores   time: 0.01 seconds ## Working on mixture collection: rec3 with 29 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds ##   tidying output into a tibble.   time: 0.01 seconds ## Working on mixture collection: rec1 with 36 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds ##   tidying output into a tibble.   time: 0.01 seconds ## Working on mixture collection: rec2 with 35 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds ##   tidying output into a tibble.   time: 0.01 seconds comppi <- cond_model$mixing_proportions %>%   mutate(cond_pi = pi, full_pi = full_model$mixing_proportions$pi)  ggplot(comppi, aes(x = cond_pi, y = full_pi, colour = collection)) +   geom_point() +   geom_abline(slope = 1, intercept = 0) +   facet_wrap(~mixture_collection) +   theme(legend.position = \"bottom\")"},{"path":"https://eriqande.github.io/rubias/articles/rubias-fully-bayesian.html","id":"initializing-mixture-proportions-with-the-conditional-model","dir":"Articles","previous_headings":"Running the Model with Baseline Resampling","what":"Initializing Mixture Proportions with the Conditional Model","title":"Using the Fully Bayesian Model in rubias","text":"collections poorly resolved, fully Bayesian model may show pathological behaviors allocating individuals one closely related populations. One way reduce behavior initialize fully Bayesian model output conditional model. rubias explicitly supports options prelim_reps prelim_burn_in: changed NULL default, parameters specify conditional MCMC cycles perform, posterior mean mixing proportions used initial mixing proportion estimates fully Bayesian model. example:  case, results largely identical uniform initial proportions, potentially collections well-resolved begin .","code":"set.seed(15) prelim_full_model <- infer_mixture(   reference = small_chinook_ref,    mixture = small_chinook_mix,    gen_start_col = 5,    method = \"BR\",   reps = 100,   burn_in = 35,   prelim_reps = 100,   prelim_burn_in = 50,   ) ## Collating data; compiling reference allele frequencies, etc.   time: 0.10 seconds ## Computing reference locus specific means and variances for computing mixture z-scores   time: 0.01 seconds ## Working on mixture collection: rec3 with 29 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##     performing 100 initial sweeps, 50 of which are burn-in and will not be used in computing averages to initialize starting point for method \"BR\".   time: 0.00 seconds ##   performing 100 sweeps of method \"BR\", 35 sweeps of which are burn-in.   time: 0.03 seconds ##   tidying output into a tibble.   time: 0.10 seconds ## Working on mixture collection: rec1 with 36 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##     performing 100 initial sweeps, 50 of which are burn-in and will not be used in computing averages to initialize starting point for method \"BR\".   time: 0.00 seconds ##   performing 100 sweeps of method \"BR\", 35 sweeps of which are burn-in.   time: 0.03 seconds ##   tidying output into a tibble.   time: 0.10 seconds ## Working on mixture collection: rec2 with 35 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##     performing 100 initial sweeps, 50 of which are burn-in and will not be used in computing averages to initialize starting point for method \"BR\".   time: 0.00 seconds ##   performing 100 sweeps of method \"BR\", 35 sweeps of which are burn-in.   time: 0.03 seconds ##   tidying output into a tibble.   time: 0.10 seconds prelimpi <-  prelim_full_model$mix_prop_traces %>%   filter(sweep == 0) %>%   select(-sweep) %>%   mutate(prelim_pi = pi, full_pi = prelim_full_model$mixing_proportions$pi)  ggplot(prelimpi, aes(x = prelim_pi, y = full_pi, colour = collection)) +   geom_point() +   geom_abline(slope = 1, intercept = 0) +   facet_wrap(~mixture_collection) +   theme(legend.position = \"bottom\")"},{"path":"https://eriqande.github.io/rubias/articles/rubias-fully-bayesian.html","id":"managing-parallelization","dir":"Articles","previous_headings":"","what":"Managing Parallelization","title":"Using the Fully Bayesian Model in rubias","text":"incorporate baseline updates keeping runtimes reasonable, genotype likelihood calculations fully Bayesian model parallelized using RcppParallel. default, RcppParallel runs one thread per core machine; check number cores available, use detectCores() function package parallel. However, default behavior dangerous HPC systems, mismatch number cores requested user number threads demanded RcppParallel might cause job abort. cases, number threads manually set RcppParallel::setThreadOptions. example, set number threads used 1: run just like : slow things relatively using multiple cores. reset threading options utilize available cores, just use:","code":"RcppParallel::setThreadOptions(numThreads = 1) full_model <- infer_mixture(   reference = small_chinook_ref,    mixture = small_chinook_mix,    gen_start_col = 5,    method = \"BR\"   ) RcppParallel::setThreadOptions(numThreads = RcppParallel::defaultNumThreads())"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"input-data","dir":"Articles","previous_headings":"","what":"Input Data","title":"An Overview of rubias Usage","text":"functions conducting genetic mixture analysis simulation assessment predict accuracy set genetic markers genetic stock identification require genetic data input data frame specific format: one row per individual locus represented two adjacent columns, one allele (package configured diploids, moment). Allelic types can expressed number character missing data locus expressed NA values gene copy locus one gene copy missing locus indivividual, gene copies must missing locus. name locus taken column name first column pair locus columns. header second column ignored. sample_type: column telling whether sample reference sample mixture sample. repunit: reporting unit individual/collection belongs . required sample_type reference. sample_type mixture repunit must NA. must character vector. factor. idea “reporting unit” well-known amongst people genetic stock identfication salmon, might familiar elsewhere. Briefly, reporting unit group populations (call “collections”) typically closely related genetically, likely aggregrated results GSI exercise. collection: reference samples, name population individual . mixture samples, name particular sample (.e. stratum port treated together space time). must character, factor. indiv character vector ID fish. must unique. started developing rubias, intended allow repunit collection columns either character vectors factors. factors might desirable , example, certain sort order collections repunits desired. However point became clear Eric , given approach converting data C++ data structure integers, rapid analyis, exposing greater opportunities bugginess allowing repunit collection factors. Accordingly, must character vectors. , rubias throw error. Note: specific sort order collections repunits, can always change factors analysis rubias. Additionally, can keep extra columns original data frame (example repunit_f collection_f) repunits collections stored factors. See, example data file alewife. can just keep character vector sort order like, use changing things factors rubias analysis. (See, instance, chinook_repunit_levels.) file can number meta data columns; however, must occur data frame columns genetic data. pass data frame functions, tell column genetic data starts , assumed columns one contain genetic data. mixture analysis, data frame mixture fish reference fish must column structure, .e., must exactly number columns exactly column names, order type.","code":""},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"how-about-haploid-markers","dir":"Articles","previous_headings":"Input Data","what":"How about haploid markers?","title":"An Overview of rubias Usage","text":"request good folks ADFG, introduced hacks allow input include markers haploid (example mtDNA haplotypes). denote marker haploid still give two columns data data frame, second column haploid marker must entirely NAs. rubias processing data sees , assumes marker haploid treats appropriately. Note diploid marker typically make sense mark one gene copies missing non-missing. Accordingly, diploid marker records just one gene copies missing individual, going throw error. Likewise, haploid marker every single individual NA second gene copy, ’s also going throw error.","code":""},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"an-example-reference-data-file","dir":"Articles","previous_headings":"Input Data","what":"An example reference data file","title":"An Overview of rubias Usage","text":"Load packages first: meta data columns first two loci eight individuals chinook reference data set comes package:","code":"library(rubias)  # all the following libraries can be loaded with \"library(tidyverse)\" # but then you have to put tidyverse in the Suggests because this is # in the vignette, and that is bad practice, so, load the packages separately... library(tibble) library(dplyr) ##  ## Attaching package: 'dplyr' ## The following objects are masked from 'package:stats': ##  ##     filter, lag ## The following objects are masked from 'package:base': ##  ##     intersect, setdiff, setequal, union library(tidyr) library(stringr) library(ggplot2) head(chinook[, 1:8]) ## # A tibble: 6 × 8 ##   sample_type repunit         collection   indiv   Ots_94857.232 Ots_94857.232.1 ##   <chr>       <chr>           <chr>        <chr>           <int>           <int> ## 1 reference   CentralValleyfa Feather_H_sp Feathe…             2               2 ## 2 reference   CentralValleyfa Feather_H_sp Feathe…             2               4 ## 3 reference   CentralValleyfa Feather_H_sp Feathe…             2               4 ## 4 reference   CentralValleyfa Feather_H_sp Feathe…             2               4 ## 5 reference   CentralValleyfa Feather_H_sp Feathe…             2               2 ## 6 reference   CentralValleyfa Feather_H_sp Feathe…             2               4 ## # ℹ 2 more variables: Ots_102213.210 <int>, Ots_102213.210.1 <int>"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"an-example-mixture-data-file","dir":"Articles","previous_headings":"Input Data","what":"An example mixture data file","title":"An Overview of rubias Usage","text":"mixture data frame goes along reference data set:","code":"head(chinook_mix[, 1:8]) ## # A tibble: 6 × 8 ##   sample_type repunit collection indiv   Ots_94857.232 Ots_94857.232.1 ##   <chr>       <chr>   <chr>      <chr>           <int>           <int> ## 1 mixture     NA      rec2       T124711             4               2 ## 2 mixture     NA      rec2       T124719             4               2 ## 3 mixture     NA      rec2       T124727             4               4 ## 4 mixture     NA      rec1       T124735             4               4 ## 5 mixture     NA      rec1       T124743             2               2 ## 6 mixture     NA      rec1       T124759             4               2 ## # ℹ 2 more variables: Ots_102213.210 <int>, Ots_102213.210.1 <int>"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"preliminary-good-practice-check-for-duplicate-individuals","dir":"Articles","previous_headings":"Input Data","what":"Preliminary good practice — check for duplicate individuals","title":"An Overview of rubias Usage","text":"Sometimes, variety reasons, individual’s genotype might appear data set. rubias quick dirty function spot pairs individuals share large number genotypes. Clearly want look pairs don’t whole lot missing data, one parameter fraction loci non-missing either fish. experience Fluidigm assays, fish missing > 10% SNPs, remaining genotypes likely fairly high error rate. , look matching samples, let’s require 85% genotypes non-missing members pair. last parameter fraction non-missing loci pair genotype. set 0.94 first. see action: Check . reveals 7 pairs data set likely duplicate samples. reduce min_frac_matching, get matches, unlikely individual, unless genotyping error rates high. principled approach use allele frequencies collection take likelihood based approach, adequate finding obvious duplicates.","code":"# combine small_chinook_ref and small_chinook_mix into one big data frame, # but drop the California_Coho collection because Coho all # have pretty much the same genotype at these loci! small_chinook_all <- bind_rows(small_chinook_ref, small_chinook_mix) %>%   filter(collection != \"California_Coho\")  # then toss them into a function.  matchy_pairs <- close_matching_samples(D = small_chinook_all,                                         gen_start_col = 5,                                         min_frac_non_miss = 0.85,                                         min_frac_matching = 0.94                                        ) ## Summary Statistics: ##  ## 1009 Individuals in Sample ##  ## 91 Loci: AldB1.122, AldoB4.183, OTNAML12_1.SNP1, Ots_100884.287, Ots_101119.381, Ots_101704.143, Ots_102213.210, Ots_102414.395, Ots_102420.494, Ots_102457.132, Ots_102801.308, Ots_102867.609, Ots_103041.52, Ots_104063.132, Ots_104569.86, Ots_105105.613, Ots_105132.200, Ots_105401.325, Ots_105407.117, Ots_106499.70, Ots_106747.239, Ots_107074.284, Ots_107285.93, Ots_107806.821, Ots_108007.208, Ots_108390.329, Ots_108735.302, Ots_109693.392, Ots_110064.383, Ots_110201.363, Ots_110495.380, Ots_110551.64, Ots_111312.435, Ots_111666.408, Ots_111681.657, Ots_112301.43, Ots_112419.131, Ots_112820.284, Ots_112876.371, Ots_113242.216, Ots_113457.40, Ots_117043.255, Ots_117242.136, Ots_117432.409, Ots_118175.479, Ots_118205.61, Ots_118938.325, Ots_122414.56, Ots_123048.521, Ots_123921.111, Ots_124774.477, Ots_127236.62, Ots_128302.57, Ots_128693.461, Ots_128757.61, Ots_129144.472, Ots_129170.683, Ots_129458.451, Ots_130720.99, Ots_131460.584, Ots_131906.141, Ots_94857.232, Ots_96222.525, Ots_96500.180, Ots_97077.179, Ots_99550.204, Ots_ARNT.195, Ots_AsnRS.60, Ots_aspat.196, Ots_CD59.2, Ots_CD63, Ots_EP.529, Ots_GDH.81x, Ots_HSP90B.385, Ots_MHC1, Ots_mybp.85, Ots_myoD.364, Ots_Ots311.101x, Ots_PGK.54, Ots_Prl2, Ots_RFC2.558, Ots_SClkF2R2.135, Ots_SWS1op.182, Ots_TAPBP, Ots_u07.07.161, Ots_u07.49.290, Ots_u4.92, OTSBMP.2.SNP1, OTSTF1.SNP1, S71.336, unk_526 ##  ## 7 Reporting Units: CentralValleysp, CentralValleyfa, CentralValleywi, CaliforniaCoast, KlamathR, MidOregonCoast ##  ## 6 Collections: Deer_Cr_sp, Feather_H_fa, Sacramento_H, Eel_R, Klamath_IGH_fa, Umpqua_sp ##  ## 3.65% of allelic data identified as missing # see that that looks like: matchy_pairs %>%   arrange(desc(num_non_miss), desc(num_match)) ## # A tibble: 7 × 10 ##   num_non_miss num_match indiv_1 indiv_2 collection_1 collection_2 sample_type_1 ##          <int>     <int> <chr>   <chr>   <chr>        <chr>        <chr>         ## 1           91        90 Umpqua… Umpqua… Umpqua_sp    Umpqua_sp    reference     ## 2           91        90 Umpqua… Umpqua… Umpqua_sp    Umpqua_sp    reference     ## 3           91        89 Umpqua… Umpqua… Umpqua_sp    Umpqua_sp    reference     ## 4           90        90 Umpqua… Umpqua… Umpqua_sp    Umpqua_sp    reference     ## 5           90        89 Umpqua… Umpqua… Umpqua_sp    Umpqua_sp    reference     ## 6           88        87 Umpqua… Umpqua… Umpqua_sp    Umpqua_sp    reference     ## 7           78        74 Deer_C… Deer_C… Deer_Cr_sp   Deer_Cr_sp   reference     ## # ℹ 3 more variables: repunit_1 <chr>, sample_type_2 <chr>, repunit_2 <chr> # then toss them into a function.  This takes half a minute or so... matchy_pairs2 <- close_matching_samples(D = small_chinook_all,                                         gen_start_col = 5,                                         min_frac_non_miss = 0.85,                                         min_frac_matching = 0.80                                        ) ## Summary Statistics: ##  ## 1009 Individuals in Sample ##  ## 91 Loci: AldB1.122, AldoB4.183, OTNAML12_1.SNP1, Ots_100884.287, Ots_101119.381, Ots_101704.143, Ots_102213.210, Ots_102414.395, Ots_102420.494, Ots_102457.132, Ots_102801.308, Ots_102867.609, Ots_103041.52, Ots_104063.132, Ots_104569.86, Ots_105105.613, Ots_105132.200, Ots_105401.325, Ots_105407.117, Ots_106499.70, Ots_106747.239, Ots_107074.284, Ots_107285.93, Ots_107806.821, Ots_108007.208, Ots_108390.329, Ots_108735.302, Ots_109693.392, Ots_110064.383, Ots_110201.363, Ots_110495.380, Ots_110551.64, Ots_111312.435, Ots_111666.408, Ots_111681.657, Ots_112301.43, Ots_112419.131, Ots_112820.284, Ots_112876.371, Ots_113242.216, Ots_113457.40, Ots_117043.255, Ots_117242.136, Ots_117432.409, Ots_118175.479, Ots_118205.61, Ots_118938.325, Ots_122414.56, Ots_123048.521, Ots_123921.111, Ots_124774.477, Ots_127236.62, Ots_128302.57, Ots_128693.461, Ots_128757.61, Ots_129144.472, Ots_129170.683, Ots_129458.451, Ots_130720.99, Ots_131460.584, Ots_131906.141, Ots_94857.232, Ots_96222.525, Ots_96500.180, Ots_97077.179, Ots_99550.204, Ots_ARNT.195, Ots_AsnRS.60, Ots_aspat.196, Ots_CD59.2, Ots_CD63, Ots_EP.529, Ots_GDH.81x, Ots_HSP90B.385, Ots_MHC1, Ots_mybp.85, Ots_myoD.364, Ots_Ots311.101x, Ots_PGK.54, Ots_Prl2, Ots_RFC2.558, Ots_SClkF2R2.135, Ots_SWS1op.182, Ots_TAPBP, Ots_u07.07.161, Ots_u07.49.290, Ots_u4.92, OTSBMP.2.SNP1, OTSTF1.SNP1, S71.336, unk_526 ##  ## 7 Reporting Units: CentralValleysp, CentralValleyfa, CentralValleywi, CaliforniaCoast, KlamathR, MidOregonCoast ##  ## 6 Collections: Deer_Cr_sp, Feather_H_fa, Sacramento_H, Eel_R, Klamath_IGH_fa, Umpqua_sp ##  ## 3.65% of allelic data identified as missing # see that that looks like: matchy_pairs2 %>%   arrange(desc(num_non_miss), desc(num_match)) ## # A tibble: 16 × 10 ##    num_non_miss num_match indiv_1           indiv_2    collection_1 collection_2 ##           <int>     <int> <chr>             <chr>      <chr>        <chr>        ##  1           91        90 Umpqua_sp:0009    Umpqua_sp… Umpqua_sp    Umpqua_sp    ##  2           91        90 Umpqua_sp:0018    Umpqua_sp… Umpqua_sp    Umpqua_sp    ##  3           91        89 Umpqua_sp:0001    Umpqua_sp… Umpqua_sp    Umpqua_sp    ##  4           91        74 Sacramento_H:0076 Sacrament… Sacramento_H Sacramento_H ##  5           91        74 Sacramento_H:0096 Sacrament… Sacramento_H Sacramento_H ##  6           90        90 Umpqua_sp:0016    Umpqua_sp… Umpqua_sp    Umpqua_sp    ##  7           90        89 Umpqua_sp:0002    Umpqua_sp… Umpqua_sp    Umpqua_sp    ##  8           90        73 Sacramento_H:0063 Sacrament… Sacramento_H Sacramento_H ##  9           90        72 Sacramento_H:0061 Sacrament… Sacramento_H Sacramento_H ## 10           90        72 Sacramento_H:0081 Sacrament… Sacramento_H Sacramento_H ## 11           89        73 Sacramento_H:0196 Sacrament… Sacramento_H Sacramento_H ## 12           89        72 Sacramento_H:0041 Sacrament… Sacramento_H Sacramento_H ## 13           88        87 Umpqua_sp:0010    Umpqua_sp… Umpqua_sp    Umpqua_sp    ## 14           85        68 Sacramento_H:0060 Sacrament… Sacramento_H Sacramento_H ## 15           79        71 Deer_Cr_sp:0009   Deer_Cr_s… Deer_Cr_sp   Deer_Cr_sp   ## 16           78        74 Deer_Cr_sp:0021   Deer_Cr_s… Deer_Cr_sp   Deer_Cr_sp   ## # ℹ 4 more variables: sample_type_1 <chr>, repunit_1 <chr>, ## #   sample_type_2 <chr>, repunit_2 <chr>"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"how-about-known-origin-individuals-in-the-mixture","dir":"Articles","previous_headings":"Input Data","what":"How about known-origin individuals in the mixture?","title":"An Overview of rubias Usage","text":"cases, might know (less unambiguously) origin fish particular mixture sample. example, 10% individuals mixture carried coded wire tags, want include sample, make sure collections origin hard-coded CWTs said. Another scenario might occur genetic data used parentage-based tagging individuals mixture sample. case, individuals might placed high confidence parents. , included mixture come known collection. folks DFO Nanaimo, Canada amazing job PBT wondered rubias modified deal latter situation. ’ve made small additions accommodate . rubias actual inference parentage, know origin fish mixture, can included rubias analysis. way function infer_mixture() include column called known_collection reference data frame mixture data frame. reference data frame, known_collection just copy collection column. However, mixture data frame entry known_collection collection individual known (.e. using parentage inference CWT), , individual known collection, NA. Note names collections known_collection must match found collection column reference data set. modifications allowed parametric bootstrap (PB) baseline resampling (BR) methods infer_mixture().","code":""},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"performing-a-genetic-mixture-analysis","dir":"Articles","previous_headings":"","what":"Performing a Genetic Mixture Analysis","title":"An Overview of rubias Usage","text":"done infer_mixture function. example data chinook_mix data consist fish caught three different fisheries, rec1, rec2, rec3 denoted collection column. collections treated separate sample, getting mixing proportion estimate. run default options: result comes back list four tidy data frames: mixing_proportions: mixing proportions. column pi holds estimated mixing proportion collection. indiv_posteriors: holds, individual, posterior means group membership collection. Column PofZ holds values. Column log_likelihood holds log probability individuals genotype given collection. Also included n_non_miss_loci n_miss_loci number observed loci number missing loci individual. list column missing_loci contains vectors indices (names) loci missing individual. also includes column z_score can used diagnose fish don’t belong samples reference data base (see ). mix_prop_traces: MCMC traces mixing proportions collection. use want make density estimates posterior distribution mixing proportions want compute credible intervals. bootstrapped_proportions: NULL example, chosen method = \"PB\" tibble bootstrap-corrected reporting unit mixing proportions. data frames look like :","code":"mix_est <- infer_mixture(reference = chinook,                           mixture = chinook_mix,                           gen_start_col = 5) ## Collating data; compiling reference allele frequencies, etc.   time: 1.06 seconds ## Computing reference locus specific means and variances for computing mixture z-scores   time: 0.10 seconds ## Working on mixture collection: rec2 with 772 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.54 seconds ##   tidying output into a tibble.   time: 0.03 seconds ## Working on mixture collection: rec1 with 743 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.52 seconds ##   tidying output into a tibble.   time: 0.03 seconds ## Working on mixture collection: rec3 with 741 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.51 seconds ##   tidying output into a tibble.   time: 0.03 seconds lapply(mix_est, head) ## $mixing_proportions ## # A tibble: 6 × 4 ##   mixture_collection repunit         collection                  pi ##   <chr>              <chr>           <chr>                    <dbl> ## 1 rec2               CentralValleyfa Feather_H_sp         0.0733    ## 2 rec2               CentralValleysp Butte_Cr_Sp          0.0000312 ## 3 rec2               CentralValleysp Mill_Cr_sp           0.0000338 ## 4 rec2               CentralValleysp Deer_Cr_sp           0.0000646 ## 5 rec2               CentralValleysp UpperSacramento_R_sp 0.000702  ## 6 rec2               CentralValleyfa Feather_H_fa         0.157     ##  ## $indiv_posteriors ## # A tibble: 6 × 10 ##   mixture_collection indiv   repunit  collection     PofZ log_likelihood z_score ##   <chr>              <chr>   <chr>    <chr>         <dbl>          <dbl>   <dbl> ## 1 rec2               T124711 Central… Feather_H… 1.67e-28          -137.   -13.1 ## 2 rec2               T124711 Central… Feather_H… 1.03e-27          -136.   -12.6 ## 3 rec2               T124711 Central… Butte_Cr_… 1.55e-24          -130.   -10.5 ## 4 rec2               T124711 Central… Mill_Cr_fa 6.90e-30          -135.   -11.8 ## 5 rec2               T124711 Central… Deer_Cr_fa 2.09e-28          -134.   -11.6 ## 6 rec2               T124711 Central… Mokelumne… 1.86e-27          -134.   -12.3 ## # ℹ 3 more variables: n_non_miss_loci <int>, n_miss_loci <int>, ## #   missing_loci <list> ##  ## $mix_prop_traces ## # A tibble: 6 × 5 ##   mixture_collection sweep repunit         collection               pi ##   <chr>              <int> <chr>           <chr>                 <dbl> ## 1 rec2                   0 CentralValleyfa Feather_H_sp         0.0145 ## 2 rec2                   0 CentralValleysp Butte_Cr_Sp          0.0145 ## 3 rec2                   0 CentralValleysp Mill_Cr_sp           0.0145 ## 4 rec2                   0 CentralValleysp Deer_Cr_sp           0.0145 ## 5 rec2                   0 CentralValleysp UpperSacramento_R_sp 0.0145 ## 6 rec2                   0 CentralValleyfa Feather_H_fa         0.0145 ##  ## $bootstrapped_proportions ## # A tibble: 0 × 0"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"setting-the-prior-for-the-mixing-proportions","dir":"Articles","previous_headings":"Performing a Genetic Mixture Analysis","what":"Setting the prior for the mixing proportions","title":"An Overview of rubias Usage","text":"cases might reason explicitly set parameters Dirichlet prior mixing proportions collections. contrived example, imagine wanted Dirichlet prior parameters equal 1/(# collections), except parameters Central Valley Fall Run populations, like assign Dirichlet parameters 2. can accomplished pi_prior argument infer_mixture() function, let pass tibble one column named “collection” gives collection, column, named “pi_param” gives desired parameter. construct kind input: can run infer_mixture(): now, fun, can compare results mixing proportions different collections without prior mixture collection rec1:  Yep, slightly different . Let’s look sums everything: see part change prior changed distribution fish different collections within Central Valley Fall reporting unit. suprising—hard tell apart fish different collections. However, greatly change estimated proportion whole reporting unit. also turns make sense consider effect extra weight prior .","code":"prior_tibble <- chinook %>%   count(repunit, collection) %>%   filter(repunit == \"CentralValleyfa\") %>%   select(collection) %>%   mutate(pi_param = 2)  # see what it looks like: prior_tibble ## # A tibble: 8 × 2 ##   collection      pi_param ##   <chr>              <dbl> ## 1 Battle_Cr              2 ## 2 Butte_Cr_fa            2 ## 3 Deer_Cr_fa             2 ## 4 Feather_H_fa           2 ## 5 Feather_H_sp           2 ## 6 Mill_Cr_fa             2 ## 7 Mokelumne_R_fa         2 ## 8 Sacramento_R_lf        2 set.seed(12) mix_est_with_prior <- infer_mixture(reference = chinook,                           mixture = chinook_mix,                           gen_start_col = 5,                          pi_prior = prior_tibble) ## Collating data; compiling reference allele frequencies, etc.   time: 0.79 seconds ## Computing reference locus specific means and variances for computing mixture z-scores   time: 0.10 seconds ## Working on mixture collection: rec2 with 772 individuals ## Joining with `by = join_by(collection)`  calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.54 seconds ##   tidying output into a tibble.   time: 0.03 seconds ## Working on mixture collection: rec1 with 743 individuals ## Joining with `by = join_by(collection)`  calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.54 seconds ##   tidying output into a tibble.   time: 0.03 seconds ## Working on mixture collection: rec3 with 741 individuals ## Joining with `by = join_by(collection)`  calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.52 seconds ##   tidying output into a tibble.   time: 0.03 seconds comp_mix_ests <- list(   `pi (default prior)` = mix_est$mixing_proportions,   `pi (cv fall gets 2s prior)` = mix_est_with_prior$mixing_proportions ) %>%   bind_rows(.id = \"prior_type\") %>%   filter(mixture_collection == \"rec1\") %>%   select(prior_type, repunit, collection, pi) %>%   spread(prior_type, pi) %>%   mutate(coll_group = ifelse(repunit == \"CentralValleyfa\", \"CV_fall\", \"Not_CV_fall\"))  ggplot(comp_mix_ests,         aes(x = `pi (default prior)`,             y = `pi (cv fall gets 2s prior)`,            colour = coll_group            )) +   geom_point() +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") comp_mix_ests %>%    group_by(coll_group) %>%    summarise(with_explicit_prior = sum(`pi (cv fall gets 2s prior)`),              with_default_prior = sum(`pi (default prior)`)) ## # A tibble: 2 × 3 ##   coll_group  with_explicit_prior with_default_prior ##   <chr>                     <dbl>              <dbl> ## 1 CV_fall                   0.824              0.820 ## 2 Not_CV_fall               0.176              0.180"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"aggregating-collections-into-reporting-units","dir":"Articles","previous_headings":"Performing a Genetic Mixture Analysis","what":"Aggregating collections into reporting units","title":"An Overview of rubias Usage","text":"simple operation tidyverse:","code":"# for mixing proportions rep_mix_ests <- mix_est$mixing_proportions %>%   group_by(mixture_collection, repunit) %>%   summarise(repprop = sum(pi))  # adding mixing proportions over collections in the repunit ## `summarise()` has grouped output by 'mixture_collection'. You can override ## using the `.groups` argument. # for individuals posteriors rep_indiv_ests <- mix_est$indiv_posteriors %>%   group_by(mixture_collection, indiv, repunit) %>%   summarise(rep_pofz = sum(PofZ)) ## `summarise()` has grouped output by 'mixture_collection', 'indiv'. You can ## override using the `.groups` argument."},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"creating-posterior-density-curves-from-the-traces","dir":"Articles","previous_headings":"Performing a Genetic Mixture Analysis","what":"Creating posterior density curves from the traces","title":"An Overview of rubias Usage","text":"full MCMC output mixing proportions available default field $mix_prop_traces. can used obtain estimate posterior density mixing proportions. plot kernel density estimates 6 abundant repunits rec1 fishery:","code":"# find the top 6 most abundant: top6 <- rep_mix_ests %>%   filter(mixture_collection == \"rec1\") %>%    arrange(desc(repprop)) %>%   slice(1:6)  # check how many MCMC sweeps were done: nsweeps <- max(mix_est$mix_prop_traces$sweep)  # keep only rec1, then discard the first 200 sweeps as burn-in, # and then aggregate over reporting units # and then keep only the top6 from above trace_subset <- mix_est$mix_prop_traces %>%   filter(mixture_collection == \"rec1\", sweep > 200) %>%   group_by(sweep, repunit) %>%   summarise(repprop = sum(pi)) %>%    filter(repunit %in% top6$repunit) ## `summarise()` has grouped output by 'sweep'. You can override using the ## `.groups` argument. # now we can plot those: ggplot(trace_subset, aes(x = repprop, colour = repunit)) +   geom_density()"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"computing-credible-intervals-from-the-traces","dir":"Articles","previous_headings":"Performing a Genetic Mixture Analysis","what":"Computing Credible Intervals from the Traces","title":"An Overview of rubias Usage","text":"Following example, use trace_subset compute equal-tail 95% credible intervals 6 abundant reporting units rec1 fishery:","code":"top6_cis <- trace_subset %>%   group_by(repunit) %>%   summarise(loCI = quantile(repprop, probs = 0.025),             hiCI = quantile(repprop, probs = 0.975))  top6_cis ## # A tibble: 6 × 3 ##   repunit                     loCI   hiCI ##   <chr>                      <dbl>  <dbl> ## 1 CaliforniaCoast         1.91e- 2 0.0427 ## 2 CentralValleyfa         7.92e- 1 0.846  ## 3 KlamathR                4.97e- 2 0.0868 ## 4 NCaliforniaSOregonCoast 2.94e- 3 0.0185 ## 5 RogueR                  4.45e- 2 0.0808 ## 6 UColumbiaRsufa          1.59e-24 0.0108"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"assessing-whether-individuals-are-not-from-any-of-the-reference-populations","dir":"Articles","previous_headings":"Performing a Genetic Mixture Analysis","what":"Assessing whether individuals are not from any of the reference populations","title":"An Overview of rubias Usage","text":"Sometimes totally unexpected things happen. One situation saw California Chinook fishery samples coming us actually coho salmon. included coho salmon reference sample, coho always assigned quite strongly Alaska populations Chinook, even though don’t really look like Chinook . case, useful look raw log-likelihood values computed individual, rather scaled posterior probabilities. aberrantly low values genotype log-likelihood can indicate something wrong. However, raw likelihood get depend number missing loci, etc. rubias deals computing z-score fish. Z-score Z statistic obtained fish’s log-likelihood (subtracting expected log-likelihood dividing expected standard deviation). rubias’s implementation z-score accounts pattern missing data, without simulation gsi_sim . makes much, much, faster—fast enough can compute default every fish every population. , look z-score computed fish population highest posterior. (worth noting never want use z-score assign fish different populations—decide whether looks like might actually come population assigned , population reference data set.) everything kosher, expect z-scores see roughly normally distributed. can compare distribution z-scores see bunch simulated normal random variables.  normal density black distribution observed z_scores blue. fit reasonably well, suggesting much weird stuff going overall. (good!) z_score statistic useful check individuals. intended quick way identify aberrant individuals. see z-score maximum--posteriori population individual mixture sample considerably less z_scores saw reference, might infer individual doesn’t actually fit populations reference well.","code":"# get the maximum-a-posteriori population for each individual map_rows <- mix_est$indiv_posteriors %>%   group_by(indiv) %>%   top_n(1, PofZ) %>%   ungroup() normo <- tibble(z_score = rnorm(1e06)) ggplot(map_rows, aes(x = z_score)) +   geom_density(colour = \"blue\") +   geom_density(data = normo, colour = \"black\")"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"individuals-of-known-origin-in-the-mixture","dir":"Articles","previous_headings":"Performing a Genetic Mixture Analysis","what":"Individuals of known origin in the mixture","title":"An Overview of rubias Usage","text":"include small, contrived example. use small_chinook data set goes fast. First, analyze data fish mixture known collection look results mixing proportions: Now, analysis, pretend know first 8 36 fish fishery rec1 Deer_Cr_sp collection. First add known_collection column reference. add known collection column mixture. start making NAs, change Deer_Cr_sp 8 rec1 fish: now can mixture analysis: , look estimated proportions, see rec1 reflect fact 8 fish singled known fish Deer_Cr_sp: output infer_mixture() case can used just like without known individuals baseline.","code":"no_kc <- infer_mixture(small_chinook_ref, small_chinook_mix, gen_start_col = 5) ## Collating data; compiling reference allele frequencies, etc.   time: 0.09 seconds ## Computing reference locus specific means and variances for computing mixture z-scores   time: 0.01 seconds ## Working on mixture collection: rec3 with 29 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds ##   tidying output into a tibble.   time: 0.01 seconds ## Working on mixture collection: rec1 with 36 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds ##   tidying output into a tibble.   time: 0.01 seconds ## Working on mixture collection: rec2 with 35 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds ##   tidying output into a tibble.   time: 0.01 seconds no_kc$mixing_proportions %>%    arrange(mixture_collection, desc(pi)) ## # A tibble: 18 × 4 ##    mixture_collection repunit         collection          pi ##    <chr>              <chr>           <chr>            <dbl> ##  1 rec1               CentralValleyfa Feather_H_fa   0.849   ##  2 rec1               CentralValleysp Deer_Cr_sp     0.0508  ##  3 rec1               CaliforniaCoast Eel_R          0.0400  ##  4 rec1               KlamathR        Klamath_IGH_fa 0.0305  ##  5 rec1               MidOregonCoast  Umpqua_sp      0.0252  ##  6 rec1               CentralValleywi Sacramento_H   0.00463 ##  7 rec2               CentralValleyfa Feather_H_fa   0.809   ##  8 rec2               KlamathR        Klamath_IGH_fa 0.103   ##  9 rec2               MidOregonCoast  Umpqua_sp      0.0733  ## 10 rec2               CentralValleysp Deer_Cr_sp     0.00550 ## 11 rec2               CaliforniaCoast Eel_R          0.00479 ## 12 rec2               CentralValleywi Sacramento_H   0.00474 ## 13 rec3               CentralValleyfa Feather_H_fa   0.839   ## 14 rec3               CaliforniaCoast Eel_R          0.0714  ## 15 rec3               MidOregonCoast  Umpqua_sp      0.0496  ## 16 rec3               KlamathR        Klamath_IGH_fa 0.0262  ## 17 rec3               CentralValleysp Deer_Cr_sp     0.00875 ## 18 rec3               CentralValleywi Sacramento_H   0.00542 # make reference file that includes the known_collection column kc_ref <- small_chinook_ref %>%   mutate(known_collection = collection) %>%   select(known_collection, everything())  # see what that looks like kc_ref[1:10, 1:8] ## # A tibble: 10 × 8 ##    known_collection sample_type repunit         collection indiv   Ots_94857.232 ##    <chr>            <chr>       <chr>           <chr>      <chr>           <int> ##  1 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 ##  2 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 ##  3 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 ##  4 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             4 ##  5 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 ##  6 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             4 ##  7 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 ##  8 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             4 ##  9 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 ## 10 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 ## # ℹ 2 more variables: Ots_94857.232.1 <int>, Ots_102213.210 <int> kc_mix <- small_chinook_mix %>%   mutate(known_collection = NA) %>%   select(known_collection, everything())  kc_mix$known_collection[kc_mix$collection == \"rec1\"][1:8] <- \"Deer_Cr_sp\"  # here is what that looks like now (dropping most of the genetic data columns) kc_mix[1:20, 1:7] ## # A tibble: 20 × 7 ##    known_collection sample_type repunit collection indiv   Ots_94857.232 ##    <chr>            <chr>       <chr>   <chr>      <chr>           <int> ##  1 NA               mixture     NA      rec3       T125347             4 ##  2 Deer_Cr_sp       mixture     NA      rec1       T127759             4 ##  3 NA               mixture     NA      rec2       T124955             4 ##  4 NA               mixture     NA      rec2       T127564             2 ##  5 NA               mixture     NA      rec3       T127392             4 ##  6 Deer_Cr_sp       mixture     NA      rec1       T127414             4 ##  7 NA               mixture     NA      rec3       T124839             4 ##  8 Deer_Cr_sp       mixture     NA      rec1       T126414             2 ##  9 NA               mixture     NA      rec3       T125252             4 ## 10 Deer_Cr_sp       mixture     NA      rec1       T127765             4 ## 11 Deer_Cr_sp       mixture     NA      rec1       T127293             2 ## 12 Deer_Cr_sp       mixture     NA      rec1       T127577             2 ## 13 NA               mixture     NA      rec2       T126766             4 ## 14 NA               mixture     NA      rec3       T126494             4 ## 15 NA               mixture     NA      rec2       T125205             4 ## 16 Deer_Cr_sp       mixture     NA      rec1       T126584             4 ## 17 NA               mixture     NA      rec2       T124821             4 ## 18 NA               mixture     NA      rec3       T124905             2 ## 19 Deer_Cr_sp       mixture     NA      rec1       T124735             4 ## 20 NA               mixture     NA      rec3       T125624             2 ## # ℹ 1 more variable: Ots_94857.232.1 <int> # note that the genetic data start in column 6 now with_kc <- infer_mixture(kc_ref, kc_mix, 6) ## Collating data; compiling reference allele frequencies, etc.   time: 0.09 seconds ## Computing reference locus specific means and variances for computing mixture z-scores   time: 0.01 seconds ## Working on mixture collection: rec3 with 29 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds ##   tidying output into a tibble.   time: 0.01 seconds ## Working on mixture collection: rec1 with 36 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds ##   tidying output into a tibble.   time: 0.01 seconds ## Working on mixture collection: rec2 with 35 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds ##   tidying output into a tibble.   time: 0.01 seconds with_kc$mixing_proportions %>%    arrange(mixture_collection, desc(pi)) ## # A tibble: 18 × 4 ##    mixture_collection repunit         collection          pi ##    <chr>              <chr>           <chr>            <dbl> ##  1 rec1               CentralValleyfa Feather_H_fa   0.546   ##  2 rec1               CentralValleysp Deer_Cr_sp     0.355   ##  3 rec1               CaliforniaCoast Eel_R          0.0411  ##  4 rec1               KlamathR        Klamath_IGH_fa 0.0318  ##  5 rec1               MidOregonCoast  Umpqua_sp      0.0220  ##  6 rec1               CentralValleywi Sacramento_H   0.00438 ##  7 rec2               CentralValleyfa Feather_H_fa   0.806   ##  8 rec2               KlamathR        Klamath_IGH_fa 0.104   ##  9 rec2               MidOregonCoast  Umpqua_sp      0.0732  ## 10 rec2               CentralValleysp Deer_Cr_sp     0.00688 ## 11 rec2               CaliforniaCoast Eel_R          0.00551 ## 12 rec2               CentralValleywi Sacramento_H   0.00456 ## 13 rec3               CentralValleyfa Feather_H_fa   0.835   ## 14 rec3               CaliforniaCoast Eel_R          0.0732  ## 15 rec3               MidOregonCoast  Umpqua_sp      0.0494  ## 16 rec3               KlamathR        Klamath_IGH_fa 0.0281  ## 17 rec3               CentralValleysp Deer_Cr_sp     0.00883 ## 18 rec3               CentralValleywi Sacramento_H   0.00565"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"fully-bayesian-model-with-updating-of-allele-freqencies","dir":"Articles","previous_headings":"Performing a Genetic Mixture Analysis","what":"Fully Bayesian model (with updating of allele freqencies)","title":"An Overview of rubias Usage","text":"default model rubias conditional model inference done baseline allele counts fixed. fully Bayesian version, fish within mixture allocated (particular step MCMC) one reference samples alleles added reference sample, thus (one hopes) refining estimate allele frequencies sample. computationally intensive, , done using parallel computation, default running one thread every core machine. basic way invoke fully Bayesian model use infer_mixture function method option set “BR”. example: details different options working fully Bayesian model available vignette fully Bayesian model.","code":"full_model_results <- infer_mixture(   reference = chinook,    mixture = chinook_mix,    gen_start_col = 5,    method = \"BR\"   )"},{"path":[]},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"self-assigning-fish-from-the-reference","dir":"Articles","previous_headings":"Assessment of Genetic References","what":"Self-assigning fish from the reference","title":"An Overview of rubias Usage","text":"standard analysis molecular ecology assign individuals reference back collections reference using leave-one-procedure. taken care self_assign() function. Now, can look self assignment results: log_likelihood log probability fish’s genotype given inferred_collection computed using leave-one-. scaled_likelihood posterior prob assigning fish inferred_collection given equal prior every collection reference. columns output infer_mixture(). Note z_score computed can used assess distribution z_score statistic fish known, reference populations. can used compare values obtained mixed fisheries. output can summarized repunit done :","code":"sa_chinook <- self_assign(reference = chinook, gen_start_col = 5) ## Summary Statistics: ##  ## 7301 Individuals in Sample ##  ## 91 Loci: AldB1.122, AldoB4.183, OTNAML12_1.SNP1, Ots_100884.287, Ots_101119.381, Ots_101704.143, Ots_102213.210, Ots_102414.395, Ots_102420.494, Ots_102457.132, Ots_102801.308, Ots_102867.609, Ots_103041.52, Ots_104063.132, Ots_104569.86, Ots_105105.613, Ots_105132.200, Ots_105401.325, Ots_105407.117, Ots_106499.70, Ots_106747.239, Ots_107074.284, Ots_107285.93, Ots_107806.821, Ots_108007.208, Ots_108390.329, Ots_108735.302, Ots_109693.392, Ots_110064.383, Ots_110201.363, Ots_110495.380, Ots_110551.64, Ots_111312.435, Ots_111666.408, Ots_111681.657, Ots_112301.43, Ots_112419.131, Ots_112820.284, Ots_112876.371, Ots_113242.216, Ots_113457.40, Ots_117043.255, Ots_117242.136, Ots_117432.409, Ots_118175.479, Ots_118205.61, Ots_118938.325, Ots_122414.56, Ots_123048.521, Ots_123921.111, Ots_124774.477, Ots_127236.62, Ots_128302.57, Ots_128693.461, Ots_128757.61, Ots_129144.472, Ots_129170.683, Ots_129458.451, Ots_130720.99, Ots_131460.584, Ots_131906.141, Ots_94857.232, Ots_96222.525, Ots_96500.180, Ots_97077.179, Ots_99550.204, Ots_ARNT.195, Ots_AsnRS.60, Ots_aspat.196, Ots_CD59.2, Ots_CD63, Ots_EP.529, Ots_GDH.81x, Ots_HSP90B.385, Ots_MHC1, Ots_mybp.85, Ots_myoD.364, Ots_Ots311.101x, Ots_PGK.54, Ots_Prl2, Ots_RFC2.558, Ots_SClkF2R2.135, Ots_SWS1op.182, Ots_TAPBP, Ots_u07.07.161, Ots_u07.49.290, Ots_u4.92, OTSBMP.2.SNP1, OTSTF1.SNP1, S71.336, unk_526 ##  ## 39 Reporting Units: CentralValleyfa, CentralValleysp, CentralValleywi, CaliforniaCoast, KlamathR, NCaliforniaSOregonCoast, RogueR, MidOregonCoast, NOregonCoast, WillametteR, DeschutesRfa, LColumbiaRfa, LColumbiaRsp, MidColumbiaRtule, UColumbiaRsufa, MidandUpperColumbiaRsp, SnakeRfa, SnakeRspsu, NPugetSound, WashingtonCoast, SPugetSound, LFraserR, LThompsonR, EVancouverIs, WVancouverIs, MSkeenaR, MidSkeenaR, LSkeenaR, SSEAlaska, NGulfCoastAlsekR, NGulfCoastKarlukR, TakuR, NSEAlaskaChilkatR, NGulfCoastSitukR, CopperR, SusitnaR, LKuskokwimBristolBay, MidYukon, CohoSp ##  ## 69 Collections: Feather_H_sp, Butte_Cr_Sp, Mill_Cr_sp, Deer_Cr_sp, UpperSacramento_R_sp, Feather_H_fa, Butte_Cr_fa, Mill_Cr_fa, Deer_Cr_fa, Mokelumne_R_fa, Battle_Cr, Sacramento_R_lf, Sacramento_H, Eel_R, Russian_R, Klamath_IGH_fa, Trinity_H_sp, Smith_R, Chetco_R, Cole_Rivers_H, Applegate_Cr, Coquille_R, Umpqua_sp, Nestucca_H, Siuslaw_R, Alsea_R, Nehalem_R, Siletz_R, N_Santiam_H, McKenzie_H, L_Deschutes_R, Cowlitz_H_fa, Cowlitz_H_sp, Kalama_H_sp, Spring_Cr_H, Hanford_Reach, PriestRapids_H, Wells_H, Wenatchee_R, CleElum, Lyons_Ferry_H, Rapid_R_H, McCall_H, Kendall_H_sp, Forks_Cr_H, Soos_H, Marblemount_H_sp, QuinaltLake_f, Harris_R, Birkenhead_H, Spius_H, Big_Qual_H, Robertson_H, Morice_R, Kitwanga_R, L_Kalum_R, LPW_Unuk_R, Goat_Cr, Karluk_R, LittleTatsamenie, Tahini_R, Situk_R, Sinona_Ck, Montana_Ck, George_R, Kanektok_R, Togiak_R, Kantishna_R, California_Coho ##  ## 4.18% of allelic data identified as missing head(sa_chinook, n = 100) ## # A tibble: 100 × 11 ##    indiv             collection   repunit   inferred_collection inferred_repunit ##    <chr>             <chr>        <chr>     <chr>               <chr>            ##  1 Feather_H_sp:0001 Feather_H_sp CentralV… Feather_H_sp        CentralValleyfa  ##  2 Feather_H_sp:0001 Feather_H_sp CentralV… Feather_H_fa        CentralValleyfa  ##  3 Feather_H_sp:0001 Feather_H_sp CentralV… Butte_Cr_fa         CentralValleyfa  ##  4 Feather_H_sp:0001 Feather_H_sp CentralV… Mill_Cr_sp          CentralValleysp  ##  5 Feather_H_sp:0001 Feather_H_sp CentralV… Mill_Cr_fa          CentralValleyfa  ##  6 Feather_H_sp:0001 Feather_H_sp CentralV… UpperSacramento_R_… CentralValleysp  ##  7 Feather_H_sp:0001 Feather_H_sp CentralV… Deer_Cr_sp          CentralValleysp  ##  8 Feather_H_sp:0001 Feather_H_sp CentralV… Butte_Cr_Sp         CentralValleysp  ##  9 Feather_H_sp:0001 Feather_H_sp CentralV… Battle_Cr           CentralValleyfa  ## 10 Feather_H_sp:0001 Feather_H_sp CentralV… Mokelumne_R_fa      CentralValleyfa  ## # ℹ 90 more rows ## # ℹ 6 more variables: scaled_likelihood <dbl>, log_likelihood <dbl>, ## #   z_score <dbl>, n_non_miss_loci <int>, n_miss_loci <int>, ## #   missing_loci <list> sa_to_repu <- sa_chinook %>%   group_by(indiv, collection, repunit, inferred_repunit) %>%   summarise(repu_scaled_like = sum(scaled_likelihood)) ## `summarise()` has grouped output by 'indiv', 'collection', 'repunit'. You can ## override using the `.groups` argument. head(sa_to_repu, n = 200) ## # A tibble: 200 × 5 ## # Groups:   indiv, collection, repunit [6] ##    indiv        collection repunit      inferred_repunit repu_scaled_like ##    <chr>        <chr>      <chr>        <chr>                       <dbl> ##  1 Alsea_R:0001 Alsea_R    NOregonCoast CaliforniaCoast          3.72e- 8 ##  2 Alsea_R:0001 Alsea_R    NOregonCoast CentralValleyfa          1.54e-14 ##  3 Alsea_R:0001 Alsea_R    NOregonCoast CentralValleysp          8.12e-15 ##  4 Alsea_R:0001 Alsea_R    NOregonCoast CentralValleywi          1.22e-23 ##  5 Alsea_R:0001 Alsea_R    NOregonCoast CohoSp                   2.09e-52 ##  6 Alsea_R:0001 Alsea_R    NOregonCoast CopperR                  3.08e-20 ##  7 Alsea_R:0001 Alsea_R    NOregonCoast DeschutesRfa             3.81e-10 ##  8 Alsea_R:0001 Alsea_R    NOregonCoast EVancouverIs             1.02e- 8 ##  9 Alsea_R:0001 Alsea_R    NOregonCoast KlamathR                 1.11e-11 ## 10 Alsea_R:0001 Alsea_R    NOregonCoast LColumbiaRfa             8.52e- 8 ## # ℹ 190 more rows"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"simulated-mixtures-using-a-leave-one-out-type-of-approach","dir":"Articles","previous_headings":"Assessment of Genetic References","what":"Simulated mixtures using a leave-one-out type of approach","title":"An Overview of rubias Usage","text":"want know much accuracy can expect given set genetic markers grouping populations (collections) reporting units (repunits), two different functions might use: assess_reference_loo(): function carries simulation mixtures using leave-one-approach Anderson et al. (2008). assess_reference_mc(): functions breaks reference data set different subsets, one used reference data set mixture. difficult simulate large mixture samples using method, constrained number fish reference data set. Additionally, constraints mixing proportions can simulated variation number fish collection reference. functions take two required arguments: 1) data frame reference genetic data, 2) number column genetic data start. use chinook data simulate 5 mixture samples (note, typically want just 5, use low numbers illustration) size 200 fish using default values (Dirichlet parameters 1.5 reporting unit, Dirichlet parameters 1.5 collection within reporting unit…) output looks like: columns : repunit_scenario integer gives repunit simulation parameters (see simulating multiple scenarios). collections_scenario integer gives collection simulation paramters (see simulating multiple scenarios). iter simulation number (1 reps) repunit reporting unit collection collection true_pi true simulated mixing proportion n actual number fish collection simulated mixture. post_mean_pi posterior mean mixing proportion. mle_pi maximum likelihood pi obtained using EM-algorithm.","code":"chin_sims <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 5,                       mixsize = 200) chin_sims ## # A tibble: 345 × 9 ##    repunit_scenario collection_scenario  iter repunit   collection true_pi     n ##    <chr>            <chr>               <int> <chr>     <chr>        <dbl> <dbl> ##  1 1                1                       1 CentralV… Feather_H… 8.42e-4     0 ##  2 1                1                       1 CentralV… Butte_Cr_… 6.55e-4     0 ##  3 1                1                       1 CentralV… Mill_Cr_sp 1.37e-3     0 ##  4 1                1                       1 CentralV… Deer_Cr_sp 4.41e-3     1 ##  5 1                1                       1 CentralV… UpperSacr… 6.25e-4     0 ##  6 1                1                       1 CentralV… Feather_H… 2.89e-3     2 ##  7 1                1                       1 CentralV… Butte_Cr_… 8.50e-4     0 ##  8 1                1                       1 CentralV… Mill_Cr_fa 2.86e-3     1 ##  9 1                1                       1 CentralV… Deer_Cr_fa 6.53e-3     0 ## 10 1                1                       1 CentralV… Mokelumne… 8.99e-4     0 ## # ℹ 335 more rows ## # ℹ 2 more variables: post_mean_pi <dbl>, mle_pi <dbl>"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"specifying-mixture-proportions-in-assess_reference_loo","dir":"Articles","previous_headings":"Assessment of Genetic References","what":"Specifying mixture proportions in assess_reference_loo()","title":"An Overview of rubias Usage","text":"default, iteration, proportions fish reporting unit simulated Dirichlet distribution parameter (1.5,…,1.5). , within reporting unit mixing proportions different collections drawn Dirichlet distribution parameter (1.5,…,1.5). value 1.5 Dirichlet parameter reporting units can changed using alpha_repunit. Dirichlet parameter collections can set using alpha_collection parameter. Sometimes, however, control composition simulated mixtures desired. achieved passing two-column data.frame either alpha_repunit alpha_collection (). passing data.frame alpha_repunit, first column must named repunit must contain character vector specifying reporting units. data.frame alpha_collection first column must named collection must hold character vector specifying different collections. error repunit collection specified exist reference. However, need specify value every reporting unit collection. (absent, value assumed zero.) second column data frame must one count, ppn dirichlet. specify, respectively, exact count individuals simulated repunit (collection); proportion individuals repunit (collection). ppn values normalized sum one . , can regarded weights. parameters Dirichlet distribution proportion individuals simulated. Let’s say want simulate data roughly proportions like saw Chinook rec1 fishery. estimates variable top6: , put repprop values ppn column, simulate mixtures exactly proportions. wanted simulate exact numbers fish sample 345 fish, get values like : put cnts column. However, case, want simulate mixtures look similar one estimated, variation. want supply Dirichlet random variable parameters column named dirichlet. make values proportional mixing proportions, , average . values large, little variation simulated mixtures. values small lots variation. ’ll scale sum 10—give variation, much. Accordingly tibble pass alpha_repunit parameter, describes variation reporting unit proportions like simulate look like : Let’s simulations repunit parameters. default, don’t specify anything extra collections, get dirichlet parameters 1.5. Now, can summarise output reporting unit… …plot values interested :  plot comparing “n” value, actual number fish reporting unit sample.","code":"top6 ## # A tibble: 6 × 3 ## # Groups:   mixture_collection [1] ##   mixture_collection repunit                 repprop ##   <chr>              <chr>                     <dbl> ## 1 rec1               CentralValleyfa         0.820   ## 2 rec1               KlamathR                0.0669  ## 3 rec1               RogueR                  0.0610  ## 4 rec1               CaliforniaCoast         0.0298  ## 5 rec1               NCaliforniaSOregonCoast 0.00921 ## 6 rec1               UColumbiaRsufa          0.00329 round(top6$repprop * 350) ## [1] 287  23  21  10   3   1 arep <- top6 %>%   ungroup() %>%   mutate(dirichlet = 10 * repprop) %>%   select(repunit, dirichlet)  arep ## # A tibble: 6 × 2 ##   repunit                 dirichlet ##   <chr>                       <dbl> ## 1 CentralValleyfa            8.20   ## 2 KlamathR                   0.669  ## 3 RogueR                     0.610  ## 4 CaliforniaCoast            0.298  ## 5 NCaliforniaSOregonCoast    0.0921 ## 6 UColumbiaRsufa             0.0329 chin_sims_repu_top6 <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 5,                       mixsize = 200,                      alpha_repunit = arep) # now, call those repunits that we did not specify in arep \"OTHER\" # and then sum up over reporting units tmp <- chin_sims_repu_top6 %>%   mutate(repunit = ifelse(repunit %in% arep$repunit, repunit, \"OTHER\")) %>%   group_by(iter, repunit) %>%   summarise(true_repprop = sum(true_pi),              reprop_posterior_mean = sum(post_mean_pi),             repu_n = sum(n)) %>%   mutate(repu_n_prop = repu_n / sum(repu_n)) ## `summarise()` has grouped output by 'iter'. You can override using the ## `.groups` argument. # then plot them ggplot(tmp, aes(x = true_repprop, y = reprop_posterior_mean, colour = repunit)) +   geom_point() +   geom_abline(intercept = 0, slope = 1) +   facet_wrap(~ repunit) ggplot(tmp, aes(x = repu_n_prop, y = reprop_posterior_mean, colour = repunit)) +   geom_point() +   geom_abline(intercept = 0, slope = 1) +   facet_wrap(~ repunit)"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"retrieving-the-individual-simulated-fish-posteriors","dir":"Articles","previous_headings":"Assessment of Genetic References","what":"Retrieving the individual simulated fish posteriors","title":"An Overview of rubias Usage","text":"Quite often might curious much can expect able trust posterior individual fish mixture like . can retrieve posteriors computed fish simulated assess_reference_loo() using return_indiv_posteriors option. , function returns list components mixture_proportions (holds tibble like chin_sims_repu_top6 previous section) indiv_posteriors, holds posteriors (PofZs) simulated individuals. tibble: - indiv integer specifier simulated individual - simulated_repunit reporting unit individual simulated - simulated_collection collection simulated genotype came - PofZ mean MCMC posterior probability individual originated collection. Now done , can see distribution posteriors correct reporting unit fish different simulated collections. ’ll boxplot, coloring repunit:  Great. helpful.","code":"set.seed(100) chin_sims_with_indivs <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 5,                       mixsize = 200,                      alpha_repunit = arep,                      return_indiv_posteriors = TRUE) ## Warning: `as.tibble()` was deprecated in tibble 2.0.0. ## ℹ Please use `as_tibble()` instead. ## ℹ The signature and semantics have changed, see `?as_tibble`. ## ℹ The deprecated feature was likely used in the rubias package. ##   Please report the issue at <https://github.com/eriqande/rubias/issues>. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. # print out the indiv posteriors chin_sims_with_indivs$indiv_posteriors ## # A tibble: 69,000 × 9 ##    repunit_scenario collection_scenario  iter indiv simulated_repunit ##    <chr>            <chr>               <int> <int> <chr>             ##  1 1                1                       1     1 CentralValleyfa   ##  2 1                1                       1     1 CentralValleyfa   ##  3 1                1                       1     1 CentralValleyfa   ##  4 1                1                       1     1 CentralValleyfa   ##  5 1                1                       1     1 CentralValleyfa   ##  6 1                1                       1     1 CentralValleyfa   ##  7 1                1                       1     1 CentralValleyfa   ##  8 1                1                       1     1 CentralValleyfa   ##  9 1                1                       1     1 CentralValleyfa   ## 10 1                1                       1     1 CentralValleyfa   ## # ℹ 68,990 more rows ## # ℹ 4 more variables: simulated_collection <chr>, repunit <chr>, ## #   collection <chr>, PofZ <dbl> # summarise things repu_pofzs <- chin_sims_with_indivs$indiv_posteriors %>%   filter(repunit == simulated_repunit) %>%   group_by(iter, indiv, simulated_collection, repunit) %>%  # first aggregate over reporting units   summarise(repu_PofZ = sum(PofZ)) %>%   ungroup() %>%   arrange(repunit, simulated_collection) %>%   mutate(simulated_collection = factor(simulated_collection, levels = unique(simulated_collection))) ## `summarise()` has grouped output by 'iter', 'indiv', 'simulated_collection'. ## You can override using the `.groups` argument. # also get the number of simulated individuals from each collection num_simmed <- chin_sims_with_indivs$indiv_posteriors %>%   group_by(iter, indiv) %>%   slice(1) %>%   ungroup() %>%   count(simulated_collection)    # note, the last few steps make simulated collection a factor so that collections within # the same repunit are grouped together in the plot.  # now, plot it ggplot(repu_pofzs, aes(x = simulated_collection, y = repu_PofZ)) +   geom_boxplot(aes(colour = repunit)) +   geom_text(data = num_simmed, mapping = aes(y = 1.025, label = n), angle = 90, hjust = 0, vjust = 0.5, size = 3) +    theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 9, vjust = 0.5)) +   ylim(c(NA, 1.05))"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"changing-the-resampling-unit","dir":"Articles","previous_headings":"Assessment of Genetic References","what":"Changing the resampling unit","title":"An Overview of rubias Usage","text":"default, individuals simulated assess_reference_loo() resampling full multilocus genotypes. tends realistic, includes missing simulations missing data individuals reference. However, genes individuals incorrectly placed reference stay together, individual might low value PofZ population simulated . Due latter issue, might also yield pessimistic assessment’ power GSI. alternative resample gene copies—CV-GC method Anderson et al. (2008). Let us see simulated PofZ results change. simulations. Note, 5 reps don’t take long generate vignette. reps, typically. process output plot :  , find somewhat fewer fish low posteriors, still . reminds us dataset, (rather) occasionally possible get individuals carrying genotypes make difficult correctly assign reporting unit.","code":"set.seed(101) # for reproducibility # do the simulation chin_sims_by_gc <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 5,                       mixsize = 200,                      alpha_repunit = arep,                      return_indiv_posteriors = TRUE,                      resampling_unit = \"gene_copies\") # summarise things repu_pofzs_gc <- chin_sims_by_gc$indiv_posteriors %>%   filter(repunit == simulated_repunit) %>%   group_by(iter, indiv, simulated_collection, repunit) %>%  # first aggregate over reporting units   summarise(repu_PofZ = sum(PofZ)) %>%   ungroup() %>%   arrange(repunit, simulated_collection) %>%   mutate(simulated_collection = factor(simulated_collection, levels = unique(simulated_collection))) ## `summarise()` has grouped output by 'iter', 'indiv', 'simulated_collection'. ## You can override using the `.groups` argument. # also get the number of simulated individuals from each collection num_simmed_gc <- chin_sims_by_gc$indiv_posteriors %>%   group_by(iter, indiv) %>%   slice(1) %>%   ungroup() %>%   count(simulated_collection)    # note, the last few steps make simulated collection a factor so that collections within # the same repunit are grouped together in the plot.  # now, plot it ggplot(repu_pofzs_gc, aes(x = simulated_collection, y = repu_PofZ)) +   geom_boxplot(aes(colour = repunit)) +   geom_text(data = num_simmed_gc, mapping = aes(y = 1.025, label = n), angle = 90, hjust = 0, vjust = 0.5, size = 3) +    theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 9, vjust = 0.5)) +   ylim(c(NA, 1.05))"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"sub-specifying-collection-proportions-or-dirichlet-parameters","dir":"Articles","previous_headings":"Assessment of Genetic References","what":"“sub-specifying” collection proportions or dirichlet parameters","title":"An Overview of rubias Usage","text":"simulating reporting unit proportions numbers, want control collections fish simulated , within reporting units, sub_ppn sub_dirichlet settings . given column names alpha_collection data frame. example, let’s say want simulate reporting unit proportions , using arep : , now, let’s say within reporting unit want specific weights different collections. specify , example, like : Collections listed given equal proportions within repunits collections listed. However, collection listed, collections within repunit , simulated proportion zero. (Technically, zero, small—like 10−810^{-8} effectively 0…made coding lot easier…) Now, can simulate see resulting proportion fish collection (5 reps): Now observe average proportions collections repunits simulated, average fraction, within reporting units collection","code":"arep ## # A tibble: 6 × 2 ##   repunit                 dirichlet ##   <chr>                       <dbl> ## 1 CentralValleyfa            8.20   ## 2 KlamathR                   0.669  ## 3 RogueR                     0.610  ## 4 CaliforniaCoast            0.298  ## 5 NCaliforniaSOregonCoast    0.0921 ## 6 UColumbiaRsufa             0.0329 arep_subs <- tribble(   ~collection, ~sub_ppn,   \"Eel_R\",   0.1,   \"Russian_R\", 0.9,   \"Butte_Cr_fa\", 0.7,   \"Feather_H_sp\", 0.3 ) chin_sims_sub_ppn <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 5,                       mixsize = 200,                      alpha_repunit = arep,                      alpha_collection = arep_subs,                      return_indiv_posteriors = FALSE)  # don't bother returning individual posteriors chin_sims_sub_ppn %>%   group_by(repunit, collection) %>%   summarise(mean_pi = mean(true_pi)) %>%   group_by(repunit) %>%   mutate(repunit_mean_pi = sum(mean_pi),          fract_within = mean_pi / repunit_mean_pi) %>%   mutate(fract_within = ifelse(fract_within < 1e-06, 0, fract_within))  %>% # anything less than 1 in a million gets called 0   filter(repunit_mean_pi > 0.0) ## `summarise()` has grouped output by 'repunit'. You can override using the ## `.groups` argument. ## # A tibble: 20 × 5 ## # Groups:   repunit [6] ##    repunit                 collection       mean_pi repunit_mean_pi fract_within ##    <chr>                   <chr>              <dbl>           <dbl>        <dbl> ##  1 CaliforniaCoast         Eel_R            3.88e-3      0.0388            0.1   ##  2 CaliforniaCoast         Russian_R        3.49e-2      0.0388            0.9   ##  3 CentralValleyfa         Battle_Cr        8.25e-8      0.825             0     ##  4 CentralValleyfa         Butte_Cr_fa      5.77e-1      0.825             0.700 ##  5 CentralValleyfa         Deer_Cr_fa       8.25e-8      0.825             0     ##  6 CentralValleyfa         Feather_H_fa     8.25e-8      0.825             0     ##  7 CentralValleyfa         Feather_H_sp     2.47e-1      0.825             0.300 ##  8 CentralValleyfa         Mill_Cr_fa       8.25e-8      0.825             0     ##  9 CentralValleyfa         Mokelumne_R_fa   8.25e-8      0.825             0     ## 10 CentralValleyfa         Sacramento_R_lf  8.25e-8      0.825             0     ## 11 KlamathR                Klamath_IGH_fa   3.13e-2      0.0626            0.5   ## 12 KlamathR                Trinity_H_sp     3.13e-2      0.0626            0.5   ## 13 NCaliforniaSOregonCoast Chetco_R         1.24e-2      0.0248            0.5   ## 14 NCaliforniaSOregonCoast Smith_R          1.24e-2      0.0248            0.5   ## 15 RogueR                  Applegate_Cr     2.45e-2      0.0490            0.5   ## 16 RogueR                  Cole_Rivers_H    2.45e-2      0.0490            0.5   ## 17 UColumbiaRsufa          Hanford_Reach    1.59e-6      0.00000635        0.25  ## 18 UColumbiaRsufa          PriestRapids_H   1.59e-6      0.00000635        0.25  ## 19 UColumbiaRsufa          Wells_H          1.59e-6      0.00000635        0.25  ## 20 UColumbiaRsufa          Wenatchee_R      1.59e-6      0.00000635        0.25"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"multiple-simulation-scenarios-and-100-simulations","dir":"Articles","previous_headings":"Assessment of Genetic References","what":"Multiple simulation scenarios and “100% Simulations”","title":"An Overview of rubias Usage","text":"fisheries world, “100% simulations” staple. simulations, mixtures simulated 100% individuals one collection (reporting unit, suppose). Eric never big fan since don’t necessarily tell might inferring actual mixtures might encounter. Nonetheless, since mainstay field, worthwile showing 100% simulations using rubias. Furthermore, people asked feature made clear Eric provide way simulate multiple different scenarios without re-processing reference data set time. came : way pass list scenarios alpha_repunit alpha_collection option assess_reference_loo(). can named lists, desired. , example, let’s 100% simulations repunits arep: let collections within just drawn dirichlet distribution parameter 10 (, pretty close equal proportions). , , make list data frames proportions. ’ll give names : , use , producing 5 replicates scenario:","code":"arep$repunit ## [1] \"CentralValleyfa\"         \"KlamathR\"                ## [3] \"RogueR\"                  \"CaliforniaCoast\"         ## [5] \"NCaliforniaSOregonCoast\" \"UColumbiaRsufa\" six_hundy_scenarios <- lapply(arep$repunit, function(x) tibble(repunit = x, ppn = 1.0)) names(six_hundy_scenarios) <- paste(\"All\", arep$repunit, sep = \"-\") repu_hundy_results <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 5,                       mixsize = 50,                      alpha_repunit = six_hundy_scenarios,                      alpha_collection = 10) repu_hundy_results ## # A tibble: 2,070 × 9 ##    repunit_scenario   collection_scenario  iter repunit collection true_pi     n ##    <chr>              <chr>               <int> <chr>   <chr>        <dbl> <dbl> ##  1 All-CentralValley… 1                       1 Centra… Feather_H…   0.100     5 ##  2 All-CentralValley… 1                       1 Centra… Butte_Cr_…   0         0 ##  3 All-CentralValley… 1                       1 Centra… Mill_Cr_sp   0         0 ##  4 All-CentralValley… 1                       1 Centra… Deer_Cr_sp   0         0 ##  5 All-CentralValley… 1                       1 Centra… UpperSacr…   0         0 ##  6 All-CentralValley… 1                       1 Centra… Feather_H…   0.141     5 ##  7 All-CentralValley… 1                       1 Centra… Butte_Cr_…   0.100     5 ##  8 All-CentralValley… 1                       1 Centra… Mill_Cr_fa   0.140     5 ##  9 All-CentralValley… 1                       1 Centra… Deer_Cr_fa   0.193    14 ## 10 All-CentralValley… 1                       1 Centra… Mokelumne…   0.102     5 ## # ℹ 2,060 more rows ## # ℹ 2 more variables: post_mean_pi <dbl>, mle_pi <dbl>"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"do-it-again-with-100-collections","dir":"Articles","previous_headings":"Assessment of Genetic References > Multiple simulation scenarios and “100% Simulations”","what":"Do it again with 100% collections","title":"An Overview of rubias Usage","text":"Just make sure clear collections (rather reporting units) well, lets 100% simulations handful collections. Let’s just randomly take 5 , 6 reps : , now make list 100% specifications tibbles: , :","code":"set.seed(10) hundy_colls <- sample(unique(chinook$collection), 5) hundy_colls ## [1] \"Deer_Cr_fa\"  \"Kitwanga_R\"  \"Morice_R\"    \"Wenatchee_R\" \"Russian_R\" hundy_coll_list <- lapply(hundy_colls, function(x) tibble(collection = x, ppn = 1.0)) %>%   setNames(paste(\"100%\", hundy_colls, sep = \"_\")) hundy_coll_results <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 5,                       mixsize = 50,                      alpha_collection = hundy_coll_list) hundy_coll_results ## # A tibble: 1,725 × 9 ##    repunit_scenario collection_scenario  iter repunit   collection true_pi     n ##    <chr>            <chr>               <int> <chr>     <chr>        <dbl> <dbl> ##  1 1                100%_Deer_Cr_fa         1 CentralV… Feather_H…       0     0 ##  2 1                100%_Deer_Cr_fa         1 CentralV… Butte_Cr_…       0     0 ##  3 1                100%_Deer_Cr_fa         1 CentralV… Mill_Cr_sp       0     0 ##  4 1                100%_Deer_Cr_fa         1 CentralV… Deer_Cr_sp       0     0 ##  5 1                100%_Deer_Cr_fa         1 CentralV… UpperSacr…       0     0 ##  6 1                100%_Deer_Cr_fa         1 CentralV… Feather_H…       0     0 ##  7 1                100%_Deer_Cr_fa         1 CentralV… Butte_Cr_…       0     0 ##  8 1                100%_Deer_Cr_fa         1 CentralV… Mill_Cr_fa       0     0 ##  9 1                100%_Deer_Cr_fa         1 CentralV… Deer_Cr_fa       1    50 ## 10 1                100%_Deer_Cr_fa         1 CentralV… Mokelumne…       0     0 ## # ℹ 1,715 more rows ## # ℹ 2 more variables: post_mean_pi <dbl>, mle_pi <dbl>"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"bootstrap-corrected-reporting-unit-proportions","dir":"Articles","previous_headings":"","what":"Bootstrap-Corrected Reporting Unit Proportions","title":"An Overview of rubias Usage","text":"obtained using method = \"PB\" infer_mixture(). invoked, return regular MCMC results , also population bootstrapped_proportions field output. takes little bit longer, computationally, good deal simulation involved, doesn’t get evaluated vignette. now can compare estimates, showing 10 prevalent repunits, rec1 fishery: can give whirl see gives us result expect: appreciable difference, reporting units already well resolved, don’t expect parametric bootstrap procedure find benefit correcting .","code":"mix_est_pb <- infer_mixture(reference = chinook,                           mixture = chinook_mix,                           gen_start_col = 5,                          method = \"PB\") mix_est_pb$mixing_proportions %>%   group_by(mixture_collection, repunit) %>%   summarise(repprop = sum(pi)) %>%   left_join(mix_est_pb$bootstrapped_proportions) %>%   ungroup() %>%   filter(mixture_collection == \"rec1\") %>%   arrange(desc(repprop)) %>%   slice(1:10)"},{"path":"https://eriqande.github.io/rubias/articles/rubias-overview.html","id":"references","dir":"Articles","previous_headings":"","what":"References","title":"An Overview of rubias Usage","text":"Anderson, Eric C, Robin S Waples, Steven T Kalinowski. 2008. “Improved Method Predicting Accuracy Genetic Stock Identification.” Can J Fish Aquat Sci 65:1475–86.","code":""},{"path":"https://eriqande.github.io/rubias/articles/rubias-underlying-data-structures.html","id":"the-param_list","dir":"Articles","previous_headings":"","what":"The param_list","title":"An Explanation of the Underlying Data Structures in rubias","text":"basic data structure call param_list. following named elements, briefly described . describe detail separate sections . L: number loci, integer N: number individuals (integer) C: number collections reference data set (integer) : number alleles locus (integer vector length L) CA: “cumulative number alleles” locus. locus gives base-0 index first allele locus (line alleles locus one another.) coll: integer vector length N gives index collection fish . coll_N: integer vector length C gives number fish collections RU_vec: hardest one figure / remember. Imagine collection index 1 C, imagine collection belongs single reporting unit. reporting unit assigned integer. Now, sort everything first reporting unit index collection index. order get order collections RU_vec. vector named integer vector. collections order described . names collection names values base-1 index collection. RU_starts: base-0 index starting position reporting unit RU_vec vector. named integer vector. example, first entries chinook data set : look first 15 elements RU_vec gives us names indices collections first 4 listed reporting units: : integer vector giving allelic type gene copy carried individual. ploidy = 2 (case implemented far) vector length (N * L * 2). entry 0 denotes missing data, observed alleles named 1, 2, … AC: flat integer vector counts alleles different types different populations. length C * sum() (.e. number collections reference times total number alleles loci.). created somewhat lengthy process: first function reference_allele_counts() makes long data frame collection, locus, allele, counts. gets turned list matrices a_freq_list(). One matrix collection. rows different alleles columns different populations. list_diploid_params() list matrices gets flattened one long integer vector. One weaknesses see now, loci arranged alphabetically, rather input order. least include names loci order appear can get back loci, necessary. order loci coming process used make sure corresponds order loci , good, super intuitive. rate, foregoing, can deduced can index vector thus (indexes base-0): want count -th allele l-th locus c-th collection get base-0 subscipting AC [C * CA[l] + c * [l] + ].  WhereCis number collections,CAis cumulative number alleles, andAis number alleles locus. Now clear storeCA`—use ! sum_AC: sum allele counts locus collection reference data set. (Basically number observed gene copies locus reference data set). gets computed list_diploid_params() list matrices returned a_freq_list(). length L * C. named vector names taking Locus.Collection, don’t think names get used . gets indexed [l * C + c] DP: vector completely parallel AC prior weights added allele collection. sum_DP: sum Dirichlet Parameters DP locus collection. parallel sum_AC. Finally, entries day one, didn’t, aren’t consistently used throughout code access names entities ordered ended ordered: - indiv_names - collection_names - repunit_names - locus_names","code":"ploidies <- check_refmix(chinook, 5) cpar <- tcf2param_list(chinook, 5, summ = FALSE, ploidies = ploidies) cpar$RU_starts[1:5] #> CentralValleyfa CentralValleysp CentralValleywi CaliforniaCoast        KlamathR  #>               0               8              12              13              15 cpar$RU_vec[1:15] #>         Feather_H_sp         Feather_H_fa          Butte_Cr_fa  #>                    1                    6                    7  #>           Mill_Cr_fa           Deer_Cr_fa       Mokelumne_R_fa  #>                    8                    9                   10  #>            Battle_Cr      Sacramento_R_lf          Butte_Cr_Sp  #>                   11                   12                    2  #>           Mill_Cr_sp           Deer_Cr_sp UpperSacramento_R_sp  #>                    3                    4                    5  #>         Sacramento_H                Eel_R            Russian_R  #>                   13                   14                   15"},{"path":"https://eriqande.github.io/rubias/articles/rubias-underlying-data-structures.html","id":"howwhere-do-all-these-get-set","dir":"Articles","previous_headings":"","what":"How/Where do all these get set?","title":"An Explanation of the Underlying Data Structures in rubias","text":"trickier question seems, things done slightly differently different top-level functions.","code":""},{"path":"https://eriqande.github.io/rubias/articles/rubias-underlying-data-structures.html","id":"assess_reference_loo-and-assess_reference_mc","dir":"Articles","previous_headings":"How/Where do all these get set?","what":"assess_reference_loo() and assess_reference_mc()","title":"An Explanation of the Underlying Data Structures in rubias","text":"functions, original data sets gets read , collection repunit get converted factors, param_list made inside single function: tcf2param_list().","code":""},{"path":"https://eriqande.github.io/rubias/articles/rubias-underlying-data-structures.html","id":"assess_pb_bias_correction","dir":"Articles","previous_headings":"How/Where do all these get set?","what":"assess_pb_bias_correction()","title":"An Explanation of the Underlying Data Structures in rubias","text":", uses tcf2param_list() steps original data frame.","code":""},{"path":"https://eriqande.github.io/rubias/articles/rubias-underlying-data-structures.html","id":"self_assign","dir":"Articles","previous_headings":"How/Where do all these get set?","what":"self_assign()","title":"An Explanation of the Underlying Data Structures in rubias","text":"Uses tcf2param_list() unless using preCompiledParams can run stuff infer_mixture compute locus-specific means variances log-likelihoods.","code":""},{"path":"https://eriqande.github.io/rubias/articles/rubias-underlying-data-structures.html","id":"infer_mixture","dir":"Articles","previous_headings":"How/Where do all these get set?","what":"infer_mixture()","title":"An Explanation of the Underlying Data Structures in rubias","text":"tough one. end multiple mixture collections, couldn’t simply use tcf2param_list() function. Rather, create summary reference sample (keeping track alleles found reference mixture), split mixture samples mixture collection use","code":""},{"path":"https://eriqande.github.io/rubias/articles/rubias-underlying-data-structures.html","id":"dealing-with-012-matrices","dir":"Articles","previous_headings":"","what":"Dealing with 012 matrices","title":"An Explanation of the Underlying Data Structures in rubias","text":"One problem current approach terribly slow start get 10K+ SNPs. much faster read store data 012 matrix. thinking deal : functions use tcf2param_list() just write another function, tcf2param_list_012(), took D just data frame sample_type, collection, repunit indiv, 012 matrix genetic data , indiv names rownames locus names colnames. just deal seeing AC_list I_list correctly. Actually, looking now, can just tcf2param_list() function. d012 parameter NULL : make cleaned$long NULL, set cleaned$clean_short D. make AC_list directly 012 matrix. super straightforward. probably want drop monomorphic loci first. make I_list 012 matrix Cool, order make two new functions: reference_allele_counts_012 allelic_list_012. might give enough insight easily infer_mixture, .","code":""},{"path":"https://eriqande.github.io/rubias/articles/uncertainty-on-total-catch.html","id":"uncertainty-in-boldsymbolpi-is-not-uncertainty-in-stock-specific-total-catch","dir":"Articles","previous_headings":"","what":"Uncertainty in 𝛑\\boldsymbol{\\pi} is not uncertainty in stock-specific total catch","title":"Summarizing Uncertainty on Stock-Specific Total Catch","text":"Although uncertainty 𝛑\\boldsymbol{\\pi} can affect amount uncertainty stock-specific total catch, two directly equated uncertainty 𝛑\\boldsymbol{\\pi} always reflects variability due drawn random sample. contrast, sample might fixed part total catch. implications easiest understand entire catch sampled GSI. , example, imagine total catch 300 fish, 300 fish subject GSI, population origin fish stock xx can identified uncertainty using genetics. 20 fish originated stock xx, total catch stock xx 20, error. However, 90% credible interval proportion fish stock xx ocean , binomial distribution, (0.043, 0.09). variation applied total catch 300, erroneously suggest 13 27 fish stock xx catch, clear exactly 20 fish xx catch! example simple contrived illustrates uncertainty around 𝛑\\boldsymbol{\\pi} directly used quantify uncertainty stock-specific total catch. Unlike simple example, stock-specific total catch typically affected sources variation uncertainty genetic assignment, subsampling total catch genetic analysis, simple uncertainty estimates actual total catch. Fortunately, sources uncertainty can now accounted rigorous way within Markov Chain Monte Carlo (MCMC) sampling framework ‘rubias,’ providing users MCMC sample stock-specific total catch stock. MCMC sample can summarized however desired, can fed analyses. next section describes statistical background ‘rubias’ provides MCMC sample stock-specific total catch.","code":""},{"path":"https://eriqande.github.io/rubias/articles/uncertainty-on-total-catch.html","id":"mcmc-for-stock-specific-total-catch","dir":"Articles","previous_headings":"","what":"MCMC for stock-specific total catch","title":"Summarizing Uncertainty on Stock-Specific Total Catch","text":"Acyclic directed graph showing standard conditional GSI model. Diamond nodes deterministic values used priors. Circular nodes variables. shaded, circular nodes denote variables observed unshaded circular nodes variables whose values updated sampled MCMC process. large rectangles plates represent replication individuals /loci. figure shows acyclic directed graph (DAG) used conditional GSI model implemented ‘rubias.’ stock proportion vector ocean, 𝛑\\boldsymbol{\\pi}, visible immediately 𝛌(π)\\boldsymbol{\\lambda}^{(\\pi)}, parameter vector prior 𝛑\\boldsymbol{\\pi}. MM fish reference baseline data set. 𝐙j*\\boldsymbol{Z}^*_j known origin fish jj baseline, 𝐘j*\\boldsymbol{Y}^*_j observed genotype. 𝐙i\\boldsymbol{Z}_i indicator vector giving unknown origin ithi^\\mathrm{th} fish mixture, 𝐘i\\boldsymbol{Y}_i genotype data fish, ii. 𝛉ℓ\\boldsymbol{\\theta}_\\ell unknown population allele freqeunces locus ℓ\\ell, 𝛄ℓ\\boldsymbol{\\gamma}_\\ell priors frequencies. MCMC sampling model proceeds using Gibbs sampling, 𝛑\\boldsymbol{\\pi}, 𝐙i\\boldsymbol{Z}_i, 𝛉ℓ\\boldsymbol{\\theta}_\\ell updated sweep algorithm drawing new value full conditional distribution. (“sweep” context cycle MCMC algorithm values updated variables model.) Acyclic directed graph showing augmented standard conditional GSI model include additional fish catch included GSI analysis. order sample posterior distribution stock-specific total catch, introduce indicator vectors 𝐙kr\\boldsymbol{Z}^r_k, k=1,…,Rk=1,\\ldots,R, giving unknown origin RR fish total catch remain fish used GSI analysis removed total catch. DAG model appears figure. Sampling new model proceeds exactly , except every sweep also simulate values RR different 𝐙kr\\boldsymbol{Z}^r_k vectors full conditional distribution, simply multinomial sample size 1 cell probabilities current values 𝛑\\boldsymbol{\\pi}: 𝐙kr∼Multinomial(1,𝛑),fork=1,…,R. \\boldsymbol{Z}^r_k \\sim \\mathrm{Multinomial}(1, \\boldsymbol{\\pi}),~~\\mathrm{}~k=1,\\ldots,R.  conclusion sweep sample posterior distribution stock-specific total catch obtained summing 𝐙kr\\boldsymbol{Z}^r_k 𝐙i\\boldsymbol{Z}_i vectors, Css=∑k=1R𝐙kr+∑=1N𝐙i. C_\\mathrm{ss} = \\sum_{k=1}^R \\boldsymbol{Z}^r_k + \\sum_{=1}^N \\boldsymbol{Z}_i.  fact, make things even easier, definition ∑k=1R𝐙kr\\sum_{k=1}^R \\boldsymbol{Z}^r_k simply multinomial random variable R trials cell probabilities 𝛑\\boldsymbol{\\pi}.","code":""},{"path":"https://eriqande.github.io/rubias/articles/uncertainty-on-total-catch.html","id":"additional-complications","dir":"Articles","previous_headings":"MCMC for stock-specific total catch","what":"Additional Complications","title":"Summarizing Uncertainty on Stock-Specific Total Catch","text":"Sometimes, size total catch, RR, might estimated uncertainty. Although catch estimates often presented without uncertainty, validated catch estimates may rare. Frequently, catches individuals estimated converting landed biomass individual pieces estimating average weight countable subsamples catch (e.g. commercial offloads fish processing facilities), substantial uncertainty catch numbers may result due heterogeneity average size date, location, fishing gear, even due error handled samples [e.g., species identification estimating average weights; see Faunce et al. (2015)]. Another method commonly used estimate numerical catch multiply total fishing effort sampled estimates catch per unit effort (CPUE, e.g. creel surveys recreational fisheries). fishers can vary strongly based behavior (spatiotemporal distribution, skill, willingness surveyed), estimates based CPUE can highly uncertain (Cabanellas-Reboredo et al. 2017). order handle uncertainty true total catch, ‘rubias’ assumption made true size total catch conditionally independent stock composition given estimated total catch. assumption, uncertainty RR (total catch) can propagated stock-specific total catch supplying sample RR posterior distribution. Different values posterior sample can used RR sweep ‘rubias’ performs. Examples provided . worth noting may times stock composition conditionally independent true catch given estimated total catch, users verify whether assumption holds. example, one may imagine case transgenerational genetic mark-recapture (Rosenbaum et al. 2024) used inform run reconstructions associated catch estimates subset stocks, GSI used parse total catch estimates stocks, resulting genotypes possibly contributing total catch estimates estimates stock composition. Often, mixed fishery includes commercial recreational landings, certainly part lethal catch take. However, mixed stock fisheries, fish sampled genotyped might test fishery necessarily lethal, fish might returned alive water sampled genetic analysis. cases, fish test fishery might considered part total catch, therefore, contribute estimated impacts particular stock assigned . cases, managers might independent estimate post-sampling mortality 0. can accommodated, shown examples “Genotypes Sampled Might Considered Part Catch/Mortality” section .","code":""},{"path":"https://eriqande.github.io/rubias/articles/uncertainty-on-total-catch.html","id":"examples","dir":"Articles","previous_headings":"","what":"Examples","title":"Summarizing Uncertainty on Stock-Specific Total Catch","text":"section walk simple, hands-examples. using example data comes rubias package. Namely, using chinook reference data set comprises 91 SNP markers typed 7,301 fish 69 collections belonging 39 different reporting units. samples mixed stock fisheries analyze data object chinook_mix. data set contains genotypes 2,256 fish grouped three different fisheries (“rec1”, “rec2”, “rec3”). (really different fisheries, purposes, , going pretend different fisheries featuring different levels management information.) part, mix fish found fisheries typical seen coast central northern California. fish Central Valley fall-run stock , purposes , assume particularly interested impacts one less numerous reporting units mixtures: “CaliforniaCoast”, comprises fish Eel Russian rivers,listed Threatened U.S. Endanged Species Act. purposes illustration, imagine “rec1” recreational fishery every single landed fish sampled, “rec2” fishery exact 25% total catch sampled genotyped, “rec3” fishery managers try sample 25% fish; however true fraction sampled varies quite bit. Let’s imagine managers “rec3” Bayesian method estimate true fraction sampled, posterior fraction beta distribution parameters 2 6, sample posterior can obtained like posterior sample distributed shown following figure. Histogram estimated sampling fraction rec3 fishery words, lot uncertainty sampling fraction , means lot uncertainty estimate total catch “rec3” fishery.","code":"library(dplyr) library(tidyr) library(ggplot2) library(rubias) rubi_method <-  \"MCMC\" # set this to BR if you want to run everything using                        # the \"Bayesian Resampling\" approach in which the allele                         # frequencies are updated according to the allocations                        # of the fish in the mixture. set.seed(3) rec3_tot_catch_sample <- rbeta(5000, 16, 48)"},{"path":"https://eriqande.github.io/rubias/articles/uncertainty-on-total-catch.html","id":"using-variability-in-boldsymbolpi","dir":"Articles","previous_headings":"Examples","what":"Using Variability in 𝛑\\boldsymbol{\\pi}","title":"Summarizing Uncertainty on Stock-Specific Total Catch","text":"start simple look things can go wrong use variability 𝛑\\boldsymbol{\\pi} try estimate variability total catch. focus “rec1” fishery , assuming every single fish catch sampled genotyped. First, analyze just fishery summarise reporting units. Histogram posterior probabilites membership CaliforniaCoast reporting unit 22 fish assigned . appears 15 fish almost certainly CaliforniaCoast, another 5 likely , two somewhat likely . words, pretty confident 20 22 fish CaliforniaCoast included total catch. Histogram sample posterior distribution fraction fish CaliforniaCoast reporting unit ocean. Posterior distribution total catch CaliforniaCoast calculated naïvely simply multiplying corresponding mixing proportion sample total number fish caught. absurd! basis individual assignments, pretty sure 20 22 CaliforniaCoast fish caught, certainly 14 30! important use new functionality ‘rubias’ estimate total stock-specific catch. illustrate next two sections.","code":"rec1_ests <- chinook_mix %>%   filter(collection == \"rec1\") %>%   infer_mixture(chinook, ., gen_start_col = 5) ## Collating data; compiling reference allele frequencies, etc.   time: 1.01 seconds ## Computing reference locus specific means and variances for computing mixture z-scores   time: 0.10 seconds ## Working on mixture collection: rec1 with 743 individuals ##   calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.52 seconds ##   tidying output into a tibble.   time: 0.03 seconds # get the mixing proportions trace by repunit rec1_pi_trace_repu <- rec1_ests$mix_prop_traces %>%   filter(sweep > 100) %>%   group_by(sweep, repunit) %>%   summarise(repunit_pi = sum(pi)) ## `summarise()` has grouped output by 'sweep'. You can override using the ## `.groups` argument. # get the maximum-a-posteriori assignment to repunit rec1_MAP_repu <- rec1_ests$indiv_posteriors %>%   group_by(indiv, repunit) %>%   summarise(repunit_PofZ = sum(PofZ)) %>%   group_by(indiv) %>%   filter(repunit_PofZ == max(repunit_PofZ)) ## `summarise()` has grouped output by 'indiv'. You can override using the ## `.groups` argument."},{"path":"https://eriqande.github.io/rubias/articles/uncertainty-on-total-catch.html","id":"all-fishery-samples-are-part-of-the-catch","dir":"Articles","previous_headings":"Examples","what":"All Fishery Samples are Part of the Catch","title":"Summarizing Uncertainty on Stock-Specific Total Catch","text":"start likely standard case: samples come fishery samples considered part impact fishery. words, every fish sample genotypes considered part total catch. (next section discusses handle departures standard case). estimate total stock specific catch must provide ‘rubias’ information size total catch. provide information tibble one column collection gives mixture collection (“rec1”, “rec2”, “rec3” current case), another column, tot_catch, must list-column, gives information total catch. second column list column want able hold sample posterior distribution total, aggregate catch. order make tibble, need know sample sizes three fisheries. : , given described earlier sample size relates total catch (, specifically recalling rec3_tot_catch_sample sample posterior distribution sampled catch fractions), form necessary tibble like : looks like : , get standard-case total catch estimates ‘rubias’ just need pass tibble infer_mixture() total_catch_tib parameter. run, tibble mix_ests_with_catch$stock_specific_total_catch_traces holds posterior sample total catch. structured much like mixing proportions trace output. first lines look like: column SSTC holds stock-specific total catch. Thus, want see posterior distribution total catch CaliforniaCoast repunit looks like three fisheries (“rec1”, “rec2”, “rec3”) just : Summarize reporting unit Filter just CaliforniaCoast Discard burn-(take default 100 sweeps, ) Plot steps look like :  just expect things look: genotyped entire catch (“rec1” fishery) little variation around stock specific total catch, especially repunit like CaliforniaCoast easily distinguished others. genotyped 25% catch, considerably variation posterior stock-specific total catch. makes sense—case extrapolating repunit mixture proportion (𝛑\\boldsymbol{\\pi}) estimates 772×3=2316772 \\times 3 = 2316 fish. course lot uncertainty stock origin fish sampled. “rec3” fishery, variability even greater uncertainty actual fraction fishery sampled. can also instructive visualize total stock-specific catch decomposed components: 1) fish actually genetic sample, 2) additional fish () part catch genetic sample. fairly easy—return object just stock_specific_total_catch_traces, also: allocation_count_traces: counts fish mixture sample allocated catch iteration. posterior_predictive_remaining_catch_traces: counts fish sampled posterior predictive distribution account total catch (caught fish sample). can pick plot total catch confirm things working way . can plot together like :  worth taking time confirm results exactly expected, given scenarios designed.","code":"chinook_mix %>%   count(collection) ## # A tibble: 3 × 2 ##   collection     n ##   <chr>      <int> ## 1 rec1         743 ## 2 rec2         772 ## 3 rec3         741 total_catches <- tibble(   collection = c(\"rec1\", \"rec2\", \"rec3\"),   tot_catch = list(     743,     772 / 0.25,     743 / rec3_tot_catch_sample   ) ) total_catches ## # A tibble: 3 × 2 ##   collection tot_catch     ##   <chr>      <list>        ## 1 rec1       <dbl [1]>     ## 2 rec2       <dbl [1]>     ## 3 rec3       <dbl [5,000]> mix_ests_with_catch <- infer_mixture(   reference = chinook,   mixture = chinook_mix,   gen_start_col = 5,    total_catch_tib = total_catches,   method = rubi_method ) ## Collating data; compiling reference allele frequencies, etc.   time: 0.80 seconds ## Computing reference locus specific means and variances for computing mixture z-scores   time: 0.10 seconds ## Working on mixture collection: rec2 with 772 individuals ## tot_catch_vec: 3088 3088 3088 3088 3088 3088 3088 3088 3088 3088 3088 3088... ##   calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.58 seconds ##   tidying output into a tibble.   time: 0.06 seconds ## Working on mixture collection: rec1 with 743 individuals ## tot_catch_vec: 743 743 743 743 743 743 743 743 743 743 743 743... ##   calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.55 seconds ##   tidying output into a tibble.   time: 0.06 seconds ## Working on mixture collection: rec3 with 741 individuals ## tot_catch_vec: 3839 3198 2791 4069 2834 2951 2911 2258 4157 2172 3606 4042... ##   calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.57 seconds ##   tidying output into a tibble.   time: 0.06 seconds mix_ests_with_catch$stock_specific_total_catch_traces ## # A tibble: 414,000 × 5 ##    mixture_collection sweep repunit         collection            SSTC ##    <chr>              <int> <chr>           <chr>                <int> ##  1 rec2                   0 CentralValleyfa Feather_H_sp           256 ##  2 rec2                   0 CentralValleysp Butte_Cr_Sp             12 ##  3 rec2                   0 CentralValleysp Mill_Cr_sp              71 ##  4 rec2                   0 CentralValleysp Deer_Cr_sp              70 ##  5 rec2                   0 CentralValleysp UpperSacramento_R_sp    83 ##  6 rec2                   0 CentralValleyfa Feather_H_fa           323 ##  7 rec2                   0 CentralValleyfa Butte_Cr_fa            399 ##  8 rec2                   0 CentralValleyfa Mill_Cr_fa             250 ##  9 rec2                   0 CentralValleyfa Deer_Cr_fa             316 ## 10 rec2                   0 CentralValleyfa Mokelumne_R_fa         322 ## # ℹ 413,990 more rows CC_sstc <- mix_ests_with_catch$stock_specific_total_catch_traces %>%   group_by(mixture_collection, sweep, repunit) %>%   summarise(repunit_sstc = sum(SSTC)) %>%   filter(sweep > 100, repunit == \"CaliforniaCoast\") ## `summarise()` has grouped output by 'mixture_collection', 'sweep'. You can ## override using the `.groups` argument. ggplot(CC_sstc, aes(x = repunit_sstc)) +   geom_histogram(binwidth = 1) +   facet_wrap(~mixture_collection, scales = \"free\") CC_pprc <- mix_ests_with_catch$posterior_predictive_remaining_catch_traces %>%   group_by(mixture_collection, sweep, repunit) %>%   summarise(repunit_pprc = sum(PPRC)) %>%   # column PPRC has the posterior_predictive_remaining_catch   filter(sweep > 100, repunit == \"CaliforniaCoast\") ## `summarise()` has grouped output by 'mixture_collection', 'sweep'. You can ## override using the `.groups` argument. CC_ac <- mix_ests_with_catch$allocation_count_traces %>%   group_by(mixture_collection, sweep, repunit) %>%   summarise(repunit_ac = sum(CA)) %>%  # column CA has the allocation_count   filter(sweep > 100, repunit == \"CaliforniaCoast\") ## `summarise()` has grouped output by 'mixture_collection', 'sweep'. You can ## override using the `.groups` argument. # then join those to the total stock-specific catch and pivot them three_counts <- CC_sstc %>%   left_join(CC_pprc, by = join_by(mixture_collection, sweep, repunit)) %>%   left_join(CC_ac, by = join_by(mixture_collection, sweep, repunit)) %>%   pivot_longer(cols = repunit_sstc:repunit_ac, names_to = \"count_type\", values_to = \"n\") ggplot(three_counts, aes(x = n, fill = count_type)) +   geom_histogram(binwidth = 1) +   facet_grid(count_type ~ mixture_collection, scales = \"free\") +   xlab(\"Number of individuals of repunit CaliforniaCoast\")"},{"path":"https://eriqande.github.io/rubias/articles/uncertainty-on-total-catch.html","id":"some-genotypes-sampled-might-not-be-considered-part-of-the-catchmortality","dir":"Articles","previous_headings":"Examples","what":"Some Genotypes Sampled Might not be Considered Part of the Catch/Mortality","title":"Summarizing Uncertainty on Stock-Specific Total Catch","text":"Another possible use case involve test catch--release fishery concomitant retention fishery. Genotypes different fisheries might end together sample mixed fishery certain time place. occurs fish released sampling survive sampling process adverse impacts, one want count part fishing mortality , however, conceivable mortality associated live release, case might appropriate account mortalities part catch. fixed rate mortality may assumed applied releases depending fishery environmental conditions. Alternatively, tissues taken test fishery, score may assigned fish rating injuries received—hence chance might die release. Rubias simple way handling cases. Essentially, fish mixture assigned value 0 1, inclusive, additional column (must appear start genotype columns) called prob_is_catch. short “probability fish considered part catch.” value 1 means fish part catch. value 0 means fish certainly considered part catch. value pp 0 1 means fish probability pp dying sampling, die, considered part catch. previous section, Fishery Samples Part Catch, saw simple case fish mixture prob_is_catch = 1. default situation: unless otherwise specified, every fish mixture considered part catch. However, supply option variable_prob_is_catch = TRUE infer_mixture() function, function require prob_is_catch column, use values within account fish test samples might considered part catch. make data illustrate different scenarios. imagine : 743 “rec1” fishery samples, first 300 test fishery believed zero mortality considered part catch. 772 “rec2” fishery samples taken test fishery well known fish handled roughly. average, 1/5 released 50% chance dying result treatment, 1/5 individuals 40, 30, 20, 10% chance dying part catch, respectively, well (obviously just illustration!) “rec3” fish considered part catch. can modify chinook_mix data set prob_is_catch column reflects : Let’s just verify done correctly counting occurrences different prob_is_catch values: looks pretty good! pass infer_mixture() need address constraint associated variable_prob_is_catch = TRUE: reference data set mixture data set must columns. need add column reference data set chinook. simply put column 0’s . Now, genotype data start 6th column. run without variable_prob_is_catch = TRUE option, get just got , infer_mixture() use prob_is_catch column. However, include variable_prob_is_catch = TRUE option, infer_mixture() function going look use information prob_is_catch column. Let us now look resulting numbers, paying careful attention “rec1”, particularly illuminating. total catch (743), 300 mixture sample part catch, variation total catch .  looks .","code":"chinook_mix_with_probs <- chinook_mix %>%   group_by(collection) %>%   mutate(     prob_is_catch = case_when(       collection == \"rec1\" & (1:n()) <= 300 ~ 0,       collection == \"rec1\" & (1:n()) > 300 ~ 1,       collection == \"rec2\" ~ sample(c(0.5, 0.4, 0.3, 0.2, 0.1), n(), replace = TRUE),       collection == \"rec3\" ~ 1     ),     .after = indiv   ) %>%   ungroup() chinook_mix_with_probs %>%   count(collection, prob_is_catch) ## # A tibble: 8 × 3 ##   collection prob_is_catch     n ##   <chr>              <dbl> <int> ## 1 rec1                 0     300 ## 2 rec1                 1     443 ## 3 rec2                 0.1   158 ## 4 rec2                 0.2   149 ## 5 rec2                 0.3   148 ## 6 rec2                 0.4   160 ## 7 rec2                 0.5   157 ## 8 rec3                 1     741 new_reference <- chinook %>%   mutate(prob_is_catch = 0.0, .after = indiv) catch_ests_with_var <- infer_mixture(   reference = new_reference,   mixture = chinook_mix_with_probs,   gen_start_col = 6,   method = rubi_method,   total_catch_tib = total_catches,   variable_prob_is_catch = TRUE ) ## Collating data; compiling reference allele frequencies, etc.   time: 0.71 seconds ## Computing reference locus specific means and variances for computing mixture z-scores   time: 0.10 seconds ## Working on mixture collection: rec2 with 772 individuals ## tot_catch_vec: 3088 3088 3088 3088 3088 3088 3088 3088 3088 3088 3088 3088... ##   calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.67 seconds ##   tidying output into a tibble.   time: 0.05 seconds ## Working on mixture collection: rec1 with 743 individuals ## tot_catch_vec: 743 743 743 743 743 743 743 743 743 743 743 743... ##   calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.64 seconds ##   tidying output into a tibble.   time: 0.05 seconds ## Working on mixture collection: rec3 with 741 individuals ## tot_catch_vec: 3839 3198 2791 4069 2834 2951 2911 2258 4157 2172 3606 4042... ##   calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds ##   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.64 seconds ##   tidying output into a tibble.   time: 0.05 seconds CC_sstc_var <- catch_ests_with_var$stock_specific_total_catch_traces %>%   group_by(mixture_collection, sweep, repunit) %>%   summarise(repunit_sstc = sum(SSTC)) %>%   filter(sweep > 100, repunit == \"CaliforniaCoast\") ## `summarise()` has grouped output by 'mixture_collection', 'sweep'. You can ## override using the `.groups` argument. CC_pprc_var <- catch_ests_with_var$posterior_predictive_remaining_catch_traces %>%   group_by(mixture_collection, sweep, repunit) %>%   summarise(repunit_pprc = sum(PPRC)) %>%   # column PPRC has the posterior_predictive_remaining_catch   filter(sweep > 100, repunit == \"CaliforniaCoast\") ## `summarise()` has grouped output by 'mixture_collection', 'sweep'. You can ## override using the `.groups` argument. CC_ac_var <- catch_ests_with_var$allocation_count_traces %>%   group_by(mixture_collection, sweep, repunit) %>%   summarise(repunit_ac = sum(CA)) %>%  # column CA has the allocation_count   filter(sweep > 100, repunit == \"CaliforniaCoast\") ## `summarise()` has grouped output by 'mixture_collection', 'sweep'. You can ## override using the `.groups` argument. # then join those to the total stock-specific catch and pivot them three_counts_var <- CC_sstc_var %>%   left_join(CC_pprc_var, by = join_by(mixture_collection, sweep, repunit)) %>%   left_join(CC_ac_var, by = join_by(mixture_collection, sweep, repunit)) %>%   pivot_longer(cols = repunit_sstc:repunit_ac, names_to = \"count_type\", values_to = \"n\")  ggplot(three_counts_var, aes(x = n, fill = count_type)) +   geom_histogram(binwidth = 1) +   facet_grid(count_type ~ mixture_collection, scales = \"free\")"},{"path":"https://eriqande.github.io/rubias/articles/uncertainty-on-total-catch.html","id":"using-this-with-the-fully-bayesian-model","dir":"Articles","previous_headings":"Examples","what":"Using this with the “Fully-Bayesian” model","title":"Summarizing Uncertainty on Stock-Specific Total Catch","text":"function infer_mixture() allows model allele frequencies updated MCMC including gene copies fish mixture allocated collection. model invoked using method = \"BR\" option infer_mixture(). “BR” stands “Bayesian Resampling” (allele frequencies). stock-specific total catch estimation procedures described also implemented “BR” method. don’t show natively vignette takes considerably longer likely pass CRAN checks consequence. However, can run steps using “BR” model simply setting variable rubi_method <- \"BR\" first R code block “Examples” section header.","code":""},{"path":[]},{"path":"https://eriqande.github.io/rubias/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Eric C. Anderson. Author, maintainer. Ben Moran. Author.","code":""},{"path":"https://eriqande.github.io/rubias/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Moran BM, Anderson EC (2018). “Bayesian inference conditional genetic stock identification model.” Canadian Journal Fisheries Aquatic Sciences, 76(4), 551–560. doi:10.1139/cjfas-2018-0016.","code":"@Article{,   title = {Bayesian inference from the conditional genetic stock identification model},   author = {Benjamin M Moran and Eric C Anderson},   journal = {Canadian Journal of Fisheries and Aquatic Sciences},   year = {2018},   volume = {76},   number = {4},   pages = {551--560},   doi = {10.1139/cjfas-2018-0016}, }"},{"path":"https://eriqande.github.io/rubias/index.html","id":"rubias--genetic-stock-identification-gsi-in-the-tidyverse","dir":"","previous_headings":"","what":"Bayesian Inference from the Conditional Genetic Stock Identification Model","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"16 October, 2025 haploid markers? example reference data file example mixture data file Preliminary good practice — check duplicate individuals known-origin individuals mixture? Setting prior mixing proportions Aggregating collections reporting units Creating posterior density curves traces Computing Credible Intervals Traces Assessing whether individuals reference populations Individuals known origin mixture Fully Bayesian model (updating allele freqencies) Self-assigning fish reference Simulated mixtures using leave-one-type approach Specifying mixture proportions assess_reference_loo() Retrieving individual simulated fish posteriors Changing resampling unit “sub-specifying” collection proportions dirichlet parameters 100% collections Bootstrap-Corrected Reporting Unit Proportions References R package performing genetic stock identification (GSI) associated tasks. Additionally, includes method designed diagnose correct bias recently documented genetic stock identification. bias occurs mixture proportion estimates desired groups populations (reporting units) number populations within reporting unit uneven. order run C++ implementations MCMC, rubias requires package Rcpp (now, also, RcppParallel baseline resampling option), turn requires Rtools installation (Windows) XCode (Mac). cloning repository dependencies installed, build & reload package view documentation. script “/R-main/coalescent_sim” used generate coalescent simulations bias correction validation. unnecessary testing applicability methods particular dataset, done using assess_reference_loo() assess_pb_bias_correction(). coalescent_sim() creates simulated populations using ms coalescent simulation program, available Hudson lab UChicago, GSImulator ms2geno packages, available https://github.com/eriqande, requires dependencies rest package.","code":""},{"path":"https://eriqande.github.io/rubias/index.html","id":"input-data","dir":"","previous_headings":"","what":"Input Data","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"functions conducting genetic mixture analysis simulation assessment predict accuracy set genetic markers genetic stock identification require genetic data input data frame specific format: one row per individual locus represented two adjacent columns, one allele (package configured diploids, moment). Allelic types can expressed number character missing data locus expressed NA values gene copy locus one gene copy missing locus indivividual, gene copies must missing locus. name locus taken column name first column pair locus columns. header second column ignored. sample_type: column telling whether sample reference sample mixture sample. repunit: reporting unit individual/collection belongs . required sample_type reference. sample_type mixture repunit must NA. must character vector. factor. idea “reporting unit” well-known amongst people genetic stock identfication salmon, might familiar elsewhere. Briefly, reporting unit group populations (call “collections”) typically closely related genetically, likely aggregrated results GSI exercise. collection: reference samples, name population individual . mixture samples, name particular sample (.e. stratum port treated together space time). must character, factor. indiv character vector ID fish. must unique. started developing rubias, intended allow repunit collection columns either character vectors factors. factors might desirable , example, certain sort order collections repunits desired. However point became clear Eric , given approach converting data C++ data structure integers, rapid analyis, exposing greater opportunities bugginess allowing repunit collection factors. Accordingly, must character vectors. , rubias throw error. Note: specific sort order collections repunits, can always change factors analysis rubias. Additionally, can keep extra columns original data frame (example repunit_f collection_f) repunits collections stored factors. See, example data file alewife. can just keep character vector sort order like, use changing things factors rubias analysis. (See, instance, chinook_repunit_levels.) file can number meta data columns; however, must occur data frame columns genetic data. pass data frame functions, tell column genetic data starts , assumed columns one contain genetic data. mixture analysis, data frame mixture fish reference fish must column structure, .e., must exactly number columns exactly column names, order type.","code":""},{"path":"https://eriqande.github.io/rubias/index.html","id":"how-about-haploid-markers","dir":"","previous_headings":"","what":"How about haploid markers?","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"request good folks ADFG, introduced hacks allow input include markers haploid (example mtDNA haplotypes). denote marker haploid still give two columns data data frame, second column haploid marker must entirely NAs. rubias processing data sees , assumes marker haploid treats appropriately. Note diploid marker typically make sense mark one gene copies missing non-missing. Accordingly, diploid marker records just one gene copies missing individual, going throw error. Likewise, haploid marker every single individual NA second gene copy, ’s also going throw error.","code":""},{"path":"https://eriqande.github.io/rubias/index.html","id":"an-example-reference-data-file","dir":"","previous_headings":"","what":"An example reference data file","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"meta data columns first two loci eight individuals chinook reference data set comes package:","code":"library(tidyverse)  # load up the tidyverse library, we will use it later... #> ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ── #> ✔ dplyr     1.1.4     ✔ readr     2.1.5 #> ✔ forcats   1.0.0     ✔ stringr   1.5.1 #> ✔ ggplot2   3.5.1     ✔ tibble    3.2.1 #> ✔ lubridate 1.9.4     ✔ tidyr     1.3.1 #> ✔ purrr     1.0.4      #> ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── #> ✖ dplyr::filter() masks stats::filter() #> ✖ dplyr::lag()    masks stats::lag() #> ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors library(rubias) head(chinook[, 1:8]) #> # A tibble: 6 × 8 #>   sample_type repunit         collection   indiv   Ots_94857.232 Ots_94857.232.1 #>   <chr>       <chr>           <chr>        <chr>           <int>           <int> #> 1 reference   CentralValleyfa Feather_H_sp Feathe…             2               2 #> 2 reference   CentralValleyfa Feather_H_sp Feathe…             2               4 #> 3 reference   CentralValleyfa Feather_H_sp Feathe…             2               4 #> 4 reference   CentralValleyfa Feather_H_sp Feathe…             2               4 #> 5 reference   CentralValleyfa Feather_H_sp Feathe…             2               2 #> 6 reference   CentralValleyfa Feather_H_sp Feathe…             2               4 #> # ℹ 2 more variables: Ots_102213.210 <int>, Ots_102213.210.1 <int>"},{"path":"https://eriqande.github.io/rubias/index.html","id":"an-example-mixture-data-file","dir":"","previous_headings":"","what":"An example mixture data file","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"mixture data frame goes along reference data set:","code":"head(chinook_mix[, 1:8]) #> # A tibble: 6 × 8 #>   sample_type repunit collection indiv   Ots_94857.232 Ots_94857.232.1 #>   <chr>       <chr>   <chr>      <chr>           <int>           <int> #> 1 mixture     <NA>    rec2       T124711             4               2 #> 2 mixture     <NA>    rec2       T124719             4               2 #> 3 mixture     <NA>    rec2       T124727             4               4 #> 4 mixture     <NA>    rec1       T124735             4               4 #> 5 mixture     <NA>    rec1       T124743             2               2 #> 6 mixture     <NA>    rec1       T124759             4               2 #> # ℹ 2 more variables: Ots_102213.210 <int>, Ots_102213.210.1 <int>"},{"path":"https://eriqande.github.io/rubias/index.html","id":"preliminary-good-practice--check-for-duplicate-individuals","dir":"","previous_headings":"","what":"Preliminary good practice — check for duplicate individuals","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"Sometimes, variety reasons, individual’s genotype might appear data set. rubias quick dirty function spot pairs individuals share large number genotypes. Clearly want look pairs don’t whole lot missing data, one parameter fraction loci non-missing either fish. experience Fluidigm assays, fish missing > 10% SNPs, remaining genotypes likely fairly high error rate. , look matching samples, let’s require 85% genotypes non-missing members pair. last parameter fraction non-missing loci pair genotype. set 0.94 first. see action: Check . reveals 33 pairs data set likely duplicate samples. reduce min_frac_matching, get matches, unlikely individual, unless genotyping error rates high. principled approach use allele frequencies collection take likelihood based approach, adequate finding obvious duplicates.","code":"# combine chinook and chinook_mix into one big data frame, # but drop the California_Coho collection because Coho all # have pretty much the same genotype at these loci! chinook_all <- bind_rows(chinook, chinook_mix) %>%   filter(collection != \"California_Coho\")  # then toss them into a function.  This takes half a minute or so... matchy_pairs <- close_matching_samples(D = chinook_all,                                         gen_start_col = 5,                                         min_frac_non_miss = 0.85,                                         min_frac_matching = 0.94                                        ) #> Summary Statistics: #>  #> 9510 Individuals in Sample #>  #> 91 Loci: AldB1.122, AldoB4.183, OTNAML12_1.SNP1, Ots_100884.287, Ots_101119.381, Ots_101704.143, Ots_102213.210, Ots_102414.395, Ots_102420.494, Ots_102457.132, Ots_102801.308, Ots_102867.609, Ots_103041.52, Ots_104063.132, Ots_104569.86, Ots_105105.613, Ots_105132.200, Ots_105401.325, Ots_105407.117, Ots_106499.70, Ots_106747.239, Ots_107074.284, Ots_107285.93, Ots_107806.821, Ots_108007.208, Ots_108390.329, Ots_108735.302, Ots_109693.392, Ots_110064.383, Ots_110201.363, Ots_110495.380, Ots_110551.64, Ots_111312.435, Ots_111666.408, Ots_111681.657, Ots_112301.43, Ots_112419.131, Ots_112820.284, Ots_112876.371, Ots_113242.216, Ots_113457.40, Ots_117043.255, Ots_117242.136, Ots_117432.409, Ots_118175.479, Ots_118205.61, Ots_118938.325, Ots_122414.56, Ots_123048.521, Ots_123921.111, Ots_124774.477, Ots_127236.62, Ots_128302.57, Ots_128693.461, Ots_128757.61, Ots_129144.472, Ots_129170.683, Ots_129458.451, Ots_130720.99, Ots_131460.584, Ots_131906.141, Ots_94857.232, Ots_96222.525, Ots_96500.180, Ots_97077.179, Ots_99550.204, Ots_ARNT.195, Ots_AsnRS.60, Ots_aspat.196, Ots_CD59.2, Ots_CD63, Ots_EP.529, Ots_GDH.81x, Ots_HSP90B.385, Ots_MHC1, Ots_mybp.85, Ots_myoD.364, Ots_Ots311.101x, Ots_PGK.54, Ots_Prl2, Ots_RFC2.558, Ots_SClkF2R2.135, Ots_SWS1op.182, Ots_TAPBP, Ots_u07.07.161, Ots_u07.49.290, Ots_u4.92, OTSBMP.2.SNP1, OTSTF1.SNP1, S71.336, unk_526 #>  #> 39 Reporting Units: CentralValleyfa, CentralValleysp, CentralValleywi, CaliforniaCoast, KlamathR, NCaliforniaSOregonCoast, RogueR, MidOregonCoast, NOregonCoast, WillametteR, DeschutesRfa, LColumbiaRfa, LColumbiaRsp, MidColumbiaRtule, UColumbiaRsufa, MidandUpperColumbiaRsp, SnakeRfa, SnakeRspsu, NPugetSound, WashingtonCoast, SPugetSound, LFraserR, LThompsonR, EVancouverIs, WVancouverIs, MSkeenaR, MidSkeenaR, LSkeenaR, SSEAlaska, NGulfCoastAlsekR, NGulfCoastKarlukR, TakuR, NSEAlaskaChilkatR, NGulfCoastSitukR, CopperR, SusitnaR, LKuskokwimBristolBay, MidYukon #>  #> 68 Collections: Feather_H_sp, Butte_Cr_Sp, Mill_Cr_sp, Deer_Cr_sp, UpperSacramento_R_sp, Feather_H_fa, Butte_Cr_fa, Mill_Cr_fa, Deer_Cr_fa, Mokelumne_R_fa, Battle_Cr, Sacramento_R_lf, Sacramento_H, Eel_R, Russian_R, Klamath_IGH_fa, Trinity_H_sp, Smith_R, Chetco_R, Cole_Rivers_H, Applegate_Cr, Coquille_R, Umpqua_sp, Nestucca_H, Siuslaw_R, Alsea_R, Nehalem_R, Siletz_R, N_Santiam_H, McKenzie_H, L_Deschutes_R, Cowlitz_H_fa, Cowlitz_H_sp, Kalama_H_sp, Spring_Cr_H, Hanford_Reach, PriestRapids_H, Wells_H, Wenatchee_R, CleElum, Lyons_Ferry_H, Rapid_R_H, McCall_H, Kendall_H_sp, Forks_Cr_H, Soos_H, Marblemount_H_sp, QuinaltLake_f, Harris_R, Birkenhead_H, Spius_H, Big_Qual_H, Robertson_H, Morice_R, Kitwanga_R, L_Kalum_R, LPW_Unuk_R, Goat_Cr, Karluk_R, LittleTatsamenie, Tahini_R, Situk_R, Sinona_Ck, Montana_Ck, George_R, Kanektok_R, Togiak_R, Kantishna_R #>  #> 3.85% of allelic data identified as missing  # see that that looks like: matchy_pairs %>%   arrange(desc(num_non_miss), desc(num_match)) #> # A tibble: 33 × 10 #>    num_non_miss num_match indiv_1            indiv_2   collection_1 collection_2 #>           <int>     <int> <chr>              <chr>     <chr>        <chr>        #>  1           91        91 T124864            T124866   rec3         rec1         #>  2           91        91 T124864            T125335   rec3         rec3         #>  3           91        91 T124866            T125335   rec1         rec3         #>  4           91        91 T126402            T126403   rec2         rec2         #>  5           91        90 Mill_Cr_sp:0060    Mill_Cr_… Mill_Cr_sp   Mill_Cr_sp   #>  6           91        90 Cole_Rivers_H:0002 Cole_Riv… Cole_Rivers… Cole_Rivers… #>  7           91        90 Cole_Rivers_H:0017 Cole_Riv… Cole_Rivers… Cole_Rivers… #>  8           91        90 Umpqua_sp:0009     Umpqua_s… Umpqua_sp    Umpqua_sp    #>  9           91        90 Umpqua_sp:0018     Umpqua_s… Umpqua_sp    Umpqua_sp    #> 10           91        90 T125044            T125337   rec2         rec1         #> # ℹ 23 more rows #> # ℹ 4 more variables: sample_type_1 <chr>, repunit_1 <chr>, #> #   sample_type_2 <chr>, repunit_2 <chr> # then toss them into a function.  This takes half a minute or so... matchy_pairs2 <- close_matching_samples(D = chinook_all,                                         gen_start_col = 5,                                         min_frac_non_miss = 0.85,                                         min_frac_matching = 0.85                                        ) #> Summary Statistics: #>  #> 9510 Individuals in Sample #>  #> 91 Loci: AldB1.122, AldoB4.183, OTNAML12_1.SNP1, Ots_100884.287, Ots_101119.381, Ots_101704.143, Ots_102213.210, Ots_102414.395, Ots_102420.494, Ots_102457.132, Ots_102801.308, Ots_102867.609, Ots_103041.52, Ots_104063.132, Ots_104569.86, Ots_105105.613, Ots_105132.200, Ots_105401.325, Ots_105407.117, Ots_106499.70, Ots_106747.239, Ots_107074.284, Ots_107285.93, Ots_107806.821, Ots_108007.208, Ots_108390.329, Ots_108735.302, Ots_109693.392, Ots_110064.383, Ots_110201.363, Ots_110495.380, Ots_110551.64, Ots_111312.435, Ots_111666.408, Ots_111681.657, Ots_112301.43, Ots_112419.131, Ots_112820.284, Ots_112876.371, Ots_113242.216, Ots_113457.40, Ots_117043.255, Ots_117242.136, Ots_117432.409, Ots_118175.479, Ots_118205.61, Ots_118938.325, Ots_122414.56, Ots_123048.521, Ots_123921.111, Ots_124774.477, Ots_127236.62, Ots_128302.57, Ots_128693.461, Ots_128757.61, Ots_129144.472, Ots_129170.683, Ots_129458.451, Ots_130720.99, Ots_131460.584, Ots_131906.141, Ots_94857.232, Ots_96222.525, Ots_96500.180, Ots_97077.179, Ots_99550.204, Ots_ARNT.195, Ots_AsnRS.60, Ots_aspat.196, Ots_CD59.2, Ots_CD63, Ots_EP.529, Ots_GDH.81x, Ots_HSP90B.385, Ots_MHC1, Ots_mybp.85, Ots_myoD.364, Ots_Ots311.101x, Ots_PGK.54, Ots_Prl2, Ots_RFC2.558, Ots_SClkF2R2.135, Ots_SWS1op.182, Ots_TAPBP, Ots_u07.07.161, Ots_u07.49.290, Ots_u4.92, OTSBMP.2.SNP1, OTSTF1.SNP1, S71.336, unk_526 #>  #> 39 Reporting Units: CentralValleyfa, CentralValleysp, CentralValleywi, CaliforniaCoast, KlamathR, NCaliforniaSOregonCoast, RogueR, MidOregonCoast, NOregonCoast, WillametteR, DeschutesRfa, LColumbiaRfa, LColumbiaRsp, MidColumbiaRtule, UColumbiaRsufa, MidandUpperColumbiaRsp, SnakeRfa, SnakeRspsu, NPugetSound, WashingtonCoast, SPugetSound, LFraserR, LThompsonR, EVancouverIs, WVancouverIs, MSkeenaR, MidSkeenaR, LSkeenaR, SSEAlaska, NGulfCoastAlsekR, NGulfCoastKarlukR, TakuR, NSEAlaskaChilkatR, NGulfCoastSitukR, CopperR, SusitnaR, LKuskokwimBristolBay, MidYukon #>  #> 68 Collections: Feather_H_sp, Butte_Cr_Sp, Mill_Cr_sp, Deer_Cr_sp, UpperSacramento_R_sp, Feather_H_fa, Butte_Cr_fa, Mill_Cr_fa, Deer_Cr_fa, Mokelumne_R_fa, Battle_Cr, Sacramento_R_lf, Sacramento_H, Eel_R, Russian_R, Klamath_IGH_fa, Trinity_H_sp, Smith_R, Chetco_R, Cole_Rivers_H, Applegate_Cr, Coquille_R, Umpqua_sp, Nestucca_H, Siuslaw_R, Alsea_R, Nehalem_R, Siletz_R, N_Santiam_H, McKenzie_H, L_Deschutes_R, Cowlitz_H_fa, Cowlitz_H_sp, Kalama_H_sp, Spring_Cr_H, Hanford_Reach, PriestRapids_H, Wells_H, Wenatchee_R, CleElum, Lyons_Ferry_H, Rapid_R_H, McCall_H, Kendall_H_sp, Forks_Cr_H, Soos_H, Marblemount_H_sp, QuinaltLake_f, Harris_R, Birkenhead_H, Spius_H, Big_Qual_H, Robertson_H, Morice_R, Kitwanga_R, L_Kalum_R, LPW_Unuk_R, Goat_Cr, Karluk_R, LittleTatsamenie, Tahini_R, Situk_R, Sinona_Ck, Montana_Ck, George_R, Kanektok_R, Togiak_R, Kantishna_R #>  #> 3.85% of allelic data identified as missing  # see that that looks like: matchy_pairs2 %>%   arrange(desc(num_non_miss), desc(num_match)) #> # A tibble: 46 × 10 #>    num_non_miss num_match indiv_1            indiv_2   collection_1 collection_2 #>           <int>     <int> <chr>              <chr>     <chr>        <chr>        #>  1           91        91 T124864            T124866   rec3         rec1         #>  2           91        91 T124864            T125335   rec3         rec3         #>  3           91        91 T124866            T125335   rec1         rec3         #>  4           91        91 T126402            T126403   rec2         rec2         #>  5           91        90 Mill_Cr_sp:0060    Mill_Cr_… Mill_Cr_sp   Mill_Cr_sp   #>  6           91        90 Cole_Rivers_H:0002 Cole_Riv… Cole_Rivers… Cole_Rivers… #>  7           91        90 Cole_Rivers_H:0017 Cole_Riv… Cole_Rivers… Cole_Rivers… #>  8           91        90 Umpqua_sp:0009     Umpqua_s… Umpqua_sp    Umpqua_sp    #>  9           91        90 Umpqua_sp:0018     Umpqua_s… Umpqua_sp    Umpqua_sp    #> 10           91        90 T125044            T125337   rec2         rec1         #> # ℹ 36 more rows #> # ℹ 4 more variables: sample_type_1 <chr>, repunit_1 <chr>, #> #   sample_type_2 <chr>, repunit_2 <chr>"},{"path":"https://eriqande.github.io/rubias/index.html","id":"how-about-known-origin-individuals-in-the-mixture","dir":"","previous_headings":"","what":"How about known-origin individuals in the mixture?","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"cases, might know (less unambiguously) origin fish particular mixture sample. example, 10% individuals mixture carried coded wire tags, want include sample, make sure collections origin hard-coded CWTs said. Another scenario might occur genetic data used parentage-based tagging individuals mixture sample. case, individuals might placed high confidence parents. , included mixture come known collection. folks DFO Nanaimo, Canada amazing job PBT wondered rubias modified deal latter situation. ’ve made small additions accommodate . rubias actual inference parentage, know origin fish mixture, can included rubias analysis. way function infer_mixture() include column called known_collection reference data frame mixture data frame. reference data frame, known_collection just copy collection column. However, mixture data frame entry known_collection collection individual known (.e. using parentage inference CWT), , individual known collection, NA. Note names collections known_collection must match found collection column reference data set. modifications allowed parametric bootstrap (PB) method infer_mixture().","code":""},{"path":"https://eriqande.github.io/rubias/index.html","id":"performing-a-genetic-mixture-analysis","dir":"","previous_headings":"","what":"Performing a Genetic Mixture Analysis","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"done infer_mixture function. example data chinook_mix data consist fish caught three different fisheries, rec1, rec2, rec3 denoted collection column. collections treated separate sample, getting mixing proportion estimate. run default options: result comes back list four tidy data frames: mixing_proportions: mixing proportions. column pi holds estimated mixing proportion collection. indiv_posteriors: holds, individual, posterior means group membership collection. Column PofZ holds values. Column log_likelihood holds log probability individuals genotype given collection. Also included n_non_miss_loci n_miss_loci number observed loci number missing loci individual. list column missing_loci contains vectors indices (names) loci missing individual. also includes column z_score can used diagnose fish don’t belong samples reference data base (see ). mix_prop_traces: MCMC traces mixing proportions collection. use want make density estimates posterior distribution mixing proportions want compute credible intervals. bootstrapped_proportions: NULL example, chosen method = \"PB\" tibble bootstrap-corrected reporting unit mixing proportions. data frames look like :","code":"mix_est <- infer_mixture(reference = chinook,                           mixture = chinook_mix,                           gen_start_col = 5) #> Collating data; compiling reference allele frequencies, etc.   time: 0.83 seconds #> Computing reference locus specific means and variances for computing mixture z-scores   time: 0.10 seconds #> Working on mixture collection: rec2 with 772 individuals #>   calculating log-likelihoods of the mixture individuals.   time: 0.07 seconds #>   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.54 seconds #>   tidying output into a tibble.   time: 0.03 seconds #> Working on mixture collection: rec1 with 743 individuals #>   calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds #>   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.52 seconds #>   tidying output into a tibble.   time: 0.03 seconds #> Working on mixture collection: rec3 with 741 individuals #>   calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds #>   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.51 seconds #>   tidying output into a tibble.   time: 0.03 seconds lapply(mix_est, head) #> $mixing_proportions #> # A tibble: 6 × 4 #>   mixture_collection repunit         collection                  pi #>   <chr>              <chr>           <chr>                    <dbl> #> 1 rec2               CentralValleyfa Feather_H_sp         0.0819    #> 2 rec2               CentralValleysp Butte_Cr_Sp          0.0000443 #> 3 rec2               CentralValleysp Mill_Cr_sp           0.0000426 #> 4 rec2               CentralValleysp Deer_Cr_sp           0.0000383 #> 5 rec2               CentralValleysp UpperSacramento_R_sp 0.000380  #> 6 rec2               CentralValleyfa Feather_H_fa         0.147     #>  #> $indiv_posteriors #> # A tibble: 6 × 10 #>   mixture_collection indiv   repunit  collection     PofZ log_likelihood z_score #>   <chr>              <chr>   <chr>    <chr>         <dbl>          <dbl>   <dbl> #> 1 rec2               T124711 Central… Feather_H… 1.86e-28          -137.   -13.1 #> 2 rec2               T124711 Central… Feather_H… 9.66e-28          -136.   -12.6 #> 3 rec2               T124711 Central… Butte_Cr_… 1.53e-24          -130.   -10.5 #> 4 rec2               T124711 Central… Mill_Cr_fa 2.80e-29          -135.   -11.8 #> 5 rec2               T124711 Central… Deer_Cr_fa 1.82e-28          -134.   -11.6 #> 6 rec2               T124711 Central… Mokelumne… 1.94e-27          -134.   -12.3 #> # ℹ 3 more variables: n_non_miss_loci <int>, n_miss_loci <int>, #> #   missing_loci <list> #>  #> $mix_prop_traces #> # A tibble: 6 × 5 #>   mixture_collection sweep repunit         collection               pi #>   <chr>              <int> <chr>           <chr>                 <dbl> #> 1 rec2                   0 CentralValleyfa Feather_H_sp         0.0145 #> 2 rec2                   0 CentralValleysp Butte_Cr_Sp          0.0145 #> 3 rec2                   0 CentralValleysp Mill_Cr_sp           0.0145 #> 4 rec2                   0 CentralValleysp Deer_Cr_sp           0.0145 #> 5 rec2                   0 CentralValleysp UpperSacramento_R_sp 0.0145 #> 6 rec2                   0 CentralValleyfa Feather_H_fa         0.0145 #>  #> $bootstrapped_proportions #> # A tibble: 0 × 0"},{"path":"https://eriqande.github.io/rubias/index.html","id":"setting-the-prior-for-the-mixing-proportions","dir":"","previous_headings":"","what":"Setting the prior for the mixing proportions","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"cases might reason explicitly set parameters Dirichlet prior mixing proportions collections. contrived example, imagine wanted Dirichlet prior parameters equal 1/(# collections), except parameters Central Valley Fall Run populations, like assign Dirichlet parameters 2. can accomplished pi_prior argument infer_mixture() function, let pass tibble one column named “collection” gives collection, column, named “pi_param” gives desired parameter. construct kind input: can run infer_mixture(): now, fun, can compare results mixing proportions different collections without prior mixture collection rec1:  Yep, slightly different . Let’s look sums everything: see part change prior changed distribution fish different collections within Central Valley Fall reporting unit. suprising—hard tell apart fish different collections. However, greatly change estimated proportion whole reporting unit. also turns make sense consider effect extra weight prior .","code":"prior_tibble <- chinook %>%   count(repunit, collection) %>%   filter(repunit == \"CentralValleyfa\") %>%   select(collection) %>%   mutate(pi_param = 2)  # see what it looks like: prior_tibble #> # A tibble: 8 × 2 #>   collection      pi_param #>   <chr>              <dbl> #> 1 Battle_Cr              2 #> 2 Butte_Cr_fa            2 #> 3 Deer_Cr_fa             2 #> 4 Feather_H_fa           2 #> 5 Feather_H_sp           2 #> 6 Mill_Cr_fa             2 #> 7 Mokelumne_R_fa         2 #> 8 Sacramento_R_lf        2 set.seed(12) mix_est_with_prior <- infer_mixture(reference = chinook,                           mixture = chinook_mix,                           gen_start_col = 5,                          pi_prior = prior_tibble) #> Collating data; compiling reference allele frequencies, etc.   time: 0.66 seconds #> Computing reference locus specific means and variances for computing mixture z-scores   time: 0.10 seconds #> Working on mixture collection: rec2 with 772 individuals #> Joining with `by = join_by(collection)`  calculating log-likelihoods of the mixture individuals.   time: 0.07 seconds #>   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.55 seconds #>   tidying output into a tibble.   time: 0.03 seconds #> Working on mixture collection: rec1 with 743 individuals #> Joining with `by = join_by(collection)`  calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds #>   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.52 seconds #>   tidying output into a tibble.   time: 0.03 seconds #> Working on mixture collection: rec3 with 741 individuals #> Joining with `by = join_by(collection)`  calculating log-likelihoods of the mixture individuals.   time: 0.06 seconds #>   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.52 seconds #>   tidying output into a tibble.   time: 0.03 seconds comp_mix_ests <- list(   `pi (default prior)` = mix_est$mixing_proportions,   `pi (cv fall gets 2s prior)` = mix_est_with_prior$mixing_proportions ) %>%   bind_rows(.id = \"prior_type\") %>%   filter(mixture_collection == \"rec1\") %>%   select(prior_type, repunit, collection, pi) %>%   spread(prior_type, pi) %>%   mutate(coll_group = ifelse(repunit == \"CentralValleyfa\", \"CV_fall\", \"Not_CV_fall\"))  ggplot(comp_mix_ests,         aes(x = `pi (default prior)`,             y = `pi (cv fall gets 2s prior)`,            colour = coll_group            )) +   geom_point() +   geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") comp_mix_ests %>%    group_by(coll_group) %>%    summarise(with_explicit_prior = sum(`pi (cv fall gets 2s prior)`),              with_default_prior = sum(`pi (default prior)`)) #> # A tibble: 2 × 3 #>   coll_group  with_explicit_prior with_default_prior #>   <chr>                     <dbl>              <dbl> #> 1 CV_fall                   0.824              0.821 #> 2 Not_CV_fall               0.176              0.179"},{"path":"https://eriqande.github.io/rubias/index.html","id":"aggregating-collections-into-reporting-units","dir":"","previous_headings":"","what":"Aggregating collections into reporting units","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"simple operation tidyverse:","code":"# for mixing proportions rep_mix_ests <- mix_est$mixing_proportions %>%   group_by(mixture_collection, repunit) %>%   summarise(repprop = sum(pi))  # adding mixing proportions over collections in the repunit #> `summarise()` has grouped output by 'mixture_collection'. You can override #> using the `.groups` argument.  # for individuals posteriors rep_indiv_ests <- mix_est$indiv_posteriors %>%   group_by(mixture_collection, indiv, repunit) %>%   summarise(rep_pofz = sum(PofZ)) #> `summarise()` has grouped output by 'mixture_collection', 'indiv'. You can #> override using the `.groups` argument."},{"path":"https://eriqande.github.io/rubias/index.html","id":"creating-posterior-density-curves-from-the-traces","dir":"","previous_headings":"","what":"Creating posterior density curves from the traces","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"full MCMC output mixing proportions available default field $mix_prop_traces. can used obtain estimate posterior density mixing proportions. plot kernel density estimates 6 abundant repunits rec1 fishery:","code":"# find the top 6 most abundant: top6 <- rep_mix_ests %>%   filter(mixture_collection == \"rec1\") %>%    arrange(desc(repprop)) %>%   slice(1:6)  # check how many MCMC sweeps were done: nsweeps <- max(mix_est$mix_prop_traces$sweep)  # keep only rec1, then discard the first 200 sweeps as burn-in, # and then aggregate over reporting units # and then keep only the top6 from above trace_subset <- mix_est$mix_prop_traces %>%   filter(mixture_collection == \"rec1\", sweep > 200) %>%   group_by(sweep, repunit) %>%   summarise(repprop = sum(pi)) %>%    filter(repunit %in% top6$repunit) #> `summarise()` has grouped output by 'sweep'. You can override using the #> `.groups` argument.   # now we can plot those: ggplot(trace_subset, aes(x = repprop, colour = repunit)) +   geom_density()"},{"path":"https://eriqande.github.io/rubias/index.html","id":"computing-credible-intervals-from-the-traces","dir":"","previous_headings":"","what":"Computing Credible Intervals from the Traces","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"Following example, use trace_subset compute equal-tail 95% credible intervals 6 abundant reporting units rec1 fishery:","code":"top6_cis <- trace_subset %>%   group_by(repunit) %>%   summarise(loCI = quantile(repprop, probs = 0.025),             hiCI = quantile(repprop, probs = 0.975))  top6_cis #> # A tibble: 6 × 3 #>   repunit                     loCI   hiCI #>   <chr>                      <dbl>  <dbl> #> 1 CaliforniaCoast         1.86e- 2 0.0437 #> 2 CentralValleyfa         7.90e- 1 0.848  #> 3 KlamathR                4.95e- 2 0.0865 #> 4 NCaliforniaSOregonCoast 3.12e- 3 0.0184 #> 5 RogueR                  4.36e- 2 0.0814 #> 6 UColumbiaRsufa          2.45e-18 0.0122"},{"path":"https://eriqande.github.io/rubias/index.html","id":"assessing-whether-individuals-are-not-from-any-of-the-reference-populations","dir":"","previous_headings":"","what":"Assessing whether individuals are not from any of the reference populations","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"Sometimes totally unexpected things happen. One situation saw California Chinook fishery samples coming us actually coho salmon. included coho salmon reference sample, coho always assigned quite strongly Alaska populations Chinook, even though don’t really look like Chinook . case, useful look raw log-likelihood values computed individual, rather scaled posterior probabilities. aberrantly low values genotype log-likelihood can indicate something wrong. However, raw likelihood get depend number missing loci, etc. rubias deals computing z-score fish. Z-score Z statistic obtained fish’s log-likelihood (subtracting expected log-likelihood dividing expected standard deviation). rubias’s implementation z-score accounts pattern missing data, without simulation gsi_sim . makes much, much, faster—fast enough can compute default every fish every population. , look z-score computed fish population highest posterior. (worth noting never want use z-score assign fish different populations—decide whether looks like might actually come population assigned , population reference data set.) everything kosher, expect z-scores see roughly normally distributed. can compare distribution z-scores see bunch simulated normal random variables.  normal density black distribution observed z_scores blue. fit reasonably well, suggesting much weird stuff going overall. (good!) z_score statistic useful check individuals. intended quick way identify aberrant individuals. see z-score maximum--posteriori population individual mixture sample considerably less z_scores saw reference, might infer individual doesn’t actually fit populations reference well.","code":"# get the maximum-a-posteriori population for each individual map_rows <- mix_est$indiv_posteriors %>%   group_by(indiv) %>%   top_n(1, PofZ) %>%   ungroup() normo <- tibble(z_score = rnorm(1e06)) ggplot(map_rows, aes(x = z_score)) +   geom_density(colour = \"blue\") +   geom_density(data = normo, colour = \"black\")"},{"path":"https://eriqande.github.io/rubias/index.html","id":"individuals-of-known-origin-in-the-mixture","dir":"","previous_headings":"","what":"Individuals of known origin in the mixture","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"include small, contrived example. use small_chinook data set goes fast. First, analyze data fish mixture known collection look results mixing proportions: Now, analysis, pretend know first 8 36 fish fishery rec1 Deer_Cr_sp collection. First add known_collection column reference. add known collection column mixture. start making NAs, change Deer_Cr_sp 8 rec1 fish: now can mixture analysis: , look estimated proportions, see rec1 reflect fact 8 fish singled known fish Deer_Ck_sp: output infer_mixture() case can used just like without known individuals baseline.","code":"no_kc <- infer_mixture(small_chinook_ref, small_chinook_mix, gen_start_col = 5) #> Collating data; compiling reference allele frequencies, etc.   time: 0.09 seconds #> Computing reference locus specific means and variances for computing mixture z-scores   time: 0.01 seconds #> Working on mixture collection: rec3 with 29 individuals #>   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds #>   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds #>   tidying output into a tibble.   time: 0.01 seconds #> Working on mixture collection: rec1 with 36 individuals #>   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds #>   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds #>   tidying output into a tibble.   time: 0.01 seconds #> Working on mixture collection: rec2 with 35 individuals #>   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds #>   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds #>   tidying output into a tibble.   time: 0.01 seconds no_kc$mixing_proportions %>%    arrange(mixture_collection, desc(pi)) #> # A tibble: 18 × 4 #>    mixture_collection repunit         collection          pi #>    <chr>              <chr>           <chr>            <dbl> #>  1 rec1               CentralValleyfa Feather_H_fa   0.849   #>  2 rec1               CentralValleysp Deer_Cr_sp     0.0508  #>  3 rec1               CaliforniaCoast Eel_R          0.0400  #>  4 rec1               KlamathR        Klamath_IGH_fa 0.0305  #>  5 rec1               MidOregonCoast  Umpqua_sp      0.0252  #>  6 rec1               CentralValleywi Sacramento_H   0.00463 #>  7 rec2               CentralValleyfa Feather_H_fa   0.809   #>  8 rec2               KlamathR        Klamath_IGH_fa 0.103   #>  9 rec2               MidOregonCoast  Umpqua_sp      0.0733  #> 10 rec2               CentralValleysp Deer_Cr_sp     0.00550 #> 11 rec2               CaliforniaCoast Eel_R          0.00479 #> 12 rec2               CentralValleywi Sacramento_H   0.00474 #> 13 rec3               CentralValleyfa Feather_H_fa   0.839   #> 14 rec3               CaliforniaCoast Eel_R          0.0714  #> 15 rec3               MidOregonCoast  Umpqua_sp      0.0496  #> 16 rec3               KlamathR        Klamath_IGH_fa 0.0262  #> 17 rec3               CentralValleysp Deer_Cr_sp     0.00875 #> 18 rec3               CentralValleywi Sacramento_H   0.00542 # make reference file that includes the known_collection column kc_ref <- small_chinook_ref %>%   mutate(known_collection = collection) %>%   select(known_collection, everything())  # see what that looks like kc_ref[1:10, 1:8] #> # A tibble: 10 × 8 #>    known_collection sample_type repunit         collection indiv   Ots_94857.232 #>    <chr>            <chr>       <chr>           <chr>      <chr>           <int> #>  1 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 #>  2 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 #>  3 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 #>  4 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             4 #>  5 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 #>  6 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             4 #>  7 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 #>  8 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             4 #>  9 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 #> 10 Deer_Cr_sp       reference   CentralValleysp Deer_Cr_sp Deer_C…             2 #> # ℹ 2 more variables: Ots_94857.232.1 <int>, Ots_102213.210 <int> kc_mix <- small_chinook_mix %>%   mutate(known_collection = NA) %>%   select(known_collection, everything())  kc_mix$known_collection[kc_mix$collection == \"rec1\"][1:8] <- \"Deer_Cr_sp\"  # here is what that looks like now (dropping most of the genetic data columns) kc_mix[1:20, 1:7] #> # A tibble: 20 × 7 #>    known_collection sample_type repunit collection indiv   Ots_94857.232 #>    <chr>            <chr>       <chr>   <chr>      <chr>           <int> #>  1 <NA>             mixture     <NA>    rec3       T125347             4 #>  2 Deer_Cr_sp       mixture     <NA>    rec1       T127759             4 #>  3 <NA>             mixture     <NA>    rec2       T124955             4 #>  4 <NA>             mixture     <NA>    rec2       T127564             2 #>  5 <NA>             mixture     <NA>    rec3       T127392             4 #>  6 Deer_Cr_sp       mixture     <NA>    rec1       T127414             4 #>  7 <NA>             mixture     <NA>    rec3       T124839             4 #>  8 Deer_Cr_sp       mixture     <NA>    rec1       T126414             2 #>  9 <NA>             mixture     <NA>    rec3       T125252             4 #> 10 Deer_Cr_sp       mixture     <NA>    rec1       T127765             4 #> 11 Deer_Cr_sp       mixture     <NA>    rec1       T127293             2 #> 12 Deer_Cr_sp       mixture     <NA>    rec1       T127577             2 #> 13 <NA>             mixture     <NA>    rec2       T126766             4 #> 14 <NA>             mixture     <NA>    rec3       T126494             4 #> 15 <NA>             mixture     <NA>    rec2       T125205             4 #> 16 Deer_Cr_sp       mixture     <NA>    rec1       T126584             4 #> 17 <NA>             mixture     <NA>    rec2       T124821             4 #> 18 <NA>             mixture     <NA>    rec3       T124905             2 #> 19 Deer_Cr_sp       mixture     <NA>    rec1       T124735             4 #> 20 <NA>             mixture     <NA>    rec3       T125624             2 #> # ℹ 1 more variable: Ots_94857.232.1 <int> # note that the genetic data start in column 6 now with_kc <- infer_mixture(kc_ref, kc_mix, 6) #> Collating data; compiling reference allele frequencies, etc.   time: 0.09 seconds #> Computing reference locus specific means and variances for computing mixture z-scores   time: 0.01 seconds #> Working on mixture collection: rec3 with 29 individuals #>   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds #>   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds #>   tidying output into a tibble.   time: 0.01 seconds #> Working on mixture collection: rec1 with 36 individuals #>   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds #>   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds #>   tidying output into a tibble.   time: 0.01 seconds #> Working on mixture collection: rec2 with 35 individuals #>   calculating log-likelihoods of the mixture individuals.   time: 0.00 seconds #>   performing 2000 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\"   time: 0.02 seconds #>   tidying output into a tibble.   time: 0.01 seconds with_kc$mixing_proportions %>%    arrange(mixture_collection, desc(pi)) #> # A tibble: 18 × 4 #>    mixture_collection repunit         collection          pi #>    <chr>              <chr>           <chr>            <dbl> #>  1 rec1               CentralValleyfa Feather_H_fa   0.546   #>  2 rec1               CentralValleysp Deer_Cr_sp     0.355   #>  3 rec1               CaliforniaCoast Eel_R          0.0411  #>  4 rec1               KlamathR        Klamath_IGH_fa 0.0318  #>  5 rec1               MidOregonCoast  Umpqua_sp      0.0220  #>  6 rec1               CentralValleywi Sacramento_H   0.00438 #>  7 rec2               CentralValleyfa Feather_H_fa   0.806   #>  8 rec2               KlamathR        Klamath_IGH_fa 0.104   #>  9 rec2               MidOregonCoast  Umpqua_sp      0.0732  #> 10 rec2               CentralValleysp Deer_Cr_sp     0.00688 #> 11 rec2               CaliforniaCoast Eel_R          0.00551 #> 12 rec2               CentralValleywi Sacramento_H   0.00456 #> 13 rec3               CentralValleyfa Feather_H_fa   0.835   #> 14 rec3               CaliforniaCoast Eel_R          0.0732  #> 15 rec3               MidOregonCoast  Umpqua_sp      0.0494  #> 16 rec3               KlamathR        Klamath_IGH_fa 0.0281  #> 17 rec3               CentralValleysp Deer_Cr_sp     0.00883 #> 18 rec3               CentralValleywi Sacramento_H   0.00565"},{"path":"https://eriqande.github.io/rubias/index.html","id":"fully-bayesian-model-with-updating-of-allele-freqencies","dir":"","previous_headings":"","what":"Fully Bayesian model (with updating of allele freqencies)","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"default model rubias conditional model inference done baseline allele counts fixed. fully Bayesian version, fish within mixture allocated (particular step MCMC) one reference samples alleles added reference sample, thus (one hopes) refining estimate allele frequencies sample. computationally intensive, , done using parallel computation, default running one thread every core machine. basic way invoke fully Bayesian model use infer_mixture function method option set “BR”. example: details different options working fully Bayesian model available vignette fully Bayesian model.","code":"full_model_results <- infer_mixture(   reference = chinook,    mixture = chinook_mix,    gen_start_col = 5,    method = \"BR\"   )"},{"path":[]},{"path":"https://eriqande.github.io/rubias/index.html","id":"self-assigning-fish-from-the-reference","dir":"","previous_headings":"","what":"Self-assigning fish from the reference","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"standard analysis molecular ecology assign individuals reference back collections reference using leave-one-procedure. taken care self_assign() function. Now, can look self assignment results: log_likelihood log probability fish’s genotype given inferred_collection computed using leave-one-. scaled_likelihood posterior prob assigning fish inferred_collection given equal prior every collection reference. columns output infer_mixture(). Note z_score computed can used assess distribution z_score statistic fish known, reference populations. can used compare values obtained mixed fisheries. output can summarized repunit done :","code":"sa_chinook <- self_assign(reference = chinook, gen_start_col = 5) #> Summary Statistics: #>  #> 7301 Individuals in Sample #>  #> 91 Loci: AldB1.122, AldoB4.183, OTNAML12_1.SNP1, Ots_100884.287, Ots_101119.381, Ots_101704.143, Ots_102213.210, Ots_102414.395, Ots_102420.494, Ots_102457.132, Ots_102801.308, Ots_102867.609, Ots_103041.52, Ots_104063.132, Ots_104569.86, Ots_105105.613, Ots_105132.200, Ots_105401.325, Ots_105407.117, Ots_106499.70, Ots_106747.239, Ots_107074.284, Ots_107285.93, Ots_107806.821, Ots_108007.208, Ots_108390.329, Ots_108735.302, Ots_109693.392, Ots_110064.383, Ots_110201.363, Ots_110495.380, Ots_110551.64, Ots_111312.435, Ots_111666.408, Ots_111681.657, Ots_112301.43, Ots_112419.131, Ots_112820.284, Ots_112876.371, Ots_113242.216, Ots_113457.40, Ots_117043.255, Ots_117242.136, Ots_117432.409, Ots_118175.479, Ots_118205.61, Ots_118938.325, Ots_122414.56, Ots_123048.521, Ots_123921.111, Ots_124774.477, Ots_127236.62, Ots_128302.57, Ots_128693.461, Ots_128757.61, Ots_129144.472, Ots_129170.683, Ots_129458.451, Ots_130720.99, Ots_131460.584, Ots_131906.141, Ots_94857.232, Ots_96222.525, Ots_96500.180, Ots_97077.179, Ots_99550.204, Ots_ARNT.195, Ots_AsnRS.60, Ots_aspat.196, Ots_CD59.2, Ots_CD63, Ots_EP.529, Ots_GDH.81x, Ots_HSP90B.385, Ots_MHC1, Ots_mybp.85, Ots_myoD.364, Ots_Ots311.101x, Ots_PGK.54, Ots_Prl2, Ots_RFC2.558, Ots_SClkF2R2.135, Ots_SWS1op.182, Ots_TAPBP, Ots_u07.07.161, Ots_u07.49.290, Ots_u4.92, OTSBMP.2.SNP1, OTSTF1.SNP1, S71.336, unk_526 #>  #> 39 Reporting Units: CentralValleyfa, CentralValleysp, CentralValleywi, CaliforniaCoast, KlamathR, NCaliforniaSOregonCoast, RogueR, MidOregonCoast, NOregonCoast, WillametteR, DeschutesRfa, LColumbiaRfa, LColumbiaRsp, MidColumbiaRtule, UColumbiaRsufa, MidandUpperColumbiaRsp, SnakeRfa, SnakeRspsu, NPugetSound, WashingtonCoast, SPugetSound, LFraserR, LThompsonR, EVancouverIs, WVancouverIs, MSkeenaR, MidSkeenaR, LSkeenaR, SSEAlaska, NGulfCoastAlsekR, NGulfCoastKarlukR, TakuR, NSEAlaskaChilkatR, NGulfCoastSitukR, CopperR, SusitnaR, LKuskokwimBristolBay, MidYukon, CohoSp #>  #> 69 Collections: Feather_H_sp, Butte_Cr_Sp, Mill_Cr_sp, Deer_Cr_sp, UpperSacramento_R_sp, Feather_H_fa, Butte_Cr_fa, Mill_Cr_fa, Deer_Cr_fa, Mokelumne_R_fa, Battle_Cr, Sacramento_R_lf, Sacramento_H, Eel_R, Russian_R, Klamath_IGH_fa, Trinity_H_sp, Smith_R, Chetco_R, Cole_Rivers_H, Applegate_Cr, Coquille_R, Umpqua_sp, Nestucca_H, Siuslaw_R, Alsea_R, Nehalem_R, Siletz_R, N_Santiam_H, McKenzie_H, L_Deschutes_R, Cowlitz_H_fa, Cowlitz_H_sp, Kalama_H_sp, Spring_Cr_H, Hanford_Reach, PriestRapids_H, Wells_H, Wenatchee_R, CleElum, Lyons_Ferry_H, Rapid_R_H, McCall_H, Kendall_H_sp, Forks_Cr_H, Soos_H, Marblemount_H_sp, QuinaltLake_f, Harris_R, Birkenhead_H, Spius_H, Big_Qual_H, Robertson_H, Morice_R, Kitwanga_R, L_Kalum_R, LPW_Unuk_R, Goat_Cr, Karluk_R, LittleTatsamenie, Tahini_R, Situk_R, Sinona_Ck, Montana_Ck, George_R, Kanektok_R, Togiak_R, Kantishna_R, California_Coho #>  #> 4.18% of allelic data identified as missing head(sa_chinook, n = 100) #> # A tibble: 100 × 11 #>    indiv             collection   repunit   inferred_collection inferred_repunit #>    <chr>             <chr>        <chr>     <chr>               <chr>            #>  1 Feather_H_sp:0001 Feather_H_sp CentralV… Feather_H_sp        CentralValleyfa  #>  2 Feather_H_sp:0001 Feather_H_sp CentralV… Feather_H_fa        CentralValleyfa  #>  3 Feather_H_sp:0001 Feather_H_sp CentralV… Butte_Cr_fa         CentralValleyfa  #>  4 Feather_H_sp:0001 Feather_H_sp CentralV… Mill_Cr_sp          CentralValleysp  #>  5 Feather_H_sp:0001 Feather_H_sp CentralV… Mill_Cr_fa          CentralValleyfa  #>  6 Feather_H_sp:0001 Feather_H_sp CentralV… UpperSacramento_R_… CentralValleysp  #>  7 Feather_H_sp:0001 Feather_H_sp CentralV… Deer_Cr_sp          CentralValleysp  #>  8 Feather_H_sp:0001 Feather_H_sp CentralV… Butte_Cr_Sp         CentralValleysp  #>  9 Feather_H_sp:0001 Feather_H_sp CentralV… Battle_Cr           CentralValleyfa  #> 10 Feather_H_sp:0001 Feather_H_sp CentralV… Mokelumne_R_fa      CentralValleyfa  #> # ℹ 90 more rows #> # ℹ 6 more variables: scaled_likelihood <dbl>, log_likelihood <dbl>, #> #   z_score <dbl>, n_non_miss_loci <int>, n_miss_loci <int>, #> #   missing_loci <list> sa_to_repu <- sa_chinook %>%   group_by(indiv, collection, repunit, inferred_repunit) %>%   summarise(repu_scaled_like = sum(scaled_likelihood)) #> `summarise()` has grouped output by 'indiv', 'collection', 'repunit'. You can #> override using the `.groups` argument.  head(sa_to_repu, n = 200) #> # A tibble: 200 × 5 #> # Groups:   indiv, collection, repunit [6] #>    indiv        collection repunit      inferred_repunit repu_scaled_like #>    <chr>        <chr>      <chr>        <chr>                       <dbl> #>  1 Alsea_R:0001 Alsea_R    NOregonCoast CaliforniaCoast          3.72e- 8 #>  2 Alsea_R:0001 Alsea_R    NOregonCoast CentralValleyfa          1.54e-14 #>  3 Alsea_R:0001 Alsea_R    NOregonCoast CentralValleysp          8.12e-15 #>  4 Alsea_R:0001 Alsea_R    NOregonCoast CentralValleywi          1.22e-23 #>  5 Alsea_R:0001 Alsea_R    NOregonCoast CohoSp                   2.09e-52 #>  6 Alsea_R:0001 Alsea_R    NOregonCoast CopperR                  3.08e-20 #>  7 Alsea_R:0001 Alsea_R    NOregonCoast DeschutesRfa             3.81e-10 #>  8 Alsea_R:0001 Alsea_R    NOregonCoast EVancouverIs             1.02e- 8 #>  9 Alsea_R:0001 Alsea_R    NOregonCoast KlamathR                 1.11e-11 #> 10 Alsea_R:0001 Alsea_R    NOregonCoast LColumbiaRfa             8.52e- 8 #> # ℹ 190 more rows"},{"path":"https://eriqande.github.io/rubias/index.html","id":"simulated-mixtures-using-a-leave-one-out-type-of-approach","dir":"","previous_headings":"","what":"Simulated mixtures using a leave-one-out type of approach","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"want know much accuracy can expect given set genetic markers grouping populations (collections) reporting units (repunits), two different functions might use: assess_reference_loo(): function carries simulation mixtures using leave-one-approach Anderson, Waples, Kalinowski (2008). assess_reference_mc(): functions breaks reference data set different subsets, one used reference data set mixture. difficult simulate large mixture samples using method, constrained number fish reference data set. Additionally, constraints mixing proportions can simulated variation number fish collection reference. functions take two required arguments: 1) data frame reference genetic data, 2) number column genetic data start. use chinook data simulate 50 mixture samples size 200 fish using default values (Dirichlet parameters 1.5 reporting unit, Dirichlet parameters 1.5 collection within reporting unit…) output looks like: columns : repunit_scenario integer gives repunit simulation parameters (see simulating multiple scenarios). collections_scenario integer gives collection simulation paramters (see simulating multiple scenarios). iter simulation number (1 reps) repunit reporting unit collection collection true_pi true simulated mixing proportion n actual number fish collection simulated mixture. post_mean_pi posterior mean mixing proportion. mle_pi maximum likelihood pi obtained using EM-algorithm.","code":"chin_sims <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 50,                       mixsize = 200) chin_sims #> # A tibble: 3,450 × 9 #>    repunit_scenario collection_scenario  iter repunit   collection true_pi     n #>    <chr>            <chr>               <int> <chr>     <chr>        <dbl> <dbl> #>  1 1                1                       1 CentralV… Feather_H… 8.42e-4     0 #>  2 1                1                       1 CentralV… Butte_Cr_… 6.55e-4     0 #>  3 1                1                       1 CentralV… Mill_Cr_sp 1.37e-3     0 #>  4 1                1                       1 CentralV… Deer_Cr_sp 4.41e-3     1 #>  5 1                1                       1 CentralV… UpperSacr… 6.25e-4     0 #>  6 1                1                       1 CentralV… Feather_H… 2.89e-3     2 #>  7 1                1                       1 CentralV… Butte_Cr_… 8.50e-4     0 #>  8 1                1                       1 CentralV… Mill_Cr_fa 2.86e-3     1 #>  9 1                1                       1 CentralV… Deer_Cr_fa 6.53e-3     0 #> 10 1                1                       1 CentralV… Mokelumne… 8.99e-4     0 #> # ℹ 3,440 more rows #> # ℹ 2 more variables: post_mean_pi <dbl>, mle_pi <dbl>"},{"path":"https://eriqande.github.io/rubias/index.html","id":"specifying-mixture-proportions-in-assess_reference_loo","dir":"","previous_headings":"","what":"Specifying mixture proportions in assess_reference_loo()","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"default, iteration, proportions fish reporting unit simulated Dirichlet distribution parameter (1.5,…,1.5). , within reporting unit mixing proportions different collections drawn Dirichlet distribution parameter (1.5,…,1.5). value 1.5 Dirichlet parameter reporting units can changed using alpha_repunit. Dirichlet parameter collections can set using alpha_collection parameter. Sometimes, however, control composition simulated mixtures desired. achieved passing two-column data.frame either alpha_repunit alpha_collection (). passing data.frame alpha_repunit, first column must named repunit must contain character vector specifying reporting units. data.frame alpha_collection first column must named collection must hold character vector specifying different collections. error repunit collection specified exist reference. However, need specify value every reporting unit collection. (absent, value assumed zero.) second column data frame must one count, ppn dirichlet. specify, respectively, exact count individuals simulated repunit (collection); proportion individuals repunit (collection). ppn values normalized sum one . , can regarded weights. parameters Dirichlet distribution proportion individuals simulated. Let’s say want simulate data roughly proportions like saw Chinook rec1 fishery. estimates variable top6: , put repprop values ppn column, simulate mixtures exactly proportions. wanted simulate exact numbers fish sample 347 fish, get values like : put cnts column. However, case, want simulate mixtures look similar one estimated, variation. want supply Dirichlet random variable paramaters column named dirichlet. make values proportional mixing proportions, , average . values large, little variation simulated mixtures. values small lots variation. ’ll scale sum 10—give variation, much. Accordingly tibble pass alpha_repunit parameter, describes variation reporting unit proportions like simulate look like : Let’s simulations repunit parameters. default, don’t specify anything extra collections, get dirichlet parameters 1.5. Now, can summarise output reporting unit… …plot values interested :  plot comparing “n” value, actual number fish reporting unit sample.","code":"top6 #> # A tibble: 6 × 3 #> # Groups:   mixture_collection [1] #>   mixture_collection repunit                 repprop #>   <chr>              <chr>                     <dbl> #> 1 rec1               CentralValleyfa         0.821   #> 2 rec1               KlamathR                0.0669  #> 3 rec1               RogueR                  0.0606  #> 4 rec1               CaliforniaCoast         0.0300  #> 5 rec1               NCaliforniaSOregonCoast 0.00923 #> 6 rec1               UColumbiaRsufa          0.00430 round(top6$repprop * 350) #> [1] 287  23  21  11   3   2 arep <- top6 %>%   ungroup() %>%   mutate(dirichlet = 10 * repprop) %>%   select(repunit, dirichlet)  arep #> # A tibble: 6 × 2 #>   repunit                 dirichlet #>   <chr>                       <dbl> #> 1 CentralValleyfa            8.21   #> 2 KlamathR                   0.669  #> 3 RogueR                     0.606  #> 4 CaliforniaCoast            0.300  #> 5 NCaliforniaSOregonCoast    0.0923 #> 6 UColumbiaRsufa             0.0430 chin_sims_repu_top6 <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 50,                       mixsize = 200,                      alpha_repunit = arep) # now, call those repunits that we did not specify in arep \"OTHER\" # and then sum up over reporting units tmp <- chin_sims_repu_top6 %>%   mutate(repunit = ifelse(repunit %in% arep$repunit, repunit, \"OTHER\")) %>%   group_by(iter, repunit) %>%   summarise(true_repprop = sum(true_pi),              reprop_posterior_mean = sum(post_mean_pi),             repu_n = sum(n)) %>%   mutate(repu_n_prop = repu_n / sum(repu_n)) #> `summarise()` has grouped output by 'iter'. You can override using the #> `.groups` argument. # then plot them ggplot(tmp, aes(x = true_repprop, y = reprop_posterior_mean, colour = repunit)) +   geom_point() +   geom_abline(intercept = 0, slope = 1) +   facet_wrap(~ repunit) ggplot(tmp, aes(x = repu_n_prop, y = reprop_posterior_mean, colour = repunit)) +   geom_point() +   geom_abline(intercept = 0, slope = 1) +   facet_wrap(~ repunit)"},{"path":"https://eriqande.github.io/rubias/index.html","id":"retrieving-the-individual-simulated-fish-posteriors","dir":"","previous_headings":"","what":"Retrieving the individual simulated fish posteriors","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"Quite often might curious much can expect able trust posterior individual fish mixture like . can retrieve posteriors computed fish simulated assess_reference_loo() using return_indiv_posteriors option. , function returns list components mixture_proportions (holds tibble like chin_sims_repu_top6 previous section) indiv_posteriors, holds posteriors (PofZs) simulated individuals. tibble: - indiv integer specifier simulated individual - simulated_repunit reporting unit individual simulated - simulated_collection collection simulated genotype came - PofZ mean MCMC posterior probability individual originated collection. Now done , can see distribution posteriors correct reporting unit fish different simulated collections. ’ll boxplot, coloring repunit:  Great. helpful.","code":"set.seed(100) chin_sims_with_indivs <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 50,                       mixsize = 200,                      alpha_repunit = arep,                      return_indiv_posteriors = TRUE) #> Warning: `as.tibble()` was deprecated in tibble 2.0.0. #> ℹ Please use `as_tibble()` instead. #> ℹ The signature and semantics have changed, see `?as_tibble`. #> ℹ The deprecated feature was likely used in the rubias package. #>   Please report the issue at <https://github.com/eriqande/rubias/issues>. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated.  # print out the indiv posteriors chin_sims_with_indivs$indiv_posteriors #> # A tibble: 690,000 × 9 #>    repunit_scenario collection_scenario  iter indiv simulated_repunit #>    <chr>            <chr>               <int> <int> <chr>             #>  1 1                1                       1     1 CentralValleyfa   #>  2 1                1                       1     1 CentralValleyfa   #>  3 1                1                       1     1 CentralValleyfa   #>  4 1                1                       1     1 CentralValleyfa   #>  5 1                1                       1     1 CentralValleyfa   #>  6 1                1                       1     1 CentralValleyfa   #>  7 1                1                       1     1 CentralValleyfa   #>  8 1                1                       1     1 CentralValleyfa   #>  9 1                1                       1     1 CentralValleyfa   #> 10 1                1                       1     1 CentralValleyfa   #> # ℹ 689,990 more rows #> # ℹ 4 more variables: simulated_collection <chr>, repunit <chr>, #> #   collection <chr>, PofZ <dbl> # summarise things repu_pofzs <- chin_sims_with_indivs$indiv_posteriors %>%   filter(repunit == simulated_repunit) %>%   group_by(iter, indiv, simulated_collection, repunit) %>%  # first aggregate over reporting units   summarise(repu_PofZ = sum(PofZ)) %>%   ungroup() %>%   arrange(repunit, simulated_collection) %>%   mutate(simulated_collection = factor(simulated_collection, levels = unique(simulated_collection))) #> `summarise()` has grouped output by 'iter', 'indiv', 'simulated_collection'. #> You can override using the `.groups` argument.  # also get the number of simulated individuals from each collection num_simmed <- chin_sims_with_indivs$indiv_posteriors %>%   group_by(iter, indiv) %>%   slice(1) %>%   ungroup() %>%   count(simulated_collection)    # note, the last few steps make simulated collection a factor so that collections within # the same repunit are grouped together in the plot.  # now, plot it ggplot(repu_pofzs, aes(x = simulated_collection, y = repu_PofZ)) +   geom_boxplot(aes(colour = repunit)) +   geom_text(data = num_simmed, mapping = aes(y = 1.025, label = n), angle = 90, hjust = 0, vjust = 0.5, size = 3) +    theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 9, vjust = 0.5)) +   ylim(c(NA, 1.05))"},{"path":"https://eriqande.github.io/rubias/index.html","id":"changing-the-resampling-unit","dir":"","previous_headings":"","what":"Changing the resampling unit","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"default, individuals simulated assess_reference_loo() resampling full multilocus genotypes. tends realistic, includes missing simulations missing data individuals reference. However, genes individuals incorrectly placed reference stay together, individual might low value PofZ population simulated . Due latter issue, might also yield pessimistic assessment’ power GSI. alternative resample gene copies—CV-GC method Anderson, Waples, Kalinowski (2008). Let us see simulated PofZ results change. simulations… process output plot :  , find somewhat fewer fish low posteriors, still . reminds us dataset, (rather) occasionally possible get individuals carrying genotypes make difficult correctly assign reporting unit.","code":"set.seed(101) # for reproducibility # do the simulation chin_sims_by_gc <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 50,                       mixsize = 200,                      alpha_repunit = arep,                      return_indiv_posteriors = TRUE,                      resampling_unit = \"gene_copies\") # summarise things repu_pofzs_gc <- chin_sims_by_gc$indiv_posteriors %>%   filter(repunit == simulated_repunit) %>%   group_by(iter, indiv, simulated_collection, repunit) %>%  # first aggregate over reporting units   summarise(repu_PofZ = sum(PofZ)) %>%   ungroup() %>%   arrange(repunit, simulated_collection) %>%   mutate(simulated_collection = factor(simulated_collection, levels = unique(simulated_collection))) #> `summarise()` has grouped output by 'iter', 'indiv', 'simulated_collection'. #> You can override using the `.groups` argument.  # also get the number of simulated individuals from each collection num_simmed_gc <- chin_sims_by_gc$indiv_posteriors %>%   group_by(iter, indiv) %>%   slice(1) %>%   ungroup() %>%   count(simulated_collection)    # note, the last few steps make simulated collection a factor so that collections within # the same repunit are grouped together in the plot.  # now, plot it ggplot(repu_pofzs_gc, aes(x = simulated_collection, y = repu_PofZ)) +   geom_boxplot(aes(colour = repunit)) +   geom_text(data = num_simmed_gc, mapping = aes(y = 1.025, label = n), angle = 90, hjust = 0, vjust = 0.5, size = 3) +    theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 9, vjust = 0.5)) +   ylim(c(NA, 1.05))"},{"path":"https://eriqande.github.io/rubias/index.html","id":"sub-specifying-collection-proportions-or-dirichlet-parameters","dir":"","previous_headings":"","what":"“sub-specifying” collection proportions or dirichlet parameters","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"simulating reporting unit proportions numbers, want control collections fish simulated , within reporting units, sub_ppn sub_dirichlet settings . given column names alpha_collection data frame. example, let’s say want simulate reporting unit proportions , using arep : , now, let’s say within reporting unit want specific weights different collections. specify , example, like : Collections listed given equal proportions within repunits collections listed. However, collection listed, collections within repunit , simulated proportion zero. (Technically, zero, small—like 10−810^{-8} effectively 0…made coding lot easier…) Now, can simulate see resulting proportion fish collection : Now observe average proportions collections repunits simulated, average fraction, within reporting units collection","code":"arep #> # A tibble: 6 × 2 #>   repunit                 dirichlet #>   <chr>                       <dbl> #> 1 CentralValleyfa            8.21   #> 2 KlamathR                   0.669  #> 3 RogueR                     0.606  #> 4 CaliforniaCoast            0.300  #> 5 NCaliforniaSOregonCoast    0.0923 #> 6 UColumbiaRsufa             0.0430 arep_subs <- tribble(   ~collection, ~sub_ppn,   \"Eel_R\",   0.1,   \"Russian_R\", 0.9,   \"Butte_Cr_fa\", 0.7,   \"Feather_H_sp\", 0.3 ) chin_sims_sub_ppn <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 50,                       mixsize = 200,                      alpha_repunit = arep,                      alpha_collection = arep_subs,                      return_indiv_posteriors = FALSE)  # don't bother returning individual posteriors chin_sims_sub_ppn %>%   group_by(repunit, collection) %>%   summarise(mean_pi = mean(true_pi)) %>%   group_by(repunit) %>%   mutate(repunit_mean_pi = sum(mean_pi),          fract_within = mean_pi / repunit_mean_pi) %>%   mutate(fract_within = ifelse(fract_within < 1e-06, 0, fract_within))  %>% # anything less than 1 in a million gets called 0   filter(repunit_mean_pi > 0.0) #> `summarise()` has grouped output by 'repunit'. You can override using the #> `.groups` argument. #> # A tibble: 20 × 5 #> # Groups:   repunit [6] #>    repunit                 collection       mean_pi repunit_mean_pi fract_within #>    <chr>                   <chr>              <dbl>           <dbl>        <dbl> #>  1 CaliforniaCoast         Eel_R            3.65e-3          0.0365        0.1   #>  2 CaliforniaCoast         Russian_R        3.29e-2          0.0365        0.9   #>  3 CentralValleyfa         Battle_Cr        8.25e-8          0.825         0     #>  4 CentralValleyfa         Butte_Cr_fa      5.77e-1          0.825         0.700 #>  5 CentralValleyfa         Deer_Cr_fa       8.25e-8          0.825         0     #>  6 CentralValleyfa         Feather_H_fa     8.25e-8          0.825         0     #>  7 CentralValleyfa         Feather_H_sp     2.47e-1          0.825         0.300 #>  8 CentralValleyfa         Mill_Cr_fa       8.25e-8          0.825         0     #>  9 CentralValleyfa         Mokelumne_R_fa   8.25e-8          0.825         0     #> 10 CentralValleyfa         Sacramento_R_lf  8.25e-8          0.825         0     #> 11 KlamathR                Klamath_IGH_fa   3.07e-2          0.0613        0.5   #> 12 KlamathR                Trinity_H_sp     3.07e-2          0.0613        0.5   #> 13 NCaliforniaSOregonCoast Chetco_R         5.77e-3          0.0115        0.5   #> 14 NCaliforniaSOregonCoast Smith_R          5.77e-3          0.0115        0.5   #> 15 RogueR                  Applegate_Cr     2.78e-2          0.0557        0.5   #> 16 RogueR                  Cole_Rivers_H    2.78e-2          0.0557        0.5   #> 17 UColumbiaRsufa          Hanford_Reach    2.59e-3          0.0104        0.25  #> 18 UColumbiaRsufa          PriestRapids_H   2.59e-3          0.0104        0.25  #> 19 UColumbiaRsufa          Wells_H          2.59e-3          0.0104        0.25  #> 20 UColumbiaRsufa          Wenatchee_R      2.59e-3          0.0104        0.25"},{"path":"https://eriqande.github.io/rubias/index.html","id":"multiple-simulation-scenarios-and-100-simulations","dir":"","previous_headings":"","what":"Multiple simulation scenarios and “100% Simulations”","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"fisheries world, “100% simulations” staple. simulations, mixtures simulated 100% individuals one collection (reporting unit, suppose). Eric never big fan since don’t necessarily tell might inferring actual mixtures might encounter. Nonetheless, since mainstay field, worthwile showing 100% simulations using rubias. Furthermore, people asked feature made clear Eric provide way simulate multiple different scenarios without re-processing reference data set time. came : way pass list scenarios alpha_repunit alpha_collection option assess_reference_loo(). can named lists, desired. , example, let’s 100% simulations repunits arep: let collections within just drawn dirichlet distribution parameter 10 (, pretty close equal proportions). , , make list data frames proportions. ’ll give names : , use , producing 5 replicates scenario:","code":"arep$repunit #> [1] \"CentralValleyfa\"         \"KlamathR\"                #> [3] \"RogueR\"                  \"CaliforniaCoast\"         #> [5] \"NCaliforniaSOregonCoast\" \"UColumbiaRsufa\" six_hundy_scenarios <- lapply(arep$repunit, function(x) tibble(repunit = x, ppn = 1.0)) names(six_hundy_scenarios) <- paste(\"All\", arep$repunit, sep = \"-\") repu_hundy_results <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 5,                       mixsize = 50,                      alpha_repunit = six_hundy_scenarios,                      alpha_collection = 10) #> ++++ Starting in on repunit_scenario All-CentralValleyfa with collection scenario 1 ++++ #> Doing LOO simulations rep 1 of 5 #> Doing LOO simulations rep 2 of 5 #> Doing LOO simulations rep 3 of 5 #> Doing LOO simulations rep 4 of 5 #> Doing LOO simulations rep 5 of 5 #> ++++ Starting in on repunit_scenario All-KlamathR with collection scenario 1 ++++ #> Doing LOO simulations rep 1 of 5 #> Doing LOO simulations rep 2 of 5 #> Doing LOO simulations rep 3 of 5 #> Doing LOO simulations rep 4 of 5 #> Doing LOO simulations rep 5 of 5 #> ++++ Starting in on repunit_scenario All-RogueR with collection scenario 1 ++++ #> Doing LOO simulations rep 1 of 5 #> Doing LOO simulations rep 2 of 5 #> Doing LOO simulations rep 3 of 5 #> Doing LOO simulations rep 4 of 5 #> Doing LOO simulations rep 5 of 5 #> ++++ Starting in on repunit_scenario All-CaliforniaCoast with collection scenario 1 ++++ #> Doing LOO simulations rep 1 of 5 #> Doing LOO simulations rep 2 of 5 #> Doing LOO simulations rep 3 of 5 #> Doing LOO simulations rep 4 of 5 #> Doing LOO simulations rep 5 of 5 #> ++++ Starting in on repunit_scenario All-NCaliforniaSOregonCoast with collection scenario 1 ++++ #> Doing LOO simulations rep 1 of 5 #> Doing LOO simulations rep 2 of 5 #> Doing LOO simulations rep 3 of 5 #> Doing LOO simulations rep 4 of 5 #> Doing LOO simulations rep 5 of 5 #> ++++ Starting in on repunit_scenario All-UColumbiaRsufa with collection scenario 1 ++++ #> Doing LOO simulations rep 1 of 5 #> Doing LOO simulations rep 2 of 5 #> Doing LOO simulations rep 3 of 5 #> Doing LOO simulations rep 4 of 5 #> Doing LOO simulations rep 5 of 5 repu_hundy_results #> # A tibble: 2,070 × 9 #>    repunit_scenario   collection_scenario  iter repunit collection true_pi     n #>    <chr>              <chr>               <int> <chr>   <chr>        <dbl> <dbl> #>  1 All-CentralValley… 1                       1 Centra… Feather_H…   0.100     5 #>  2 All-CentralValley… 1                       1 Centra… Butte_Cr_…   0         0 #>  3 All-CentralValley… 1                       1 Centra… Mill_Cr_sp   0         0 #>  4 All-CentralValley… 1                       1 Centra… Deer_Cr_sp   0         0 #>  5 All-CentralValley… 1                       1 Centra… UpperSacr…   0         0 #>  6 All-CentralValley… 1                       1 Centra… Feather_H…   0.141     5 #>  7 All-CentralValley… 1                       1 Centra… Butte_Cr_…   0.100     5 #>  8 All-CentralValley… 1                       1 Centra… Mill_Cr_fa   0.140     5 #>  9 All-CentralValley… 1                       1 Centra… Deer_Cr_fa   0.193    14 #> 10 All-CentralValley… 1                       1 Centra… Mokelumne…   0.102     5 #> # ℹ 2,060 more rows #> # ℹ 2 more variables: post_mean_pi <dbl>, mle_pi <dbl>"},{"path":"https://eriqande.github.io/rubias/index.html","id":"do-it-again-with-100-collections","dir":"","previous_headings":"Multiple simulation scenarios and “100% Simulations”","what":"Do it again with 100% collections","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"Just make sure clear collections (rather reporting units) well, lets 100% simulations handful collections. Let’s just randomly take 5 , 6 reps : , now make list 100% specifications tibbles: , :","code":"set.seed(10) hundy_colls <- sample(unique(chinook$collection), 5) hundy_colls #> [1] \"Deer_Cr_fa\"  \"Kitwanga_R\"  \"Morice_R\"    \"Wenatchee_R\" \"Russian_R\" hundy_coll_list <- lapply(hundy_colls, function(x) tibble(collection = x, ppn = 1.0)) %>%   setNames(paste(\"100%\", hundy_colls, sep = \"_\")) hundy_coll_results <- assess_reference_loo(reference = chinook,                       gen_start_col = 5,                       reps = 6,                       mixsize = 50,                      alpha_collection = hundy_coll_list) hundy_coll_results #> # A tibble: 2,070 × 9 #>    repunit_scenario collection_scenario  iter repunit   collection true_pi     n #>    <chr>            <chr>               <int> <chr>     <chr>        <dbl> <dbl> #>  1 1                100%_Deer_Cr_fa         1 CentralV… Feather_H…       0     0 #>  2 1                100%_Deer_Cr_fa         1 CentralV… Butte_Cr_…       0     0 #>  3 1                100%_Deer_Cr_fa         1 CentralV… Mill_Cr_sp       0     0 #>  4 1                100%_Deer_Cr_fa         1 CentralV… Deer_Cr_sp       0     0 #>  5 1                100%_Deer_Cr_fa         1 CentralV… UpperSacr…       0     0 #>  6 1                100%_Deer_Cr_fa         1 CentralV… Feather_H…       0     0 #>  7 1                100%_Deer_Cr_fa         1 CentralV… Butte_Cr_…       0     0 #>  8 1                100%_Deer_Cr_fa         1 CentralV… Mill_Cr_fa       0     0 #>  9 1                100%_Deer_Cr_fa         1 CentralV… Deer_Cr_fa       1    50 #> 10 1                100%_Deer_Cr_fa         1 CentralV… Mokelumne…       0     0 #> # ℹ 2,060 more rows #> # ℹ 2 more variables: post_mean_pi <dbl>, mle_pi <dbl>"},{"path":"https://eriqande.github.io/rubias/index.html","id":"bootstrap-corrected-reporting-unit-proportions","dir":"","previous_headings":"","what":"Bootstrap-Corrected Reporting Unit Proportions","title":"Bayesian Inference from the Conditional Genetic Stock Identification Model","text":"obtained using method = \"PB\" infer_mixture(). invoked, return regular MCMC results , also population bootstrapped_proportions field output. takes little bit longer, computationally, good deal simulation involved: now can compare estimates, showing 10 prevalent repunits, rec1 fishery: gives us result expect: appreciable difference, reporting units already well resolved, don’t expect parametric bootstrap procedure find benefit correcting .","code":"mix_est_pb <- infer_mixture(reference = chinook,                           mixture = chinook_mix,                           gen_start_col = 5,                          method = \"PB\") mix_est_pb$mixing_proportions %>%   group_by(mixture_collection, repunit) %>%   summarise(repprop = sum(pi)) %>%   left_join(mix_est_pb$bootstrapped_proportions) %>%   ungroup() %>%   filter(mixture_collection == \"rec1\") %>%   arrange(desc(repprop)) %>%   slice(1:10)"},{"path":[]},{"path":"https://eriqande.github.io/rubias/reference/Hasselman_sim_colls.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a random population structure and mixture sample, as in Hasselman et al. 2015 — Hasselman_sim_colls","title":"Generate a random population structure and mixture sample, as in Hasselman et al. 2015 — Hasselman_sim_colls","text":"Creates random reporting unit (rho) collection (omega) proportions, sim_colls vector simulation individual genotypes, based methods used Hasselman et al. (2015)","code":""},{"path":"https://eriqande.github.io/rubias/reference/Hasselman_sim_colls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a random population structure and mixture sample, as in Hasselman et al. 2015 — Hasselman_sim_colls","text":"","code":"Hasselman_sim_colls(RU_starts, RU_vec, size = 100)"},{"path":"https://eriqande.github.io/rubias/reference/Hasselman_sim_colls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a random population structure and mixture sample, as in Hasselman et al. 2015 — Hasselman_sim_colls","text":"RU_starts vector delineating reporting units RU_vec; generated tcf2param_list RU_vec vector collection indices, grouped reporting unit; generated tcf2param_list","code":""},{"path":"https://eriqande.github.io/rubias/reference/Hasselman_sim_colls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a random population structure and mixture sample, as in Hasselman et al. 2015 — Hasselman_sim_colls","text":"Hasselman_sim_colls returns list three elements. first two rho vector omega vector, respectively, alpha parameters = 1.5. third vector origins simulated individuals, sampled collections probabilities = omega","code":""},{"path":"https://eriqande.github.io/rubias/reference/Hasselman_sim_colls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate a random population structure and mixture sample, as in Hasselman et al. 2015 — Hasselman_sim_colls","text":"function designed specifically recreate simulations Hasselman et al. (2015), check bias observed therein. Rho (reporting unit proportions) chosen alphas 1.5, omega (collection proportions) chosen alpha, scaled corresponding rho.","code":""},{"path":"https://eriqande.github.io/rubias/reference/a_freq_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert data frame of allele frequencies to nested lists — a_freq_list","title":"Convert data frame of allele frequencies to nested lists — a_freq_list","text":"List-izes output reference_allele_counts usable format allelic_list","code":""},{"path":"https://eriqande.github.io/rubias/reference/a_freq_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert data frame of allele frequencies to nested lists — a_freq_list","text":"","code":"a_freq_list(D, pop_level = \"collection\")"},{"path":"https://eriqande.github.io/rubias/reference/a_freq_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert data frame of allele frequencies to nested lists — a_freq_list","text":"D long-format dataframe counts collection, locus, allele, output reference_allele_counts, made nested list","code":""},{"path":"https://eriqande.github.io/rubias/reference/a_freq_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert data frame of allele frequencies to nested lists — a_freq_list","text":"a_freq_list returns list named loci, element matrix containing locus's allele count data. Rows matrix mark alleles, columns collections","code":""},{"path":"https://eriqande.github.io/rubias/reference/a_freq_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert data frame of allele frequencies to nested lists — a_freq_list","text":"","code":"# Generate a list of individual genotypes by allele from  # the alewife data's reference allele count tables  example(reference_allele_counts) #>  #> rfrn__> ## count alleles in alewife reference populations #> rfrn__> example(tcf2long)  # gets variable ale_long #>  #> tcf2ln> ## Convert the alewife dataset for further processing #> tcf2ln> # the data frame passed into this function must have had #> tcf2ln> # character collections and repunits converted to factors #> tcf2ln> reference <- alewife #>  #> tcf2ln> reference$repunit <- factor(reference$repunit, levels = unique(reference$repunit)) #>  #> tcf2ln> reference$collection <- factor(reference$collection, levels = unique(reference$collection)) #>  #> tcf2ln> ale_long <- tcf2long(reference, 17) #>  #> rfrn__> ale_rac <- reference_allele_counts(ale_long$long)  ale_ac <- a_freq_list(ale_rac)"},{"path":"https://eriqande.github.io/rubias/reference/alewife.html","id":null,"dir":"Reference","previous_headings":"","what":"Microsat data from alewife herring reference populations — alewife","title":"Microsat data from alewife herring reference populations — alewife","text":"Standard two-column genetic data lots columns preceding . Can fed directly rubias least columns sample_type, collection, repunit indiv.","code":""},{"path":"https://eriqande.github.io/rubias/reference/alewife.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Microsat data from alewife herring reference populations — alewife","text":"tibble.","code":""},{"path":"https://eriqande.github.io/rubias/reference/alewife.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Microsat data from alewife herring reference populations — alewife","text":"https://datadryad.org/dataset/doi:10.5061/dryad.80f4f","code":""},{"path":"https://eriqande.github.io/rubias/reference/allelic_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Create genotype lists for each locus — allelic_list","title":"Create genotype lists for each locus — allelic_list","text":"Uses allele counts a_freq_list cleaned short-format output tcf2long generate nested list individual genotypes locus","code":""},{"path":"https://eriqande.github.io/rubias/reference/allelic_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create genotype lists for each locus — allelic_list","text":"","code":"allelic_list(cs, ac, samp_type = \"both\")"},{"path":"https://eriqande.github.io/rubias/reference/allelic_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create genotype lists for each locus — allelic_list","text":"cs clean short genetic data matrix; second element output tcf2long. Must column individual identifiers, named \"indiv\" ac allele counts a_freq_list samp_type choose sample types individuals include output: \"mixture\", \"\", \"reference\"","code":""},{"path":"https://eriqande.github.io/rubias/reference/allelic_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create genotype lists for each locus — allelic_list","text":"allelic_list returns two-component nested list, data stored character names alleles ($chr) integer indices alleles ($int). forms contain lists representing loci, two component vectors corresponding gene copies b.","code":""},{"path":"https://eriqande.github.io/rubias/reference/allelic_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create genotype lists for each locus — allelic_list","text":"","code":"example(a_freq_list) #>  #> a_frq_>  # Generate a list of individual genotypes by allele from #> a_frq_>  # the alewife data's reference allele count tables #> a_frq_>  example(reference_allele_counts) #>  #> rfrn__> ## count alleles in alewife reference populations #> rfrn__> example(tcf2long)  # gets variable ale_long #>  #> tcf2ln> ## Convert the alewife dataset for further processing #> tcf2ln> # the data frame passed into this function must have had #> tcf2ln> # character collections and repunits converted to factors #> tcf2ln> reference <- alewife #>  #> tcf2ln> reference$repunit <- factor(reference$repunit, levels = unique(reference$repunit)) #>  #> tcf2ln> reference$collection <- factor(reference$collection, levels = unique(reference$collection)) #>  #> tcf2ln> ale_long <- tcf2long(reference, 17) #>  #> rfrn__> ale_rac <- reference_allele_counts(ale_long$long) #>  #> a_frq_>  ale_ac <- a_freq_list(ale_rac) ale_cs <- ale_long$clean_short # Get the vectors of gene copies a and b for all loci in integer index form ale_alle_list <- allelic_list(ale_cs, ale_ac)$int"},{"path":"https://eriqande.github.io/rubias/reference/assess_pb_bias_correction.html","id":null,"dir":"Reference","previous_headings":"","what":"Test the effects of the parametric bootstrap bias correction on a reference dataset through cross-validation — assess_pb_bias_correction","title":"Test the effects of the parametric bootstrap bias correction on a reference dataset through cross-validation — assess_pb_bias_correction","text":"rewrite bias_comparison().  Eric want plotting wrapped function, wanted return informative data frame.","code":""},{"path":"https://eriqande.github.io/rubias/reference/assess_pb_bias_correction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Test the effects of the parametric bootstrap bias correction on a reference dataset through cross-validation — assess_pb_bias_correction","text":"","code":"assess_pb_bias_correction(   reference,   gen_start_col,   seed = 5,   nreps = 50,   mixsize = 100,   alle_freq_prior = list(const_scaled = 1) )"},{"path":"https://eriqande.github.io/rubias/reference/assess_pb_bias_correction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Test the effects of the parametric bootstrap bias correction on a reference dataset through cross-validation — assess_pb_bias_correction","text":"reference two-column format genetic dataset, \"repunit\" column specifying individual's reporting unit origin, \"collection\" column specifying collection (population time sampling) \"indiv\" providing unique name gen_start_col first column containing genetic data reference. columns genetic format following column, gene copies locus adjacent seed random seed simulations nreps number reps . mixsize size simulated mixture sample. alle_freq_prior one-element named list specifying prior used generating Dirichlet parameters genotype likelihood calculations. Valid methods include \"const\", \"scaled_const\", \"empirical\". See ?list_diploid_params method details.","code":""},{"path":"https://eriqande.github.io/rubias/reference/assess_pb_bias_correction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Test the effects of the parametric bootstrap bias correction on a reference dataset through cross-validation — assess_pb_bias_correction","text":"bias_comparison returns list; first element list relevant rho values generated iteration random \"mixture\" creation. includes true rho value, standard result rho_mcmc, parametric bootstrapped rho_pb. second element dataframe listing summary statistics reporting unit estimation method. mse, mean squared error, summarizes deviation rho estimates true value, including bias variance. mean_prop_bias average ratio residual true value, gives greater weight deviations smaller values. mean_bias simply average residual; unlike mse, demonstrates direction bias.","code":""},{"path":"https://eriqande.github.io/rubias/reference/assess_pb_bias_correction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Test the effects of the parametric bootstrap bias correction on a reference dataset through cross-validation — assess_pb_bias_correction","text":"Takes reference two-column genetic dataset, pulls series random \"mixture\" datasets varying reporting unit proportions reference, compares results GSI standard MCMC vs. parametric-bootstrap MCMC bias correction amount bias reporting unit proportion calculations increases rate misassignment reporting units (decreases genetic differentiation), increases number collections within reporting units becomes uneven. Output standard Bayesian MCMC method demonstrates level bias expected input data set, parametric bootstrapping empirical method removal existing bias.","code":""},{"path":"https://eriqande.github.io/rubias/reference/assess_pb_bias_correction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Test the effects of the parametric bootstrap bias correction on a reference dataset through cross-validation — assess_pb_bias_correction","text":"","code":"if (FALSE) { # \\dontrun{ ## This takes too long to run in R CMD CHECK ale_bias <- assess_pb_bias_correction(alewife, 17) } # }"},{"path":"https://eriqande.github.io/rubias/reference/assess_reference_loo.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate mixtures and estimate reporting group and collection proportions. — assess_reference_loo","title":"Simulate mixtures and estimate reporting group and collection proportions. — assess_reference_loo","text":"reference dataset, creates genotype-logL matrix based simulation--individual randomly drawn population proportions, uses two different estimates population mixture proportions: maximum likelihood via EM-algorithm posterior mean MCMC.","code":""},{"path":"https://eriqande.github.io/rubias/reference/assess_reference_loo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate mixtures and estimate reporting group and collection proportions. — assess_reference_loo","text":"","code":"assess_reference_loo(   reference,   gen_start_col,   reps = 50,   mixsize = 100,   seed = 5,   alpha_repunit = 1.5,   alpha_collection = 1.5,   resampling_unit = \"individual\",   alle_freq_prior = list(const_scaled = 1),   printSummary = FALSE,   return_indiv_posteriors = FALSE )"},{"path":"https://eriqande.github.io/rubias/reference/assess_reference_loo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate mixtures and estimate reporting group and collection proportions. — assess_reference_loo","text":"reference two-column format genetic dataset, \"repunit\", \"collection\", \"indiv\" columns, well \"sample_type\" column \"reference\" entries gen_start_col first column genetic data reference reps number reps mixture simulation MCMC mixsize number individuals simulated mixture seed random seed simulations alpha_repunit vector, dirichlet parameter simulating proportions reporting units. Gets recycled number reporting units. Default 1.5. Otherwise, two-column data frame.  first column must named \"repunit\" second one must one \"dirichlet\", \"ppn\", \"cnt\", according whether wish specify dirichlet parameters, proportions, exact counts, respectively, population. want make multiple simulations, pass list data frames individual dirichlet parameters. examples, see sim_spec_examples. alpha_collection dirichlet parameter simulating proportions collections within reporting units. Default = 1.5. data frame first column must \"collection\" second must one \"dirichlet\", \"ppn\", \"cnt\", \"sub_dirichlet\", \"sub_ppn\".  want provide multiple different scenarios.  can pass list.  alpha_repunit alpha_collection list length greater 1, shorter recycled. examples, see sim_spec_examples. resampling_unit unit resampled.  Currently choices \"individuals\" (default) \"gene_copies\".  Using \"individuals\" preserves missing data patterns available reference data set. also \"gene_copies_with_missing\" capability, yet linked function. alle_freq_prior one-element named list specifying prior used generating Dirichlet parameters genotype likelihood calculations. Valid methods include \"const\", \"scaled_const\", \"empirical\". See ?list_diploid_params method details. printSummary TRUE summary reference samples printed stdout. return_indiv_posteriors TRUE, output list 2. first entry, mixing_proportions, contains true (simulated) estimated mixture proportions scenario, iteration, collection. second, indiv_posteriors, contains posterior probability assignment collection scenario, iteration, individual. FALSE, output single data frame, mixing_proportions","code":""},{"path":"https://eriqande.github.io/rubias/reference/assess_reference_loo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate mixtures and estimate reporting group and collection proportions. — assess_reference_loo","text":"","code":"# very small number of reps so it is quick enough for example ale_dev <- assess_reference_loo(alewife, 17, reps = 5) #> ++++ Starting in on repunit_scenario 1 with collection scenario 1 ++++ #> Doing LOO simulations rep 1 of 5 #> Doing LOO simulations rep 2 of 5 #> Doing LOO simulations rep 3 of 5 #> Doing LOO simulations rep 4 of 5 #> Doing LOO simulations rep 5 of 5"},{"path":"https://eriqande.github.io/rubias/reference/assess_reference_mc.html","id":null,"dir":"Reference","previous_headings":"","what":"Partition a reference dataset and estimate reporting group and collection proportions — assess_reference_mc","title":"Partition a reference dataset and estimate reporting group and collection proportions — assess_reference_mc","text":"reference dataset, draws (without replacement) simulated mixture dataset randomly drawn population proportions, uses two different estimates population mixture proportions: maximum likelihood via EM-algorithm posterior mean MCMC.","code":""},{"path":"https://eriqande.github.io/rubias/reference/assess_reference_mc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partition a reference dataset and estimate reporting group and collection proportions — assess_reference_mc","text":"","code":"assess_reference_mc(   reference,   gen_start_col,   reps = 50,   mixsize = 100,   seed = 5,   alpha_repunit = 1.5,   alpha_collection = 1.5,   min_remaining = 5,   alle_freq_prior = list(const_scaled = 1) )"},{"path":"https://eriqande.github.io/rubias/reference/assess_reference_mc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partition a reference dataset and estimate reporting group and collection proportions — assess_reference_mc","text":"reference two-column format genetic dataset, \"repunit\", \"collection\", \"indiv\" columns, well \"sample_type\" column \"reference\" entries. gen_start_col first column genetic data reference reps number reps mixsize number individuals simulated mixture. seed random seed simulations alpha_repunit dirichlet parameter simulating proportions reporting units. Default = 1.5 alpha_collection dirichlet parameter simulating proportions collections within reporting units. Default = 1.5 min_remaining minimum number individuals conserved reference collection sampling without replacement form simulated mixture alle_freq_prior one-element named list specifying prior used generating Dirichlet parameters genotype likelihood calculations. Valid methods include \"const\", \"scaled_const\", \"empirical\". See ?list_diploid_params method details.","code":""},{"path":"https://eriqande.github.io/rubias/reference/assess_reference_mc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Partition a reference dataset and estimate reporting group and collection proportions — assess_reference_mc","text":"method referred \"Monte Carlo cross-validation\". input parameters assess_reference_mc restrictive assess_reference_loo. Rather allowing data.frame specify Dirichlet parameters, proportions, counts specific reporting units collections, assess_reference_mc allows vector input (default = 1.5) alpha_repunit alpha_collection. inputs specify uniform Dirichlet parameters reporting units collections, respectively. mixture proportion generation, rho values first drawn using stick-breaking model Dirichlet distribution, proportions capped min_remaining. Stick-breaking used subdivide reporting unit collections. addition constraint mixture sampling without replacement deplete number individuals collection min_remaining, similar constraint placed upon number individuals left reporting units, determined min_remaining * (# collections reporting unit). Note implies data truly Dirichlet distributed rejections based min_remaining occur. reasonable certainty sufficient reference collection sizes relative desired mixture size.","code":""},{"path":"https://eriqande.github.io/rubias/reference/assess_reference_mc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partition a reference dataset and estimate reporting group and collection proportions — assess_reference_mc","text":"","code":"# only 5 reps, so it doesn't take too long.  Typically you would # do many more ale_dev <- assess_reference_mc(alewife, 17, 5)"},{"path":"https://eriqande.github.io/rubias/reference/avg_coll2correctRU.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the average within-RU assignment rate for each collection — avg_coll2correctRU","title":"Get the average within-RU assignment rate for each collection — avg_coll2correctRU","text":"function takes matrix scaled genotype likelihoods group individuals known origin, calculates average rate individuals particular collection assigned correct reporting unit.","code":""},{"path":"https://eriqande.github.io/rubias/reference/avg_coll2correctRU.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the average within-RU assignment rate for each collection — avg_coll2correctRU","text":"","code":"avg_coll2correctRU(SL, coll, RU_starts, RU_vec)"},{"path":"https://eriqande.github.io/rubias/reference/avg_coll2correctRU.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the average within-RU assignment rate for each collection — avg_coll2correctRU","text":"SL scaled likelihood matrix; column sum one, represent probability assignments collection (row) particular individual coll vector collection origin indices individuals (length = ncol(SL)) RU_starts vector delineating starting indices different reporting units RU_vec RU_vec vector collection indices, organized reporting unit","code":""},{"path":"https://eriqande.github.io/rubias/reference/avg_coll2correctRU.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the average within-RU assignment rate for each collection — avg_coll2correctRU","text":"avg_coll2correctRU returns vector length nrow(SL), element represents average proportion fish corresponding collection correctly assigned proper collection, misassigned another collection within reporting unit. distinct rate correct assignment collection level, low variable serve  stable metric omega scaling.","code":""},{"path":"https://eriqande.github.io/rubias/reference/avg_coll2correctRU.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the average within-RU assignment rate for each collection — avg_coll2correctRU","text":"average rate correct within-reporting unit assignment proportional reporting-unit-level bias posterior probability collection; correct assignment rate high relative collections, upwardly biased, vice versa. inverse vector used scale Dirichlet draws omega misassignment-scaled MCMC.","code":""},{"path":"https://eriqande.github.io/rubias/reference/avg_coll2correctRU.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the average within-RU assignment rate for each collection — avg_coll2correctRU","text":"","code":"locnames <- names(alewife)[-(1:16)][c(TRUE, FALSE)] ploidies <- rep(2, length(locnames)) names(ploidies) <- locnames  params <- tcf2param_list(alewife, 17, ploidies = ploidies) #> Summary Statistics: #>  #> 1070 Individuals in Sample #>  #> 11 Loci: Aa046, Aa070, Aa074, Aa081, Aa091, Aa093, Ap010, Ap033, Ap038, Ap058, Ap071 #>  #> 3 Reporting Units: NNE, SNE, MAT #>  #> 21 Collections: EMA, STG, PIS, MYS, MON, TBR, GIL, THA, BRI, CON, QUI, HOU, PEQ, MIA, HUD, DEL, NAN, RAP, CHO, ROA, ALL #>  #> 6.31% of allelic data identified as missing SL <- geno_logL(params) %>% exp() %>% apply(2, function(x) x/sum(x)) correct <- avg_coll2correctRU(SL, params$coll, params$RU_starts, params$RU_vec)"},{"path":"https://eriqande.github.io/rubias/reference/blueback.html","id":null,"dir":"Reference","previous_headings":"","what":"Microsat data from blueback herring reference populations — blueback","title":"Microsat data from blueback herring reference populations — blueback","text":"Standard two-column genetic data lots columns preceding . Can fed directly rubias least columns sample_type, collection, repunit indiv.","code":""},{"path":"https://eriqande.github.io/rubias/reference/blueback.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Microsat data from blueback herring reference populations — blueback","text":"tibble.","code":""},{"path":"https://eriqande.github.io/rubias/reference/blueback.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Microsat data from blueback herring reference populations — blueback","text":"https://datadryad.org/dataset/doi:10.5061/dryad.80f4f","code":""},{"path":"https://eriqande.github.io/rubias/reference/bootstrap_rho.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform a parametric bootstrapping correction on an estimated rho vector — bootstrap_rho","title":"Perform a parametric bootstrapping correction on an estimated rho vector — bootstrap_rho","text":"Takes estimate rho, two-column format genetic data frame containing reference mixture data. Returns new rho corrected parametric bootstrapping","code":""},{"path":"https://eriqande.github.io/rubias/reference/bootstrap_rho.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform a parametric bootstrapping correction on an estimated rho vector — bootstrap_rho","text":"","code":"bootstrap_rho(   rho_est,   pi_est,   D,   gen_start_col,   niter = 100,   reps = 2000,   burn_in = 100,   pi_prior = NA,   pi_prior_sum = 1 )"},{"path":"https://eriqande.github.io/rubias/reference/bootstrap_rho.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform a parametric bootstrapping correction on an estimated rho vector — bootstrap_rho","text":"rho_est rho value previously estimated MCMC GSI provided reference mixture data pi_est pi value previously estimated MCMC GSI provided reference mixture data D two-column genetic dataframe containing reference mixture data rho_est computed; \"repunit\", \"collection\", \"indiv\" columns gen_start_col first column genetic data D. columns gen_start_col must genetic data pi_prior prior added collection allocations, order generate pseudo-count Dirichlet parameters simulation new pi vector. Non-default values vector length equal number populations reference dataset. Default value NA leads calculation symmetrical prior based pi_prior_sum. pi_prior_sum total weight default symmetrical prior pi. parametric bootstrapping, niter new mixture datasets simulated individual reference reporting unit proportions rho_est, mean MCMC GSI outputs used calculate average bias. bias subtracted rho_est give output. number individuals simulated bootstrap dataset equal number \"mixture\" individuals D.","code":""},{"path":"https://eriqande.github.io/rubias/reference/bootstrap_rho.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform a parametric bootstrapping correction on an estimated rho vector — bootstrap_rho","text":"bootstrap_rho returns new rho value, corrected parametric bootstrapping.","code":""},{"path":"https://eriqande.github.io/rubias/reference/check_known_collections.html","id":null,"dir":"Reference","previous_headings":"","what":"check a baseline and mixture file together to ensure the known_collections are valid if they exist — check_known_collections","title":"check a baseline and mixture file together to ensure the known_collections are valid if they exist — check_known_collections","text":"Simple function checks known_collections columns reference mixture makes sure compliant. non-NA entry Mixture frame's known_collection column function returns TRUE.  Otherwise returns FALSE.","code":""},{"path":"https://eriqande.github.io/rubias/reference/check_known_collections.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"check a baseline and mixture file together to ensure the known_collections are valid if they exist — check_known_collections","text":"","code":"check_known_collections(R, M)"},{"path":"https://eriqande.github.io/rubias/reference/check_known_collections.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"check a baseline and mixture file together to ensure the known_collections are valid if they exist — check_known_collections","text":"R reference data frame M mixture data frame","code":""},{"path":"https://eriqande.github.io/rubias/reference/check_refmix.html","id":null,"dir":"Reference","previous_headings":"","what":"A helper function to check that the input data frame is OK — check_refmix","title":"A helper function to check that the input data frame is OK — check_refmix","text":"Just checks make sure column types correct.","code":""},{"path":"https://eriqande.github.io/rubias/reference/check_refmix.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A helper function to check that the input data frame is OK — check_refmix","text":"","code":"check_refmix(D, gen_start_col, type = \"reference\")"},{"path":"https://eriqande.github.io/rubias/reference/check_refmix.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A helper function to check that the input data frame is OK — check_refmix","text":"D data frame gen_start_col column genetic data starts type writing errors, supply \"mixture\" \"reference\" appropriate.","code":""},{"path":"https://eriqande.github.io/rubias/reference/check_refmix.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"A helper function to check that the input data frame is OK — check_refmix","text":"also checks patterns missing data, infers whether markers haploid diploid.","code":""},{"path":"https://eriqande.github.io/rubias/reference/chinook.html","id":null,"dir":"Reference","previous_headings":"","what":"SNP data from chinook reference populations — chinook","title":"SNP data from chinook reference populations — chinook","text":"Chinook salmon baseline data similar can downloaded https://datadryad.org/dataset/doi:10.5061/dryad.574sv. data set includes 91 SNPs 7301 fish Dryad data became converted TaqMan SNPtype assays (forced toss loci) tossed bunch lousy historical samples Trinity River.","code":""},{"path":"https://eriqande.github.io/rubias/reference/chinook.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"SNP data from chinook reference populations — chinook","text":"tbl_df-ed (dplyr) data frame 7,301 rows 185 variables. first three columns repunit (chr) reporting unit individual pop (chr) population individual sampled ID (chr) Unique identifier individual fish remaining columns two columns locus.  columns named like, \"Locus.1\" \"Locus.2\" first second gene copies locus.  example, \"Ots_104569-86.1\"  \"Ots_104569-86.2\".  locus columns ints missing data denoted NA.","code":""},{"path":"https://eriqande.github.io/rubias/reference/chinook.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"SNP data from chinook reference populations — chinook","text":"https://datadryad.org/dataset/doi:10.5061/dryad.574sv","code":""},{"path":"https://eriqande.github.io/rubias/reference/chinook_collection_levels.html","id":null,"dir":"Reference","previous_headings":"","what":"a vector that gives a desired sort order of the chinook collections — chinook_collection_levels","title":"a vector that gives a desired sort order of the chinook collections — chinook_collection_levels","text":"just example one use levels order get chinook collections desired sort order analysis.  issue collection input data frame functions must character vector, factor.  , analysis can always make factor use vector like one specify levels.","code":""},{"path":"https://eriqande.github.io/rubias/reference/chinook_collection_levels.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"a vector that gives a desired sort order of the chinook collections — chinook_collection_levels","text":"Made !","code":""},{"path":"https://eriqande.github.io/rubias/reference/chinook_mix.html","id":null,"dir":"Reference","previous_headings":"","what":"SNP data from Chinook salmon taken in May/August 2015 from California fisheries — chinook_mix","title":"SNP data from Chinook salmon taken in May/August 2015 from California fisheries — chinook_mix","text":"data 91 SNP markers (subset 95 markers chinook baseline data set).","code":""},{"path":"https://eriqande.github.io/rubias/reference/chinook_mix.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"SNP data from Chinook salmon taken in May/August 2015 from California fisheries — chinook_mix","text":"tbl_df-ed (dplyr) data frame 2256 rows 193 variables. first four columns meta data. remaining columns two columns locus.  columns named like, \"Locus.1\" \"Locus.2\" first second gene copies locus.  example, \"Ots_104569-86.1\"  \"Ots_104569-86.2\".  locus columns ints missing data denoted NA.","code":""},{"path":"https://eriqande.github.io/rubias/reference/chinook_mix.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"SNP data from Chinook salmon taken in May/August 2015 from California fisheries — chinook_mix","text":"Southwest Fisheries Science Center, Santa Cruz, CA","code":""},{"path":"https://eriqande.github.io/rubias/reference/chinook_repunit_levels.html","id":null,"dir":"Reference","previous_headings":"","what":"a vector that gives a desired sort order of the chinook repunits — chinook_repunit_levels","title":"a vector that gives a desired sort order of the chinook repunits — chinook_repunit_levels","text":"just example one use levels order get chinook repunits desired sort order analysis.  issue repunit input data frame functions must character vector, factor.  , analysis can always make factor use vector like one specify levels.","code":""},{"path":"https://eriqande.github.io/rubias/reference/chinook_repunit_levels.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"a vector that gives a desired sort order of the chinook repunits — chinook_repunit_levels","text":"Made !","code":""},{"path":"https://eriqande.github.io/rubias/reference/close_matching_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"check for matching (or close to matching) genotypes in a data frame — close_matching_samples","title":"check for matching (or close to matching) genotypes in a data frame — close_matching_samples","text":"Super simple function looks pairs fish data frame returns tibble includes shared fraction >= min_frac_non_miss genotypes missing either fish, matching fraction >= min_frac_matching non-missing pairs genotypes.","code":""},{"path":"https://eriqande.github.io/rubias/reference/close_matching_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"check for matching (or close to matching) genotypes in a data frame — close_matching_samples","text":"","code":"close_matching_samples(   D,   gen_start_col,   min_frac_non_miss = 0.7,   min_frac_matching = 0.9 )"},{"path":"https://eriqande.github.io/rubias/reference/close_matching_samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"check for matching (or close to matching) genotypes in a data frame — close_matching_samples","text":"D two-column format genetic dataset, \"repunit\", \"collection\", \"indiv\" columns, well \"sample_type\" column entries either \"reference\" \"reference\" \"mixture.\" gen_start_col first column genetic data reference min_frac_non_miss fraction loci pair must share non missing order reported min_frac_matching fraction shared non-missing loci must shared indivdiuals reported matching pair.","code":""},{"path":"https://eriqande.github.io/rubias/reference/close_matching_samples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"check for matching (or close to matching) genotypes in a data frame — close_matching_samples","text":"tibble ...","code":""},{"path":"https://eriqande.github.io/rubias/reference/close_matching_samples.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"check for matching (or close to matching) genotypes in a data frame — close_matching_samples","text":"","code":"# one pair found in the interal alewife data set: close_matching_samples(alewife, 17) #> Summary Statistics: #>  #> 1070 Individuals in Sample #>  #> 11 Loci: Aa046, Aa070, Aa074, Aa081, Aa091, Aa093, Ap010, Ap033, Ap038, Ap058, Ap071 #>  #> 3 Reporting Units: NNE, SNE, MAT #>  #> 21 Collections: EMA, STG, PIS, MYS, MON, TBR, GIL, THA, BRI, CON, QUI, HOU, PEQ, MIA, HUD, DEL, NAN, RAP, CHO, ROA, ALL #>  #> 6.31% of allelic data identified as missing #> # A tibble: 1 × 10 #>   num_non_miss num_match indiv_1 indiv_2 collection_1 collection_2 sample_type_1 #>          <int>     <int> <chr>   <chr>   <chr>        <chr>        <chr>         #> 1           11        10 AEMME_… ASGME_… EMA          STG          reference     #> # ℹ 3 more variables: repunit_1 <chr>, sample_type_2 <chr>, repunit_2 <chr>"},{"path":"https://eriqande.github.io/rubias/reference/count_missing_data.html","id":null,"dir":"Reference","previous_headings":"","what":"for each individual count the number or loci missing and non_missing — count_missing_data","title":"for each individual count the number or loci missing and non_missing — count_missing_data","text":"Takes rubias genetic data frame must column \"indiv\". Haploids second column locus totally missing.  Diploids missing data gene copies missing.","code":""},{"path":"https://eriqande.github.io/rubias/reference/count_missing_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"for each individual count the number or loci missing and non_missing — count_missing_data","text":"","code":"count_missing_data(D, gen_start_col)"},{"path":"https://eriqande.github.io/rubias/reference/count_missing_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"for each individual count the number or loci missing and non_missing — count_missing_data","text":"D data frame gen_start_col column genetic data starts","code":""},{"path":"https://eriqande.github.io/rubias/reference/count_missing_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"for each individual count the number or loci missing and non_missing — count_missing_data","text":"returns data frame indiv (characters), n_non_miss_loci, n_miss_loci (numeric) missing_loci (list-column named integer vectors)","code":""},{"path":"https://eriqande.github.io/rubias/reference/custom_pi_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a vector of pi Dirichlet priors with specified values for one or more collections — custom_pi_prior","title":"Create a vector of pi Dirichlet priors with specified values for one or more collections — custom_pi_prior","text":"handles case user provides data frame pi_prior. data frame lists desired Dirichlet parameter priors least one reference collection, /default value unspecified collections.","code":""},{"path":"https://eriqande.github.io/rubias/reference/custom_pi_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a vector of pi Dirichlet priors with specified values for one or more collections — custom_pi_prior","text":"","code":"custom_pi_prior(P, C)"},{"path":"https://eriqande.github.io/rubias/reference/custom_pi_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a vector of pi Dirichlet priors with specified values for one or more collections — custom_pi_prior","text":"P data frame one desired pi prior parameters. One column, \"collection\", character vector, valid values including names reference collections, special value \"DEFAULT_PI\". second column, \"pi_param\" prior value used collection. C tibble column \"collection\" collection names","code":""},{"path":"https://eriqande.github.io/rubias/reference/custom_pi_prior.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a vector of pi Dirichlet priors with specified values for one or more collections — custom_pi_prior","text":"Input checking currently done early stages infer_mixture order throw errors long processing times, avoid re-checking bootstrap_rho.","code":""},{"path":"https://eriqande.github.io/rubias/reference/dirch_from_allocations.html","id":null,"dir":"Reference","previous_headings":"","what":"Given a vector of different categories in 1...n and a prior, simulate a Dirichlet random vector — dirch_from_allocations","title":"Given a vector of different categories in 1...n and a prior, simulate a Dirichlet random vector — dirch_from_allocations","text":"Takes vector collection indices individuals (vector elements) assigned, returns Dirichlet random variable generated adding prior sum collection's occurrences, simulating alpha gamma distribution shape parameter.","code":""},{"path":"https://eriqande.github.io/rubias/reference/dirch_from_allocations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Given a vector of different categories in 1...n and a prior, simulate a Dirichlet random vector — dirch_from_allocations","text":"","code":"dirch_from_allocations(C, lambda)"},{"path":"https://eriqande.github.io/rubias/reference/dirch_from_allocations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Given a vector of different categories in 1...n and a prior, simulate a Dirichlet random vector — dirch_from_allocations","text":"C vector giving different categories individual (counts categories - untabulated) lambda priors categories","code":""},{"path":"https://eriqande.github.io/rubias/reference/dirch_from_allocations.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Given a vector of different categories in 1...n and a prior, simulate a Dirichlet random vector — dirch_from_allocations","text":"categories labeled C 1 n.  n length lambda, vector priors. Note elements lambda must strictly greater 0.","code":""},{"path":"https://eriqande.github.io/rubias/reference/dirch_from_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Given a vector of counts for different categories in 1...n and a prior, simulate a Dirichlet random vector — dirch_from_counts","title":"Given a vector of counts for different categories in 1...n and a prior, simulate a Dirichlet random vector — dirch_from_counts","text":"Takes vector counts 1:n collections, returns Dirichlet random variable generated adding prior collection value, simulating alpha gamma distribution shape parameter.","code":""},{"path":"https://eriqande.github.io/rubias/reference/dirch_from_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Given a vector of counts for different categories in 1...n and a prior, simulate a Dirichlet random vector — dirch_from_counts","text":"","code":"dirch_from_counts(C, lambda)"},{"path":"https://eriqande.github.io/rubias/reference/dirch_from_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Given a vector of counts for different categories in 1...n and a prior, simulate a Dirichlet random vector — dirch_from_counts","text":"C vector giving counts categories lambda priors categories","code":""},{"path":"https://eriqande.github.io/rubias/reference/dirch_from_counts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Given a vector of counts for different categories in 1...n and a prior, simulate a Dirichlet random vector — dirch_from_counts","text":"categories labeled C 1 n.  n length lambda, vector priors. Note elements lambda must strictly greater 0.","code":""},{"path":"https://eriqande.github.io/rubias/reference/geno_logL.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a matrix of genotype log-likelihoods for a genetic dataset — geno_logL","title":"Calculate a matrix of genotype log-likelihoods for a genetic dataset — geno_logL","text":"Takes list key parameters genetic dataset, calculates log-likelihood individual's genotype, given allele counts collection","code":""},{"path":"https://eriqande.github.io/rubias/reference/geno_logL.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a matrix of genotype log-likelihoods for a genetic dataset — geno_logL","text":"","code":"geno_logL(par_list)"},{"path":"https://eriqande.github.io/rubias/reference/geno_logL.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a matrix of genotype log-likelihoods for a genetic dataset — geno_logL","text":"par_list genetic data converted param_list format tcf2param_list","code":""},{"path":"https://eriqande.github.io/rubias/reference/geno_logL.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a matrix of genotype log-likelihoods for a genetic dataset — geno_logL","text":"geno_logL returns matrix C rows columns. column represents individual, row log-likelihood individual's genotype, given allele counts collection","code":""},{"path":"https://eriqande.github.io/rubias/reference/geno_logL.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate a matrix of genotype log-likelihoods for a genetic dataset — geno_logL","text":"Leave-One-cross-validation used avoid bias log-likelihood individual's known collection origin","code":""},{"path":"https://eriqande.github.io/rubias/reference/geno_logL.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a matrix of genotype log-likelihoods for a genetic dataset — geno_logL","text":"","code":"example(tcf2param_list) #>  #> tcf2p_> # after adding support for haploid markers we need to pass #> tcf2p_> # in the ploidies vector.  These markers are all diploid... #> tcf2p_> locnames <- names(alewife)[-(1:16)][c(TRUE, FALSE)] #>  #> tcf2p_> ploidies <- rep(2, length(locnames)) #>  #> tcf2p_> names(ploidies) <- locnames #>  #> tcf2p_> ale_par_list <- tcf2param_list(alewife, 17, ploidies = ploidies) #> Summary Statistics: #>  #> 1070 Individuals in Sample #>  #> 11 Loci: Aa046, Aa070, Aa074, Aa081, Aa091, Aa093, Ap010, Ap033, Ap038, Ap058, Ap071 #>  #> 3 Reporting Units: NNE, SNE, MAT #>  #> 21 Collections: EMA, STG, PIS, MYS, MON, TBR, GIL, THA, BRI, CON, QUI, HOU, PEQ, MIA, HUD, DEL, NAN, RAP, CHO, ROA, ALL #>  #> 6.31% of allelic data identified as missing ale_glL <- geno_logL(ale_par_list)"},{"path":"https://eriqande.github.io/rubias/reference/geno_logL_ssq.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate a matrix of sum-of-squares of genotype log-likelihoods for a genetic dataset — geno_logL_ssq","title":"Calculate a matrix of sum-of-squares of genotype log-likelihoods for a genetic dataset — geno_logL_ssq","text":"Takes list key parameters genetic dataset, calculates sum squared log-likelihood individual's genotype, given allele counts collection. used quick--dirty Z-score calculations.","code":""},{"path":"https://eriqande.github.io/rubias/reference/geno_logL_ssq.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate a matrix of sum-of-squares of genotype log-likelihoods for a genetic dataset — geno_logL_ssq","text":"","code":"geno_logL_ssq(par_list)"},{"path":"https://eriqande.github.io/rubias/reference/geno_logL_ssq.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate a matrix of sum-of-squares of genotype log-likelihoods for a genetic dataset — geno_logL_ssq","text":"par_list genetic data converted param_list format tcf2param_list","code":""},{"path":"https://eriqande.github.io/rubias/reference/geno_logL_ssq.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate a matrix of sum-of-squares of genotype log-likelihoods for a genetic dataset — geno_logL_ssq","text":"geno_logL returns matrix C rows columns. column represents individual, row log-likelihood individual's genotype, given allele counts collection","code":""},{"path":"https://eriqande.github.io/rubias/reference/geno_logL_ssq.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate a matrix of sum-of-squares of genotype log-likelihoods for a genetic dataset — geno_logL_ssq","text":"Leave-One-cross-validation used avoid bias log-likelihood individual's known collection origin","code":""},{"path":"https://eriqande.github.io/rubias/reference/geno_logL_ssq.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate a matrix of sum-of-squares of genotype log-likelihoods for a genetic dataset — geno_logL_ssq","text":"","code":"example(tcf2param_list) #>  #> tcf2p_> # after adding support for haploid markers we need to pass #> tcf2p_> # in the ploidies vector.  These markers are all diploid... #> tcf2p_> locnames <- names(alewife)[-(1:16)][c(TRUE, FALSE)] #>  #> tcf2p_> ploidies <- rep(2, length(locnames)) #>  #> tcf2p_> names(ploidies) <- locnames #>  #> tcf2p_> ale_par_list <- tcf2param_list(alewife, 17, ploidies = ploidies) #> Summary Statistics: #>  #> 1070 Individuals in Sample #>  #> 11 Loci: Aa046, Aa070, Aa074, Aa081, Aa091, Aa093, Ap010, Ap033, Ap038, Ap058, Ap071 #>  #> 3 Reporting Units: NNE, SNE, MAT #>  #> 21 Collections: EMA, STG, PIS, MYS, MON, TBR, GIL, THA, BRI, CON, QUI, HOU, PEQ, MIA, HUD, DEL, NAN, RAP, CHO, ROA, ALL #>  #> 6.31% of allelic data identified as missing ale_glL <- geno_logL(ale_par_list)"},{"path":"https://eriqande.github.io/rubias/reference/get_ploidy_from_frame.html","id":null,"dir":"Reference","previous_headings":"","what":"infer the ploidy from the pattern of NAs in the columns of data — get_ploidy_from_frame","title":"infer the ploidy from the pattern of NAs in the columns of data — get_ploidy_from_frame","text":"strictly internal","code":""},{"path":"https://eriqande.github.io/rubias/reference/get_ploidy_from_frame.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"infer the ploidy from the pattern of NAs in the columns of data — get_ploidy_from_frame","text":"","code":"get_ploidy_from_frame(tmp, type)"},{"path":"https://eriqande.github.io/rubias/reference/get_ploidy_from_frame.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"infer the ploidy from the pattern of NAs in the columns of data — get_ploidy_from_frame","text":"tmp data frame 2 * L columns (two locus)","code":""},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_gc.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate genotype log-likelihoods from a population by gene copy — gprob_sim_gc","title":"Simulate genotype log-likelihoods from a population by gene copy — gprob_sim_gc","text":"Takes list parameters genetic dataset, returns genotype log-likelihood matrix individuals simulated gene copy specified collections","code":""},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_gc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate genotype log-likelihoods from a population by gene copy — gprob_sim_gc","text":"","code":"gprob_sim_gc(par_list, sim_colls)"},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_gc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate genotype log-likelihoods from a population by gene copy — gprob_sim_gc","text":"par_list genetic data converted param_list format tcf2param_list sim_colls vector indices collections desired simulation; element list corresponds individual","code":""},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_gc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate genotype log-likelihoods from a population by gene copy — gprob_sim_gc","text":"gprob_sim returns matrix summed log-likelihoods loci simulated population mixture; columns represent individuals, row containing log-likelihood belonging collection index, given selection two independent gene copies desired collection origin's reference allele frequencies","code":""},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_gc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate genotype log-likelihoods from a population by gene copy — gprob_sim_gc","text":"simulation gene copy, genotype locus individual result two random draws allele count matrix locus. Draws within individual performed without replacement, allele counts replaced individuals.","code":""},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_gc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate genotype log-likelihoods from a population by gene copy — gprob_sim_gc","text":"","code":"example(tcf2param_list) #>  #> tcf2p_> # after adding support for haploid markers we need to pass #> tcf2p_> # in the ploidies vector.  These markers are all diploid... #> tcf2p_> locnames <- names(alewife)[-(1:16)][c(TRUE, FALSE)] #>  #> tcf2p_> ploidies <- rep(2, length(locnames)) #>  #> tcf2p_> names(ploidies) <- locnames #>  #> tcf2p_> ale_par_list <- tcf2param_list(alewife, 17, ploidies = ploidies) #> Summary Statistics: #>  #> 1070 Individuals in Sample #>  #> 11 Loci: Aa046, Aa070, Aa074, Aa081, Aa091, Aa093, Ap010, Ap033, Ap038, Ap058, Ap071 #>  #> 3 Reporting Units: NNE, SNE, MAT #>  #> 21 Collections: EMA, STG, PIS, MYS, MON, TBR, GIL, THA, BRI, CON, QUI, HOU, PEQ, MIA, HUD, DEL, NAN, RAP, CHO, ROA, ALL #>  #> 6.31% of allelic data identified as missing sim_colls <- sample(ale_par_list$C, 1070, replace = TRUE) ale_sim_gprobs_gc <- gprob_sim_gc(ale_par_list, sim_colls)"},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_gc_missing.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate genotypes by gene copy, with missing data from chosen individuals — gprob_sim_gc_missing","title":"Simulate genotypes by gene copy, with missing data from chosen individuals — gprob_sim_gc_missing","text":"Takes list parameters genetic dataset, returns genotype log-likelihood matrix individuals simulated gene copy specified collections, genotypes masked missing data patterns reference individuals","code":""},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_gc_missing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate genotypes by gene copy, with missing data from chosen individuals — gprob_sim_gc_missing","text":"","code":"gprob_sim_gc_missing(par_list, sim_colls, sim_missing)"},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_gc_missing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate genotypes by gene copy, with missing data from chosen individuals — gprob_sim_gc_missing","text":"par_list genetic data converted param_list format tcf2param_list sim_colls vector; element specifies collection sample genotypes individual sim_missing vector; element specifies index individual params$whose missing data copied individual ","code":""},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_gc_missing.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate genotypes by gene copy, with missing data from chosen individuals — gprob_sim_gc_missing","text":"simulation gene copy, genotype locus individual result two random draws allele count matrix locus. Draws within individual performed without replacement, allele counts replaced individuals. data particular locus missing individual sim_missing, data also missing simulated individual log-likelihood calculation.","code":""},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_gc_missing.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate genotypes by gene copy, with missing data from chosen individuals — gprob_sim_gc_missing","text":"","code":"# If one wanted to simulate the missing data patterns # of a troublesome mixture dataset, one would run tcf2param_list, # selecting samp_type = \"mixture\", then draw sim_miss from # the mixture individual genotype list  # make a fake mixture data set to demonstrate... drawn <- mixture_draw(alewife, rhos = c(1/3, 1/3, 1/3),N = 100) ref <- drawn$reference mix <- drawn$mix  # then run it... # we have to get the ploidies to pass to tcf2param_list locnames <- names(alewife)[-(1:16)][c(TRUE, FALSE)] ploidies <- rep(2, length(locnames)) names(ploidies) <- locnames params <- tcf2param_list(rbind(ref,mix), 17, samp_type = \"mixture\", ploidies = ploidies) #> Summary Statistics: #>  #> 99 Individuals in Sample #>  #> 11 Loci: Aa046, Aa070, Aa074, Aa081, Aa091, Aa093, Ap010, Ap033, Ap038, Ap058, Ap071 #>  #> 3 Reporting Units: NNE, SNE, MAT #>  #> 21 Collections: EMA, STG, PIS, MYS, MON, TBR, GIL, THA, BRI, CON, QUI, HOU, PEQ, MIA, HUD, DEL, NAN, RAP, CHO, ROA, ALL #>  #> 5.14% of allelic data identified as missing sim_colls <- sample(params$C, 1070, replace = TRUE) sim_miss <- sample(length(params$coll), 1070, replace = TRUE) ale_sim_gprobs_miss <- gprob_sim_gc_missing(params, sim_colls, sim_miss)"},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_ind.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate genotype log-likelihoods from a population by individual — gprob_sim_ind","title":"Simulate genotype log-likelihoods from a population by individual — gprob_sim_ind","text":"Takes list parameters genetic dataset, returns genotype log-likelihood matrix individuals simulated individual specified collections","code":""},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_ind.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate genotype log-likelihoods from a population by individual — gprob_sim_ind","text":"","code":"gprob_sim_ind(par_list, sim_colls)"},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_ind.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate genotype log-likelihoods from a population by individual — gprob_sim_ind","text":"par_list genetic data converted param_list format tcf2param_list sim_colls vector indices collections desired simulation; element list corresponds individual","code":""},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_ind.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate genotype log-likelihoods from a population by individual — gprob_sim_ind","text":"gprob_sim returns matrix summed log-likelihoods loci simulated population mixture; columns represent individuals, row containing log-likelihood belonging collection index, given selection individual's genotype reference collection interest. Selection locus gene copy level independent, missing data included selection.","code":""},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_ind.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulate genotype log-likelihoods from a population by individual — gprob_sim_ind","text":"simulation individual, genotype simulated individual result single random draw genotypes individuals collection. Gene copies loci therefore independent.","code":""},{"path":"https://eriqande.github.io/rubias/reference/gprob_sim_ind.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulate genotype log-likelihoods from a population by individual — gprob_sim_ind","text":"","code":"example(tcf2param_list) #>  #> tcf2p_> # after adding support for haploid markers we need to pass #> tcf2p_> # in the ploidies vector.  These markers are all diploid... #> tcf2p_> locnames <- names(alewife)[-(1:16)][c(TRUE, FALSE)] #>  #> tcf2p_> ploidies <- rep(2, length(locnames)) #>  #> tcf2p_> names(ploidies) <- locnames #>  #> tcf2p_> ale_par_list <- tcf2param_list(alewife, 17, ploidies = ploidies) #> Summary Statistics: #>  #> 1070 Individuals in Sample #>  #> 11 Loci: Aa046, Aa070, Aa074, Aa081, Aa091, Aa093, Ap010, Ap033, Ap038, Ap058, Ap071 #>  #> 3 Reporting Units: NNE, SNE, MAT #>  #> 21 Collections: EMA, STG, PIS, MYS, MON, TBR, GIL, THA, BRI, CON, QUI, HOU, PEQ, MIA, HUD, DEL, NAN, RAP, CHO, ROA, ALL #>  #> 6.31% of allelic data identified as missing sim_colls <- sample(ale_par_list$C, 1070, replace = TRUE) ale_sim_gprobs_ind <- gprob_sim_ind(ale_par_list, sim_colls)"},{"path":"https://eriqande.github.io/rubias/reference/gsi_em_1.html","id":null,"dir":"Reference","previous_headings":"","what":"EM algorithm from the simplest GSI model for pi and the individual posterior probabilities — gsi_em_1","title":"EM algorithm from the simplest GSI model for pi and the individual posterior probabilities — gsi_em_1","text":"Using matrix scaled likelihoods, function EM algorithm climb likelihood surface pi, computes plug-estimate posteriors individuals.  returns output list.","code":""},{"path":"https://eriqande.github.io/rubias/reference/gsi_em_1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"EM algorithm from the simplest GSI model for pi and the individual posterior probabilities — gsi_em_1","text":"","code":"gsi_em_1(SL, Pi_init, max_iterations, tolerance, return_progression)"},{"path":"https://eriqande.github.io/rubias/reference/gsi_em_1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"EM algorithm from the simplest GSI model for pi and the individual posterior probabilities — gsi_em_1","text":"SL matrix scaled likelihoods.  values individual column (going rows values different collections). Pi_init Starting value pi (collection mixture proportion) vector. max_iterations maximum total number reps iterations . tolerance EM-algorithm considered converged sum elements pi absolute value difference previous current estimate less tolerance. return_progression true, pi_trace component output shows value pi visited en route end.","code":""},{"path":"https://eriqande.github.io/rubias/reference/gsi_em_1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"EM algorithm from the simplest GSI model for pi and the individual posterior probabilities — gsi_em_1","text":"gsi_em_1 returns final Maximum-Likelihood estimate pi PofZ, well number iterations needed reach convergence (\"iterations_performed\"), traces pi values change pi iteration","code":""},{"path":"https://eriqande.github.io/rubias/reference/gsi_em_1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"EM algorithm from the simplest GSI model for pi and the individual posterior probabilities — gsi_em_1","text":"","code":"# this is shown with a scaled likelihood matrix from self-assignment # of the reference individuals  # we have to get the ploidies to pass to tcf2param_list locnames <- names(alewife)[-(1:16)][c(TRUE, FALSE)] ploidies <- rep(2, length(locnames)) names(ploidies) <- locnames params <- tcf2param_list(alewife, 17, ploidies = ploidies) #> Summary Statistics: #>  #> 1070 Individuals in Sample #>  #> 11 Loci: Aa046, Aa070, Aa074, Aa081, Aa091, Aa093, Ap010, Ap033, Ap038, Ap058, Ap071 #>  #> 3 Reporting Units: NNE, SNE, MAT #>  #> 21 Collections: EMA, STG, PIS, MYS, MON, TBR, GIL, THA, BRI, CON, QUI, HOU, PEQ, MIA, HUD, DEL, NAN, RAP, CHO, ROA, ALL #>  #> 6.31% of allelic data identified as missing logl <- geno_logL(params) SL <- apply(exp(logl), 2, function(x) x/sum(x)) test_em <- gsi_em_1(SL,                     rep(1/params$C, params$C),                     max_iterations = 10^6,                     tolerance = 10^-7,                     return_progression = TRUE)"},{"path":"https://eriqande.github.io/rubias/reference/gsi_mcmc_1.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC from the simplest GSI model for pi and the individual posterior probabilities — gsi_mcmc_1","title":"MCMC from the simplest GSI model for pi and the individual posterior probabilities — gsi_mcmc_1","text":"Using matrix scaled likelihoods, function samples values pi posteriors individuals.  returns output list.","code":""},{"path":"https://eriqande.github.io/rubias/reference/gsi_mcmc_1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC from the simplest GSI model for pi and the individual posterior probabilities — gsi_mcmc_1","text":"","code":"gsi_mcmc_1(   SL,   Pi_init,   lambda,   reps,   burn_in,   sample_int_Pi,   sample_int_PofZ,   sample_total_catch = 0L,   total_catch_vals = as.integer(c(-1)),   variable_prob_is_catch = 0L,   prob_is_catch_vec = as.numeric(c(-1)) )"},{"path":"https://eriqande.github.io/rubias/reference/gsi_mcmc_1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC from the simplest GSI model for pi and the individual posterior probabilities — gsi_mcmc_1","text":"SL matrix scaled likelihoods.  values individual column (going rows values different populations). Pi_init Starting value pi (collection mixture proportion) vector. lambda prior added collection allocations, order generate pseudo-count Dirichlet parameters simulation new pi vector reps total number reps (sweeps) . burn_in many reps discard beginning mean calculation. still returned traces desired sample_int_Pi number reps samples taken Pi traces.  0 trace samples taken sample_int_PofZ number reps samples taken traces posterior individual's origin. 0 trace samples taken. sample_total_catch integer. Set 1 want sample total-stock specific catch. , set `total_catch_vals` appropriately. total_catch_vals integer vector length reps holds total catch.  vector allow sample posterior total catch. variable_prob_is_catch integer. Set 1 samples different probabilities considered catch.  1, prob_is_catch_vec must provided. prob_is_catch_vec NumericVector probabilities individual sample considered catch.","code":""},{"path":"https://eriqande.github.io/rubias/reference/gsi_mcmc_1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC from the simplest GSI model for pi and the individual posterior probabilities — gsi_mcmc_1","text":"gsi_mcmc_1 returns list three. $mean lists posterior means collection proportions pi individual posterior probabilities assignment PofZ. $sd returns posterior standard deviations values. corresponding sample_int variables 0, $trace contains samples taken Markov chain intervals sample_int_(variable) steps.","code":""},{"path":"https://eriqande.github.io/rubias/reference/gsi_mcmc_1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCMC from the simplest GSI model for pi and the individual posterior probabilities — gsi_mcmc_1","text":"","code":"# this demonstrates it with scaled likelihoods computed from # assignment of the reference samples  # we have to get the ploidies to pass to tcf2param_list locnames <- names(alewife)[-(1:16)][c(TRUE, FALSE)] ploidies <- rep(2, length(locnames)) names(ploidies) <- locnames  params <- tcf2param_list(alewife, 17, ploidies = ploidies) #> Summary Statistics: #>  #> 1070 Individuals in Sample #>  #> 11 Loci: Aa046, Aa070, Aa074, Aa081, Aa091, Aa093, Ap010, Ap033, Ap038, Ap058, Ap071 #>  #> 3 Reporting Units: NNE, SNE, MAT #>  #> 21 Collections: EMA, STG, PIS, MYS, MON, TBR, GIL, THA, BRI, CON, QUI, HOU, PEQ, MIA, HUD, DEL, NAN, RAP, CHO, ROA, ALL #>  #> 6.31% of allelic data identified as missing logl <- geno_logL(params) SL <- apply(exp(logl), 2, function(x) x/sum(x)) lambda <- rep(1/params$C, params$C) mcmc <- gsi_mcmc_1(SL, lambda, lambda, 200, 50, 5, 5)"},{"path":"https://eriqande.github.io/rubias/reference/gsi_mcmc_fb.html","id":null,"dir":"Reference","previous_headings":"","what":"MCMC from the fully Bayesian GSI model for pi and the individual posterior probabilities — gsi_mcmc_fb","title":"MCMC from the fully Bayesian GSI model for pi and the individual posterior probabilities — gsi_mcmc_fb","text":"Given list key parameters genetic dataset, function samples values pi posteriors individuals. MCMC iteration includes recalculation scaled genotype likelihood matrix, baseline allele frequencies updated based previous iteration's allocations. returns output list.","code":""},{"path":"https://eriqande.github.io/rubias/reference/gsi_mcmc_fb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MCMC from the fully Bayesian GSI model for pi and the individual posterior probabilities — gsi_mcmc_fb","text":"","code":"gsi_mcmc_fb(   par_list,   Pi_init,   lambda,   reps,   burn_in,   sample_int_Pi,   sample_int_PofZ,   sample_total_catch = 0L,   total_catch_vals = as.integer(c(-1)),   variable_prob_is_catch = 0L,   prob_is_catch_vec = as.numeric(c(-1)) )"},{"path":"https://eriqande.github.io/rubias/reference/gsi_mcmc_fb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MCMC from the fully Bayesian GSI model for pi and the individual posterior probabilities — gsi_mcmc_fb","text":"par_list genetic data converted param_list format tcf2param_list Pi_init Starting value pi (collection mixture proportion) vector. lambda prior added collection allocations, order generate pseudo-count Dirichlet parameters simulation new pi vector reps total number reps (sweeps) . burn_in many reps discard beginning mean calculation. still returned traces desired sample_int_Pi number reps samples taken Pi traces.  0 trace samples taken sample_int_PofZ number reps samples taken traces posterior individual's origin. 0 trace samples taken.  @param sample_total_catch integer. Set 1 want sample total-stock specific catch. , set `total_catch_vals` appropriately. total_catch_vals integer vector length reps holds total catch.  vector allow sample posterior total catch. variable_prob_is_catch integer. Set 1 samples different probabilities considered catch.  1, prob_is_catch_vec must provided. prob_is_catch_vec NumericVector probabilities individual sample considered catch.","code":""},{"path":"https://eriqande.github.io/rubias/reference/gsi_mcmc_fb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MCMC from the fully Bayesian GSI model for pi and the individual posterior probabilities — gsi_mcmc_fb","text":"gsi_mcmc_fb returns list three. $mean lists posterior means collection proportions pi, individual posterior probabilities assignment PofZ, allele frequencies theta. $sd returns posterior standard deviations values. corresponding sample_int variables 0, $trace contains samples taken Markov chain intervals sample_int_(variable) steps.","code":""},{"path":"https://eriqande.github.io/rubias/reference/gsi_mcmc_fb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MCMC from the fully Bayesian GSI model for pi and the individual posterior probabilities — gsi_mcmc_fb","text":"","code":"# this demonstrates it with scaled likelihoods computed from # assignment of the reference samples  # we have to get the ploidies to pass to tcf2param_list locnames <- names(alewife)[-(1:16)][c(TRUE, FALSE)] ploidies <- rep(2, length(locnames)) names(ploidies) <- locnames  params <- tcf2param_list(alewife, 17, ploidies = ploidies) #> Summary Statistics: #>  #> 1070 Individuals in Sample #>  #> 11 Loci: Aa046, Aa070, Aa074, Aa081, Aa091, Aa093, Ap010, Ap033, Ap038, Ap058, Ap071 #>  #> 3 Reporting Units: NNE, SNE, MAT #>  #> 21 Collections: EMA, STG, PIS, MYS, MON, TBR, GIL, THA, BRI, CON, QUI, HOU, PEQ, MIA, HUD, DEL, NAN, RAP, CHO, ROA, ALL #>  #> 6.31% of allelic data identified as missing lambda <- rep(1/params$C, params$C) # use very short run and burn in so it doesn't take too long # when checking on CRAN mcmc <- gsi_mcmc_fb(params, lambda, lambda, 20, 5, 4, 4)"},{"path":"https://eriqande.github.io/rubias/reference/infer_mixture.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate mixing proportions and origin probabilities from one or several mixtures — infer_mixture","title":"Estimate mixing proportions and origin probabilities from one or several mixtures — infer_mixture","text":"Takes mixture reference dataframe two-column genetic data, desired method estimation population mixture proportions (MCMC, PB, BR). Returns output chosen estimation method","code":""},{"path":"https://eriqande.github.io/rubias/reference/infer_mixture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate mixing proportions and origin probabilities from one or several mixtures — infer_mixture","text":"","code":"infer_mixture(   reference,   mixture,   gen_start_col,   method = \"MCMC\",   alle_freq_prior = list(const_scaled = 1),   pi_prior = NULL,   pi_init = NULL,   reps = 2000,   burn_in = 100,   pb_iter = 100,   prelim_reps = NULL,   prelim_burn_in = NULL,   sample_int_Pi = 1,   sample_theta = TRUE,   pi_prior_sum = 1,   total_catch_tib = NULL,   variable_prob_is_catch = FALSE )"},{"path":"https://eriqande.github.io/rubias/reference/infer_mixture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate mixing proportions and origin probabilities from one or several mixtures — infer_mixture","text":"reference dataframe two-column genetic format data, proceeded \"repunit\", \"collection\", \"indiv\" columns. need \"sample_type\" column, overwritten provided mixture dataframe two-column genetic format data. Must structure reference dataframe, \"collection\" \"repunit\" columns ignored. need \"sample_type\" column, overwritten provided gen_start_col first column genetic data data frames method choice \"MCMC\", \"PB\", \"BR\" methods estimating mixture proportions alle_freq_prior one-element named list specifying prior used generating Dirichlet parameters genotype likelihood calculations. Valid methods include \"const\", \"scaled_const\", \"empirical\". See ?list_diploid_params method details. pi_prior prior added collection allocations, order generate pseudo-count Dirichlet parameters simulation new pi vectors MCMC. Default value NA leads calculation symmetrical prior based pi_prior_sum. provide values certain collections, can pass data frame two columns, \"collection\" listing relevant collection, \"pi_param\" listing desired prior collection. Specific priors may listed one collection. special collection name \"DEFAULT_PI\" used set prior collections explicitly listed; \"DEFAULT_PI\" given, taken 1/(# collections). pi_init initial value use mixing proportion collections.  lets user start chain specific value mixing proportion vector.  pi_init NULL (default) mixing proportions initialized equal.  Otherwise, pass data frame one column named \"collection\" named \"pi_init\".  Every value pi_init column must strictly positive (> 0), value must given every collection.  sum one values normalized sum one. reps number iterations performed MCMC burn_in many reps discard beginning MCMC mean calculation. still returned traces desired. pb_iter many bootstrapped data sets bootstrap correction using method PB.  Default 100. prelim_reps method \"BR\", number reps conditional MCMC (method \"MCMC\") perform prior MCMC baseline resampling. posterior mean mixing proportions conditional MCMC used pi_init baseline resampling MCMC. prelim_burn_in method \"BR\", sets number sweeps prelim_reps discarded burn preparing posterior means mixing proportions set pi_init baseline resampling MCMC. sample_int_Pi many iterations storing mixing proportions trace. Default 1. 0. large fewer 10 samples taken burn sweeps. sample_theta method \"BR\", whether function store posterior mean updated allele frequences. Default TRUE pi_prior_sum pi_prior = NA, prior mixing proportions set Dirichlet vector length C, element W/C, W pi_prior_sum C number collections. default 1.  made much smaller 1, things start mix poorly. total_catch_tib tibble two columns: `collection` `tot_catch`. entries `collection` must correspond different fisheries mixture collections listed `collections` column `mixture`.  `tot_catch` must list column contains estimate total catch fishery.  single number, sample posterior distribution total catch.  Providing value parameter make function return sample posterior stock-specific total catch. Note use option every single mixture collection `mixture` must represented `total_catch_tib`. variable_prob_is_catch logical indicating whether use `catch_is_prob` column simulate fish whether considered part catch.","code":""},{"path":"https://eriqande.github.io/rubias/reference/infer_mixture.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate mixing proportions and origin probabilities from one or several mixtures — infer_mixture","text":"Tidy data frames list following components: mixing_proportions: estimated mixing proportions different collections. indiv_posteriors: posterior probs fish collections. mix_prop_traces: traces mixing proportions.  Useful computing credible intervals. bootstrapped_proportions: using method \"PB\" returns bootstrap corrected reporting unit proportions.  `total_catch_tib` NULL, also found three components output list: `stock_specific_total_catch_traces`, `posterior_predictive_remaining_catch_traces` `allocation_count_traces`.  give samples posterior distribution total catch.  Note `stock_specific_total_catch_traces` sum `posterior_predictive_remaining_catch_traces` `allocation_count_traces`.  three returned can instructive able decompose `stock_specific_total_catch_traces` two constituents.","code":""},{"path":"https://eriqande.github.io/rubias/reference/infer_mixture.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate mixing proportions and origin probabilities from one or several mixtures — infer_mixture","text":"\"MCMC\" estimates mixing proportions individual posterior probabilities assignment Markov-chain Monte Carlo conditional reference allele frequencies, \"PB\" parametric bootstrapping correction, \"BR\" runs MCMC sweeps simulating reference allele frequencies using genotypes mixture individuals allocations previous sweep. methods default uniform 1/(# collections RUs) prior mixing proportions.","code":""},{"path":"https://eriqande.github.io/rubias/reference/infer_mixture.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate mixing proportions and origin probabilities from one or several mixtures — infer_mixture","text":"","code":"mcmc <- infer_mixture(reference = small_chinook_ref,                       mixture = small_chinook_mix,                       gen_start_col = 5,                       method = \"MCMC\",                       reps  = 200) #> Collating data; compiling reference allele frequencies, etc. #>    time: 0.11 seconds #> Computing reference locus specific means and variances for computing mixture z-scores #>    time: 0.01 seconds #> Working on mixture collection: rec3 with 29 individuals #>   calculating log-likelihoods of the mixture individuals. #>    time: 0.00 seconds #>   performing 200 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\" #>    time: 0.00 seconds #>   tidying output into a tibble. #>    time: 0.01 seconds #> Working on mixture collection: rec1 with 36 individuals #>   calculating log-likelihoods of the mixture individuals. #>    time: 0.00 seconds #>   performing 200 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\" #>    time: 0.00 seconds #>   tidying output into a tibble. #>    time: 0.01 seconds #> Working on mixture collection: rec2 with 35 individuals #>   calculating log-likelihoods of the mixture individuals. #>    time: 0.00 seconds #>   performing 200 total sweeps, 100 of which are burn-in and will not be used in computing averages in method \"MCMC\" #>    time: 0.00 seconds #>   tidying output into a tibble. #>    time: 0.01 seconds"},{"path":"https://eriqande.github.io/rubias/reference/list_diploid_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Collect essential data values before mixture proportion estimation — list_diploid_params","title":"Collect essential data values before mixture proportion estimation — list_diploid_params","text":"Takes relevant information created previous steps data conversion pipeline, combines single list serves input calculations","code":""},{"path":"https://eriqande.github.io/rubias/reference/list_diploid_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Collect essential data values before mixture proportion estimation — list_diploid_params","text":"","code":"list_diploid_params(   AC_list,   I_list,   PO,   coll_N,   RU_vec,   RU_starts,   alle_freq_prior = list(const_scaled = 1) )"},{"path":"https://eriqande.github.io/rubias/reference/list_diploid_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Collect essential data values before mixture proportion estimation — list_diploid_params","text":"AC_list list allele count matrices; output a_freq_list I_list list genotype vectors; output allelic_list PO vector collection (population origin) indices every individual sample, order identical I_list coll_N vector total number individuals collection, order appearance dataset RU_vec vector collection indices, sorted reporting unit RU_starts vector indices, designating first collection reporting unit RU_vec alle_freq_prior one-element named list specifying prior used generating Dirichlet parameters genotype likelihood calculations. name list item determines type prior used, options \"const\", \"scaled_const\", \"empirical\". \"const\", listed number taken constant added count allele, locus, collection. \"scaled_const\", listed number divided number alleles locus, added allele counts. \"empirical\", listed number multiplied relative frequency allele across populations, added allele counts.","code":""},{"path":"https://eriqande.github.io/rubias/reference/list_diploid_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Collect essential data values before mixture proportion estimation — list_diploid_params","text":"list_diploid_params returns list information necessary calculation genotype likelihoods MCMC: L, N, C represent number loci, individual genotypes, collections, respectively. vector number alleles locus, CA cumulative sum . coll, coll_N, RU_vec, RU_starts copied directly input. , AC, sum_AC, DP, sum_DP vectorized versions data previously represented lists matrices; indexing macros use L, N, C, , CA access vectors later Rcpp-based calculations.","code":""},{"path":"https://eriqande.github.io/rubias/reference/list_diploid_params.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Collect essential data values before mixture proportion estimation — list_diploid_params","text":"Genotypes represented I_list converted single long vector, ordered locus, individual, gene copy, NA values represented 0s. Similarly, AC_list unlisted AC, ordered locus, collection, allele. DP list Dirichlet priors likelihood calculations, created adding values calculated alle_freq_prior allele sum_AC sum_DP summed allele values locus parent vectors, ordered locus collection.","code":""},{"path":"https://eriqande.github.io/rubias/reference/list_diploid_params.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Collect essential data values before mixture proportion estimation — list_diploid_params","text":"","code":"example(allelic_list) #>  #> alllc_> example(a_freq_list) #>  #> a_frq_>  # Generate a list of individual genotypes by allele from #> a_frq_>  # the alewife data's reference allele count tables #> a_frq_>  example(reference_allele_counts) #>  #> rfrn__> ## count alleles in alewife reference populations #> rfrn__> example(tcf2long)  # gets variable ale_long #>  #> tcf2ln> ## Convert the alewife dataset for further processing #> tcf2ln> # the data frame passed into this function must have had #> tcf2ln> # character collections and repunits converted to factors #> tcf2ln> reference <- alewife #>  #> tcf2ln> reference$repunit <- factor(reference$repunit, levels = unique(reference$repunit)) #>  #> tcf2ln> reference$collection <- factor(reference$collection, levels = unique(reference$collection)) #>  #> tcf2ln> ale_long <- tcf2long(reference, 17) #>  #> rfrn__> ale_rac <- reference_allele_counts(ale_long$long) #>  #> a_frq_>  ale_ac <- a_freq_list(ale_rac) #>  #> alllc_> ale_cs <- ale_long$clean_short #>  #> alllc_> # Get the vectors of gene copies a and b for all loci in integer index form #> alllc_> ale_alle_list <- allelic_list(ale_cs, ale_ac)$int PO <- as.integer(factor(ale_long$clean_short$collection)) coll_N <- as.vector(table(PO))  Colls_by_RU <- dplyr::count(ale_long$clean_short, repunit, collection) %>%    dplyr::filter(n > 0) %>%    dplyr::select(-n)  PC <- rep(0, length(unique((Colls_by_RU$repunit))))  for(i in 1:nrow(Colls_by_RU)) {    PC[Colls_by_RU$repunit[i]] <- PC[Colls_by_RU$repunit[i]] + 1  } RU_starts <- c(0, cumsum(PC)) RU_vec <- as.integer(Colls_by_RU$collection) param_list <- list_diploid_params(ale_ac, ale_alle_list, PO, coll_N, RU_vec, RU_starts)"},{"path":"https://eriqande.github.io/rubias/reference/mixture_draw.html","id":null,"dir":"Reference","previous_headings":"","what":"Separate a chosen proportion of a reference dataset into a mixture with known population proportions — mixture_draw","title":"Separate a chosen proportion of a reference dataset into a mixture with known population proportions — mixture_draw","text":"Takes reference dataset set population proportions, either collection reporting unit level. Randomly samples individuals satisfy desired proportions, splits new \"mixture\" dataframe.","code":""},{"path":"https://eriqande.github.io/rubias/reference/mixture_draw.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Separate a chosen proportion of a reference dataset into a mixture with known population proportions — mixture_draw","text":"","code":"mixture_draw(D, rhos = NULL, omegas = NULL, N, min_remaining = 0)"},{"path":"https://eriqande.github.io/rubias/reference/mixture_draw.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Separate a chosen proportion of a reference dataset into a mixture with known population proportions — mixture_draw","text":"D two-column genetic dataframe \"indiv\", \"repunit\", \"collection\" columns rhos vector desired reporting unit proportions mixture set; named, assumed ordered order appearance dataset omegas desired collection proportions mixture set N total size mixture set min_remaining fraction collection reference dataset must remain end draw","code":""},{"path":"https://eriqande.github.io/rubias/reference/mixture_draw.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Separate a chosen proportion of a reference dataset into a mixture with known population proportions — mixture_draw","text":"mixture_draw returns list two data frames, \"mixture\" random sample taken, \"reference\" remaining samples","code":""},{"path":"https://eriqande.github.io/rubias/reference/mixture_draw.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Separate a chosen proportion of a reference dataset into a mixture with known population proportions — mixture_draw","text":"","code":"rhos <- as.vector(gtools::rdirichlet(1, table(alewife$repunit))) cross_val <- mixture_draw(D = alewife, rhos = rhos, N = 100, min_remaining = .005)"},{"path":"https://eriqande.github.io/rubias/reference/modify_scaled_likelihoods_for_known_mixture_fish.html","id":null,"dir":"Reference","previous_headings":"","what":"for individuals of known origin in the mixture, put all their weight on their known collection — modify_scaled_likelihoods_for_known_mixture_fish","title":"for individuals of known origin in the mixture, put all their weight on their known collection — modify_scaled_likelihoods_for_known_mixture_fish","text":"used internally.","code":""},{"path":"https://eriqande.github.io/rubias/reference/modify_scaled_likelihoods_for_known_mixture_fish.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"for individuals of known origin in the mixture, put all their weight on their known collection — modify_scaled_likelihoods_for_known_mixture_fish","text":"","code":"modify_scaled_likelihoods_for_known_mixture_fish(SL, KC, CFL)"},{"path":"https://eriqande.github.io/rubias/reference/modify_scaled_likelihoods_for_known_mixture_fish.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"for individuals of known origin in the mixture, put all their weight on their known collection — modify_scaled_likelihoods_for_known_mixture_fish","text":"SL matrix scaled likelihoods. KC character vector collections individuals belong (NA know come ).  NULL, SL just gets returned untouched. CFL levels collections factor (within clean$short)","code":""},{"path":"https://eriqande.github.io/rubias/reference/per_locus_means_and_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute the mean and variance of the single-locus genotype likelihoods for each collection — per_locus_means_and_vars","title":"Compute the mean and variance of the single-locus genotype likelihoods for each collection — per_locus_means_and_vars","text":"assumes compiled params reference data set just calls rcpp_per_locus summarizes results.","code":""},{"path":"https://eriqande.github.io/rubias/reference/per_locus_means_and_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute the mean and variance of the single-locus genotype likelihoods for each collection — per_locus_means_and_vars","text":"","code":"per_locus_means_and_vars(par_list)"},{"path":"https://eriqande.github.io/rubias/reference/per_locus_means_and_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute the mean and variance of the single-locus genotype likelihoods for each collection — per_locus_means_and_vars","text":"par_list genetic data converted param_list format tcf2param_list. include genotypes reference individuals.","code":""},{"path":"https://eriqande.github.io/rubias/reference/per_locus_means_and_vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute the mean and variance of the single-locus genotype likelihoods for each collection — per_locus_means_and_vars","text":"Returns list two components, mean var, one matrix C (number collections) rows L (number loci) columns, giving mean (variance) genotype likelihoods individuals collection locus.","code":""},{"path":"https://eriqande.github.io/rubias/reference/perfect_chinook.html","id":null,"dir":"Reference","previous_headings":"","what":"perfect-assignment genetic data for chinook. — perfect_chinook","title":"perfect-assignment genetic data for chinook. — perfect_chinook","text":"just like chinook data, 7 loci loci fixed fortuitous patterns every single collection easily resolved.  primarily useful testing purposes.","code":""},{"path":"https://eriqande.github.io/rubias/reference/perfect_chinook.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"perfect-assignment genetic data for chinook. — perfect_chinook","text":"Made !","code":""},{"path":"https://eriqande.github.io/rubias/reference/perfect_chinook_mix.html","id":null,"dir":"Reference","previous_headings":"","what":"perfect-assignment mixture genetic data for chinook. — perfect_chinook_mix","title":"perfect-assignment mixture genetic data for chinook. — perfect_chinook_mix","text":"similar chinook_mix data, 7 loci loci fixed fortuitous patterns every single collection easily resolved.  primarily useful testing purposes.  name individual collection inside colons.","code":""},{"path":"https://eriqande.github.io/rubias/reference/perfect_chinook_mix.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"perfect-assignment mixture genetic data for chinook. — perfect_chinook_mix","text":"Made !","code":""},{"path":"https://eriqande.github.io/rubias/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"Pipe operator","code":""},{"path":"https://eriqande.github.io/rubias/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://eriqande.github.io/rubias/reference/rcpp_close_matchers.html","id":null,"dir":"Reference","previous_headings":"","what":"Find all pairs that have close matches — rcpp_close_matchers","title":"Find all pairs that have close matches — rcpp_close_matchers","text":"Find pairs close matches","code":""},{"path":"https://eriqande.github.io/rubias/reference/rcpp_close_matchers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find all pairs that have close matches — rcpp_close_matchers","text":"","code":"rcpp_close_matchers(par_list, non_miss_fract, match_fract)"},{"path":"https://eriqande.github.io/rubias/reference/rcpp_close_matchers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find all pairs that have close matches — rcpp_close_matchers","text":"par_list genetic data converted param_list format tcf2param_list","code":""},{"path":"https://eriqande.github.io/rubias/reference/rcpp_close_matchers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find all pairs that have close matches — rcpp_close_matchers","text":"Gotta say ","code":""},{"path":"https://eriqande.github.io/rubias/reference/rcpp_close_matchers.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find all pairs that have close matches — rcpp_close_matchers","text":"","code":"# gotta do something here too"},{"path":"https://eriqande.github.io/rubias/reference/rcpp_indiv_specific_logl_means_and_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"From the pattern of missing data at each individual, compute the expected mean and variance of the logl — rcpp_indiv_specific_logl_means_and_vars","title":"From the pattern of missing data at each individual, compute the expected mean and variance of the logl — rcpp_indiv_specific_logl_means_and_vars","text":"takes param_list access individual genotypes (hence can cycle know missing .)  also takes matrix per-locus logl means variances like computed per_locus_means_and_vars.","code":""},{"path":"https://eriqande.github.io/rubias/reference/rcpp_indiv_specific_logl_means_and_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"From the pattern of missing data at each individual, compute the expected mean and variance of the logl — rcpp_indiv_specific_logl_means_and_vars","text":"","code":"rcpp_indiv_specific_logl_means_and_vars(par_list, MV)"},{"path":"https://eriqande.github.io/rubias/reference/rcpp_indiv_specific_logl_means_and_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"From the pattern of missing data at each individual, compute the expected mean and variance of the logl — rcpp_indiv_specific_logl_means_and_vars","text":"par_list genetic data converted param_list format tcf2param_list MV list two matrices, one means variances, C x L matrices.  basically list returned per_locus_means_and_vars.","code":""},{"path":"https://eriqande.github.io/rubias/reference/rcpp_indiv_specific_logl_means_and_vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"From the pattern of missing data at each individual, compute the expected mean and variance of the logl — rcpp_indiv_specific_logl_means_and_vars","text":"matrix C rows columns. row represents collection, column individual.","code":""},{"path":"https://eriqande.github.io/rubias/reference/rcpp_indiv_specific_logl_means_and_vars.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"From the pattern of missing data at each individual, compute the expected mean and variance of the logl — rcpp_indiv_specific_logl_means_and_vars","text":"function checking assure par_list per-locus logl means matrix made one another.  (.e. use collections order.)","code":""},{"path":"https://eriqande.github.io/rubias/reference/rcpp_per_locus_logls.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a matrix of locus-specific self-assignment logls — rcpp_per_locus_logls","title":"Return a matrix of locus-specific self-assignment logls — rcpp_per_locus_logls","text":"Takes list key parameters genetic dataset, calculates log-likelihood individual's single-locus genotype, given allele counts individual's collection.","code":""},{"path":"https://eriqande.github.io/rubias/reference/rcpp_per_locus_logls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a matrix of locus-specific self-assignment logls — rcpp_per_locus_logls","text":"","code":"rcpp_per_locus_logls(par_list)"},{"path":"https://eriqande.github.io/rubias/reference/rcpp_per_locus_logls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a matrix of locus-specific self-assignment logls — rcpp_per_locus_logls","text":"par_list genetic data converted param_list format tcf2param_list","code":""},{"path":"https://eriqande.github.io/rubias/reference/rcpp_per_locus_logls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a matrix of locus-specific self-assignment logls — rcpp_per_locus_logls","text":"rcpp_per_locus_logls returns matrix rows L columns. row represents individual, column locus. Note missing data locus returns zero.  changed NA later.","code":""},{"path":"https://eriqande.github.io/rubias/reference/rcpp_per_locus_logls.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Return a matrix of locus-specific self-assignment logls — rcpp_per_locus_logls","text":"uses Leave-One-cross-validation used avoid bias log-likelihood individual's known collection origin","code":""},{"path":"https://eriqande.github.io/rubias/reference/read_gsi_sim.html","id":null,"dir":"Reference","previous_headings":"","what":"read a gsi_sim formatted input file into a tibble that rubias can use — read_gsi_sim","title":"read a gsi_sim formatted input file into a tibble that rubias can use — read_gsi_sim","text":"Note relies system call awk.  probably work Windows.","code":""},{"path":"https://eriqande.github.io/rubias/reference/read_gsi_sim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"read a gsi_sim formatted input file into a tibble that rubias can use — read_gsi_sim","text":"","code":"read_gsi_sim(path, sample_type, repunits = NULL)"},{"path":"https://eriqande.github.io/rubias/reference/read_gsi_sim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"read a gsi_sim formatted input file into a tibble that rubias can use — read_gsi_sim","text":"path path gsi_sim file sample_type \"reference\" \"mixture\" depending kind file repunits gsi_sim reporting units file.  effect sample_type \"mixture\".  sample_type \"reference\" left NULL, collections put \"default_repu\".","code":""},{"path":"https://eriqande.github.io/rubias/reference/ref_and_mix_pipeline.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate mixing proportions from reference and mixture datasets — ref_and_mix_pipeline","title":"Estimate mixing proportions from reference and mixture datasets — ref_and_mix_pipeline","text":"Takes mixture reference dataframe two-column genetic data, desired method estimation population mixture proportions (MCMC, PB, BH MCMC) Returns output chosen estimation method","code":""},{"path":"https://eriqande.github.io/rubias/reference/ref_and_mix_pipeline.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate mixing proportions from reference and mixture datasets — ref_and_mix_pipeline","text":"","code":"ref_and_mix_pipeline(   reference,   mixture,   gen_start_col,   method = \"MCMC\",   reps = 2000,   burn_in = 100,   sample_int_Pi = 0,   sample_int_PofZ = 0,   sample_int_omega = 0,   sample_int_rho = 0,   sample_int_PofR = 0 )"},{"path":"https://eriqande.github.io/rubias/reference/ref_and_mix_pipeline.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate mixing proportions from reference and mixture datasets — ref_and_mix_pipeline","text":"reference dataframe two-column genetic format data, proceeded \"repunit\", \"collection\", \"indiv\" columns. need \"sample_type\" column, overwritten provided mixture dataframe two-column genetic format data. Must structure reference dataframe, \"collection\" \"repunit\" columns ignored. need \"sample_type\" column, overwritten provided gen_start_col first column genetic data data frames method must \"MCMC\".   \"PB\" \"BH\" longer supported function. reps number iterations performed MCMC burn_in many reps discard beginning MCMC mean calculation. still returned traces desired. sample_int_Pi number reps samples taken pi traces. 0 traces taken. used methods \"MCMC\" \"PB\". sample_int_PofZ number reps samples taken posterior traces individual's collection origin. 0 trace samples taken. Used methods sample_int_omega number reps samples taken collection proportion traces. 0 traces taken. used method \"BH\" sample_int_rho number reps samples taken reporting unit proportion  traces. 0 traces taken. used method \"BH\" sample_int_PofR number reps samples taken posterior traces individual's reporting unit origin. 0 trace samples taken. used method \"BH\".","code":""},{"path":"https://eriqande.github.io/rubias/reference/ref_and_mix_pipeline.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate mixing proportions from reference and mixture datasets — ref_and_mix_pipeline","text":"mix_proportion_pipeline returns standard output chosen mixing proportion estimation method (always list). method \"PB\", returns standard MCMC results, well bootstrap-corrected collection proportions $mean$bootstrap","code":""},{"path":"https://eriqande.github.io/rubias/reference/ref_and_mix_pipeline.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate mixing proportions from reference and mixture datasets — ref_and_mix_pipeline","text":"\"MCMC\" estimates mixing proportions individual posterior probabilities assignment Markov-chain Monte Carlo, \"PB\" parametric bootstrapping correction, \"BH\" uses misassignment-scaled, hierarchical MCMC. methods use uniform 1/(# collections RUs) prior pi/omega rho.","code":""},{"path":"https://eriqande.github.io/rubias/reference/ref_and_mix_pipeline.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate mixing proportions from reference and mixture datasets — ref_and_mix_pipeline","text":"","code":"reference <- small_chinook_ref mixture <- small_chinook_mix gen_start_col <- 5  # this function expects things as factors.  This function is old and needs # to be replaced and deprecated.  reference$repunit <- factor(reference$repunit, levels = unique(reference$repunit)) reference$collection <- factor(reference$collection, levels = unique(reference$collection)) mixture$repunit <- factor(mixture$repunit, levels = unique(mixture$repunit)) mixture$collection <- factor(mixture$collection, levels = unique(mixture$collection))  mcmc <- ref_and_mix_pipeline(reference, mixture, gen_start_col, method = \"MCMC\")"},{"path":"https://eriqande.github.io/rubias/reference/reference_allele_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Tabulate occurrences of all observed alleles in reference genetic data — reference_allele_counts","title":"Tabulate occurrences of all observed alleles in reference genetic data — reference_allele_counts","text":"Takes first output tcf2long, along two columns named \"collection\" \"sample_type\", returns data frame allele counts locus within reference population. Alleles counted identified reference mixture populations.","code":""},{"path":"https://eriqande.github.io/rubias/reference/reference_allele_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tabulate occurrences of all observed alleles in reference genetic data — reference_allele_counts","text":"","code":"reference_allele_counts(D, pop_level = \"collection\")"},{"path":"https://eriqande.github.io/rubias/reference/reference_allele_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tabulate occurrences of all observed alleles in reference genetic data — reference_allele_counts","text":"D data frame containing, minimum, column sample group identifiers named \"collection\", column designating row \"reference\" \"mixture\", named \"sample_type\", (tcf2long output) locus, gene copy, observed alleles. higher-level reporting unit counts desired, must column reporting unit identifiers named \"repunit\" pop_level character vector expressing population level allele counts tabulated. Set \"collection\" collection/underlying sample group (default), \"repunit\" reporting unit/overlying sample groups","code":""},{"path":"https://eriqande.github.io/rubias/reference/reference_allele_counts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tabulate occurrences of all observed alleles in reference genetic data — reference_allele_counts","text":"reference_allele_counts returns long-format dataframe, count data collection, locus, allele. Counts drawn \"reference\" samples; alleles unique \"mixture\" samples still appear list, 0s groups.","code":""},{"path":"https://eriqande.github.io/rubias/reference/reference_allele_counts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Tabulate occurrences of all observed alleles in reference genetic data — reference_allele_counts","text":"\"collection\" column key assigning samples desired groups, e.g. collection site, run time, year. \"sample_type\" column must contain either \"reference\" \"mixture\" sample.","code":""},{"path":"https://eriqande.github.io/rubias/reference/reference_allele_counts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tabulate occurrences of all observed alleles in reference genetic data — reference_allele_counts","text":"","code":"## count alleles in alewife reference populations example(tcf2long)  # gets variable ale_long #>  #> tcf2ln> ## Convert the alewife dataset for further processing #> tcf2ln> # the data frame passed into this function must have had #> tcf2ln> # character collections and repunits converted to factors #> tcf2ln> reference <- alewife #>  #> tcf2ln> reference$repunit <- factor(reference$repunit, levels = unique(reference$repunit)) #>  #> tcf2ln> reference$collection <- factor(reference$collection, levels = unique(reference$collection)) #>  #> tcf2ln> ale_long <- tcf2long(reference, 17) ale_rac <- reference_allele_counts(ale_long$long)"},{"path":"https://eriqande.github.io/rubias/reference/rmultinom_1.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate a single multinomial vector from within Rcpp — rmultinom_1","title":"Simulate a single multinomial vector from within Rcpp — rmultinom_1","text":": https://gallery.rcpp.org/articles/recreating-rmultinom--rpois--rcpp/","code":""},{"path":"https://eriqande.github.io/rubias/reference/rmultinom_1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate a single multinomial vector from within Rcpp — rmultinom_1","text":"","code":"rmultinom_1(size, probs, N)"},{"path":"https://eriqande.github.io/rubias/reference/rmultinom_1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate a single multinomial vector from within Rcpp — rmultinom_1","text":"size number trials probs cell probabilities N number cells","code":""},{"path":"https://eriqande.github.io/rubias/reference/rmultinom_1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate a single multinomial vector from within Rcpp — rmultinom_1","text":"IntegerVector length N","code":""},{"path":"https://eriqande.github.io/rubias/reference/round2.html","id":null,"dir":"Reference","previous_headings":"","what":"Round a given number, with 5 always rounded up — round2","title":"Round a given number, with 5 always rounded up — round2","text":"Given number digit round , returns rounded number, 5 always rounded upwards.","code":""},{"path":"https://eriqande.github.io/rubias/reference/round2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Round a given number, with 5 always rounded up — round2","text":"","code":"round2(x, n)"},{"path":"https://eriqande.github.io/rubias/reference/round2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Round a given number, with 5 always rounded up — round2","text":"x data rounded n number digits round ","code":""},{"path":"https://eriqande.github.io/rubias/reference/round2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Round a given number, with 5 always rounded up — round2","text":"function differs round, rounds 5 \"towards even number\". Rounding 5s leads bias positive negative numbers expected, can desired cases.","code":""},{"path":"https://eriqande.github.io/rubias/reference/rubias.html","id":null,"dir":"Reference","previous_headings":"","what":"rubias: Bayesian inference from the conditional genetic stock identification model — rubias","title":"rubias: Bayesian inference from the conditional genetic stock identification model — rubias","text":"Read \"rubias-overview\" vignette information data input formats use package","code":""},{"path":"https://eriqande.github.io/rubias/reference/rubias.html","id":"the-rubias-main-high-level-functions","dir":"Reference","previous_headings":"","what":"the rubias main high-level functions","title":"rubias: Bayesian inference from the conditional genetic stock identification model — rubias","text":"following functions wrappers, designed user-friendly input useful output: infer_mixture used perform genetic stock identification. Options include standard MCMC parametric bootstrap bias correction. self_assign simple self-assignment individuals reference data set various collections reference data set. assess_reference_loo leave-one-based simulations predict accurately GSI can done. assess_reference_mc uses Monte-Carlo cross-validation based simulations predict accurately GSI can done. assess_pb_bias_correction attempts demonstrate much (little) improvement can expected parametric bootstrap correction given particular reference data set.","code":""},{"path":"https://eriqande.github.io/rubias/reference/rubias.html","id":"genetic-data-format","dir":"Reference","previous_headings":"","what":"genetic data format","title":"rubias: Bayesian inference from the conditional genetic stock identification model — rubias","text":"See vignette.","code":""},{"path":"https://eriqande.github.io/rubias/reference/rubias.html","id":"example-data","dir":"Reference","previous_headings":"","what":"example data","title":"rubias: Bayesian inference from the conditional genetic stock identification model — rubias","text":"alewife, blueback, chinook genetic data sets useful playing around rubias testing .","code":""},{"path":[]},{"path":"https://eriqande.github.io/rubias/reference/rubias.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"rubias: Bayesian inference from the conditional genetic stock identification model — rubias","text":"Maintainer: Eric C. Anderson eriq@rams.colostate.edu Authors: Ben Moran moran.ben@husky.neu.edu","code":""},{"path":"https://eriqande.github.io/rubias/reference/samp_from_mat.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample 1 observation from cell probabilities that are columns of a matrix — samp_from_mat","title":"Sample 1 observation from cell probabilities that are columns of a matrix — samp_from_mat","text":"Takes matrix columns sum one. column, performs single multinomial draw rows, weighted values column","code":""},{"path":"https://eriqande.github.io/rubias/reference/samp_from_mat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample 1 observation from cell probabilities that are columns of a matrix — samp_from_mat","text":"","code":"samp_from_mat(M)"},{"path":"https://eriqande.github.io/rubias/reference/samp_from_mat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample 1 observation from cell probabilities that are columns of a matrix — samp_from_mat","text":"M matrix whose columns reals summing one","code":""},{"path":"https://eriqande.github.io/rubias/reference/samp_from_mat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample 1 observation from cell probabilities that are columns of a matrix — samp_from_mat","text":"vector length = ncol(M) indices, element row chosen column's sampling","code":""},{"path":"https://eriqande.github.io/rubias/reference/self_assign.html","id":null,"dir":"Reference","previous_headings":"","what":"Do leave-one-out self-assignment of individuals in a reference baseline — self_assign","title":"Do leave-one-out self-assignment of individuals in a reference baseline — self_assign","text":"Returns tidy data frame","code":""},{"path":"https://eriqande.github.io/rubias/reference/self_assign.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Do leave-one-out self-assignment of individuals in a reference baseline — self_assign","text":"","code":"self_assign(   reference,   gen_start_col,   preCompiledParams = NULL,   alle_freq_prior = list(const_scaled = 1) )"},{"path":"https://eriqande.github.io/rubias/reference/self_assign.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Do leave-one-out self-assignment of individuals in a reference baseline — self_assign","text":"reference two-column format genetic dataset, \"repunit\", \"collection\", \"indiv\" columns, well \"sample_type\" column \"reference\" entries gen_start_col first column genetic data reference preCompiledParams Users never use option.  function can called precompiled set parameters infer_mixture.  use , unless one package developers... alle_freq_prior one-element named list specifying prior used generating Dirichlet parameters genotype likelihood calculations. Valid methods include \"const\", \"scaled_const\", \"empirical\". See ?list_diploid_params method details.","code":""},{"path":"https://eriqande.github.io/rubias/reference/self_assign.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Do leave-one-out self-assignment of individuals in a reference baseline — self_assign","text":"tibble ...","code":""},{"path":"https://eriqande.github.io/rubias/reference/self_assign.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Do leave-one-out self-assignment of individuals in a reference baseline — self_assign","text":"","code":"ale_sa <- self_assign(alewife, 17) #> Summary Statistics: #>  #> 1070 Individuals in Sample #>  #> 11 Loci: Aa046, Aa070, Aa074, Aa081, Aa091, Aa093, Ap010, Ap033, Ap038, Ap058, Ap071 #>  #> 3 Reporting Units: NNE, SNE, MAT #>  #> 21 Collections: EMA, STG, PIS, MYS, MON, TBR, GIL, THA, BRI, CON, QUI, HOU, PEQ, MIA, HUD, DEL, NAN, RAP, CHO, ROA, ALL #>  #> 6.31% of allelic data identified as missing"},{"path":"https://eriqande.github.io/rubias/reference/sim_spec_examples.html","id":null,"dir":"Reference","previous_headings":"","what":"List of example ways of specifying repunit and collection quantities in simulations — sim_spec_examples","title":"List of example ways of specifying repunit and collection quantities in simulations — sim_spec_examples","text":"just list tibbles can passed alpha_repunit alpha_collection parameters , example, assess_reference_loo.","code":""},{"path":"https://eriqande.github.io/rubias/reference/sim_spec_examples.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"List of example ways of specifying repunit and collection quantities in simulations — sim_spec_examples","text":"Made !","code":""},{"path":"https://eriqande.github.io/rubias/reference/simulate_random_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a samples for a mixture. — simulate_random_samples","title":"Generate a samples for a mixture. — simulate_random_samples","text":"Creates random reporting unit (rho) collection (omega) proportions, sim_colls vector simulation individual genotypes, based methods used Hasselman et al. (2015)","code":""},{"path":"https://eriqande.github.io/rubias/reference/simulate_random_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a samples for a mixture. — simulate_random_samples","text":"","code":"simulate_random_samples(   RU_starts,   RU_vec,   size = 100,   alpha_repunit = 1.5,   alpha_collection = 1.5,   coll_sub_dirichlet_default = 1.5 )"},{"path":"https://eriqande.github.io/rubias/reference/simulate_random_samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a samples for a mixture. — simulate_random_samples","text":"RU_starts vector delineating reporting units RU_vec; generated tcf2param_list RU_vec vector collection indices, grouped reporting unit; generated tcf2param_list size number individuals desired mixture sample.  Default = 100.  ignored without warning alpha_repunit specified counts (cnt column) alpha_collection specified counts (cnt column). alpha_repunit vector, dirichlet parameter simulating proportions reporting units. Gets recycled number reporting units. Default 1.5. Otherwise, two-column data frame.  first column must named \"repunit\" second one must one \"dirichlet\", \"ppn\", \"cnt\", according whether wish specify dirichlet parameters, proportions, exact counts, respectively, population. alpha_collection dirichlet parameter simulating proportions collections within reporting units. Default = 1.5 coll_sub_dirichlet_default providing data frame requested sub_dirichlet pars collections, specifically list one, value gets.","code":""},{"path":"https://eriqande.github.io/rubias/reference/simulate_random_samples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a samples for a mixture. — simulate_random_samples","text":"list three elements. first two rho vector omega vector, respectively. third vector origins simulated individuals, sampled collections probabilities = omega","code":""},{"path":"https://eriqande.github.io/rubias/reference/small_chinook_mix.html","id":null,"dir":"Reference","previous_headings":"","what":"Small sample of SNP data from Chinook salmon taken in May/August 2015 from California fisheries — small_chinook_mix","title":"Small sample of SNP data from Chinook salmon taken in May/August 2015 from California fisheries — small_chinook_mix","text":"simply sample 100 fish chinook.","code":""},{"path":"https://eriqande.github.io/rubias/reference/small_chinook_mix.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Small sample of SNP data from Chinook salmon taken in May/August 2015 from California fisheries — small_chinook_mix","text":"Southwest Fisheries Science Center, Santa Cruz, CA","code":""},{"path":"https://eriqande.github.io/rubias/reference/small_chinook_ref.html","id":null,"dir":"Reference","previous_headings":"","what":"SNP data from selected chinook reference populations — small_chinook_ref","title":"SNP data from selected chinook reference populations — small_chinook_ref","text":"small number poulations Chinook salmon baseline data similar can downloaded https://datadryad.org/dataset/doi:10.5061/dryad.574sv. data set includes 91 SNPs 909 fish.","code":""},{"path":"https://eriqande.github.io/rubias/reference/small_chinook_ref.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"SNP data from selected chinook reference populations — small_chinook_ref","text":"tbl_df-ed (dplyr) data frame 909 rows 185 variables. first three columns repunit (chr) reporting unit individual pop (chr) population individual sampled ID (chr) Unique identifier individual fish remaining columns two columns locus.  columns named like, \"Locus.1\" \"Locus.2\" first second gene copies locus.  example, \"Ots_104569-86.1\"  \"Ots_104569-86.2\".  locus columns ints missing data denoted NA.","code":""},{"path":"https://eriqande.github.io/rubias/reference/small_chinook_ref.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"SNP data from selected chinook reference populations — small_chinook_ref","text":"https://datadryad.org/dataset/doi:10.5061/dryad.574sv","code":""},{"path":"https://eriqande.github.io/rubias/reference/tabulate_allocations.html","id":null,"dir":"Reference","previous_headings":"","what":"Given a vector of n different categories in 1...n, count up their occurrences and return in a vector of length n — tabulate_allocations","title":"Given a vector of n different categories in 1...n, count up their occurrences and return in a vector of length n — tabulate_allocations","text":"written functions , just getting now sum Zeds fish total catch sampling stuff.  set fish -1 skipped.  lets us use variable_catch_is_prob == TRUE situations.","code":""},{"path":"https://eriqande.github.io/rubias/reference/tabulate_allocations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Given a vector of n different categories in 1...n, count up their occurrences and return in a vector of length n — tabulate_allocations","text":"","code":"tabulate_allocations(C, n)"},{"path":"https://eriqande.github.io/rubias/reference/tabulate_allocations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Given a vector of n different categories in 1...n, count up their occurrences and return in a vector of length n — tabulate_allocations","text":"C vector categories taking values 1,...,n n number categories","code":""},{"path":"https://eriqande.github.io/rubias/reference/tcf2long.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert Two-Column Genetic Data to Long Format — tcf2long","title":"Convert Two-Column Genetic Data to Long Format — tcf2long","text":"Takes data frame consisting metadata followed paired columns genetic data, column pair representing gene copy locus. Returns list two data frames: one genetic data condensed one column, two-column structure intact, cleaned allele names.","code":""},{"path":"https://eriqande.github.io/rubias/reference/tcf2long.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert Two-Column Genetic Data to Long Format — tcf2long","text":"","code":"tcf2long(D, gen_start_col)"},{"path":"https://eriqande.github.io/rubias/reference/tcf2long.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert Two-Column Genetic Data to Long Format — tcf2long","text":"D data frame containing two-column genetic data, optionally preceded metadata. header first genetic data column pair lists locus name, second ignored. Locus names must spaces ! gen_start_col index (number) column genetic data starts. Columns must genetic data genetic data starts.","code":""},{"path":"https://eriqande.github.io/rubias/reference/tcf2long.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert Two-Column Genetic Data to Long Format — tcf2long","text":"tcf2long returns list two data frames: first, \"long\", rightmost column genetic data. Two new columns, \"locus\" \"gene copy\", duplicate original column name provided first pair, designate copies \"\" \"b\", respectively. Metadata duplicated necessary locus. second, \"clean_short\", replicates input dataset, column names replaced \"(locus name) \" \"(locus name) b\" pair. words locus name \"\" \"b\" added space.","code":""},{"path":"https://eriqande.github.io/rubias/reference/tcf2long.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert Two-Column Genetic Data to Long Format — tcf2long","text":"","code":"## Convert the alewife dataset for further processing # the data frame passed into this function must have had # character collections and repunits converted to factors reference <- alewife reference$repunit <- factor(reference$repunit, levels = unique(reference$repunit)) reference$collection <- factor(reference$collection, levels = unique(reference$collection)) ale_long <- tcf2long(reference, 17)"},{"path":"https://eriqande.github.io/rubias/reference/tcf2param_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate MCMC parameter list from two-column genetic data & print summary — tcf2param_list","title":"Generate MCMC parameter list from two-column genetic data & print summary — tcf2param_list","text":"function wrapper steps create parameter list necessary genotype log-likelihood calculation starting two-column genetic data","code":""},{"path":"https://eriqande.github.io/rubias/reference/tcf2param_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate MCMC parameter list from two-column genetic data & print summary — tcf2param_list","text":"","code":"tcf2param_list(   D,   gen_start_col,   samp_type = \"both\",   alle_freq_prior = list(const_scaled = 1),   summ = T,   ploidies )"},{"path":"https://eriqande.github.io/rubias/reference/tcf2param_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate MCMC parameter list from two-column genetic data & print summary — tcf2param_list","text":"D data frame containing two-column genetic data, preceded metadata. header first genetic data column pair lists locus name, second ignored. Locus names must spaces ! Required metadata includes column unique individual identifiers named \"indiv\", column named \"collection\" designating sample groups, column \"repunit\" designating reporting unit origin fish, \"sample_type\" column denoting individual \"reference\" \"mixture\" sample. NAs present metadata gen_start_col index (number) column genetic data starts. Columns must genetic data genetic data starts. samp_type sample groups include individual genotype list, whose likelihoods used MCMC. Options \"reference\", \"mixture\", \"\" alle_freq_prior one-element named list specifying prior used generating Dirichlet parameters genotype likelihood calculations. Valid methods include \"const\", \"scaled_const\", \"empirical\". See ?list_diploid_params method details. summ logical indicating whether summary descriptions formatted data provided ploidies named vector ploidies (1 2) locus.  names must locus names.","code":""},{"path":"https://eriqande.github.io/rubias/reference/tcf2param_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate MCMC parameter list from two-column genetic data & print summary — tcf2param_list","text":"tcf2param_list returns output list_diploid_params, original dataset converted usable format relevant values extracted. See ?list_diploid_params details","code":""},{"path":"https://eriqande.github.io/rubias/reference/tcf2param_list.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generate MCMC parameter list from two-column genetic data & print summary — tcf2param_list","text":"order steps conversion carried successfully, dataset must \"repunit\", \"collection\", \"indiv\", \"sample_type\" columns preceding two-column genetic data. summ == TRUE, function prints summary statistics describing structure dataset, well presence missing data, enabling verification proper data conversion.","code":""},{"path":"https://eriqande.github.io/rubias/reference/tcf2param_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate MCMC parameter list from two-column genetic data & print summary — tcf2param_list","text":"","code":"# after adding support for haploid markers we need to pass # in the ploidies vector.  These markers are all diploid... locnames <- names(alewife)[-(1:16)][c(TRUE, FALSE)] ploidies <- rep(2, length(locnames)) names(ploidies) <- locnames ale_par_list <- tcf2param_list(alewife, 17, ploidies = ploidies) #> Summary Statistics: #>  #> 1070 Individuals in Sample #>  #> 11 Loci: Aa046, Aa070, Aa074, Aa081, Aa091, Aa093, Ap010, Ap033, Ap038, Ap058, Ap071 #>  #> 3 Reporting Units: NNE, SNE, MAT #>  #> 21 Collections: EMA, STG, PIS, MYS, MON, TBR, GIL, THA, BRI, CON, QUI, HOU, PEQ, MIA, HUD, DEL, NAN, RAP, CHO, ROA, ALL #>  #> 6.31% of allelic data identified as missing"},{"path":"https://eriqande.github.io/rubias/reference/tidy_mcmc_coll_rep_stuff.html","id":null,"dir":"Reference","previous_headings":"","what":"A helper function to tidy up the output from the gsi_mcmc functions — tidy_mcmc_coll_rep_stuff","title":"A helper function to tidy up the output from the gsi_mcmc functions — tidy_mcmc_coll_rep_stuff","text":"makes tidy data frame stuff, also changes things back factors, levels provided.","code":""},{"path":"https://eriqande.github.io/rubias/reference/tidy_mcmc_coll_rep_stuff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A helper function to tidy up the output from the gsi_mcmc functions — tidy_mcmc_coll_rep_stuff","text":"","code":"tidy_mcmc_coll_rep_stuff(field, p, pname, car_tib)"},{"path":"https://eriqande.github.io/rubias/reference/tidy_mcmc_coll_rep_stuff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A helper function to tidy up the output from the gsi_mcmc functions — tidy_mcmc_coll_rep_stuff","text":"field output tidy (.e.. $mean) p name parameter whose values want extract (like \"pi\") pname name want parameter called output car_tib tibble repunit collection order appear output","code":""},{"path":"https://eriqande.github.io/rubias/reference/tidy_mcmc_pofz.html","id":null,"dir":"Reference","previous_headings":"","what":"A helper function to tidy up the PofZ-like output from the gsi_mcmc functions — tidy_mcmc_pofz","title":"A helper function to tidy up the PofZ-like output from the gsi_mcmc functions — tidy_mcmc_pofz","text":"makes tidy data frame stuff, also changes things back factors, levels provided.","code":""},{"path":"https://eriqande.github.io/rubias/reference/tidy_mcmc_pofz.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A helper function to tidy up the PofZ-like output from the gsi_mcmc functions — tidy_mcmc_pofz","text":"","code":"tidy_mcmc_pofz(input, pname, car_tib, mix_indiv_tib)"},{"path":"https://eriqande.github.io/rubias/reference/tidy_mcmc_pofz.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A helper function to tidy up the PofZ-like output from the gsi_mcmc functions — tidy_mcmc_pofz","text":"input output tidy (.e.. $mean$PofZ) pname name want parameter called output car_tib tibble repunit collection order appear output mix_indiv_tib tibble individuals order appear output","code":""},{"path":"https://eriqande.github.io/rubias/reference/tidy_pi_traces.html","id":null,"dir":"Reference","previous_headings":"","what":"a helper function to tidy up the pi-traces that come out of the mcmc functions — tidy_pi_traces","title":"a helper function to tidy up the pi-traces that come out of the mcmc functions — tidy_pi_traces","text":"makes tidy data frame stuff, also changes things back factors, levels provided.","code":""},{"path":"https://eriqande.github.io/rubias/reference/tidy_pi_traces.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"a helper function to tidy up the pi-traces that come out of the mcmc functions — tidy_pi_traces","text":"","code":"tidy_pi_traces(input, pname, car_tib, interval)"},{"path":"https://eriqande.github.io/rubias/reference/tidy_pi_traces.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"a helper function to tidy up the pi-traces that come out of the mcmc functions — tidy_pi_traces","text":"input output tidy (.e.. $trace$pi) pname name want parameter called output car_tib tibble repunit collection order appear output interval thinning interval used","code":""},{"path":"https://eriqande.github.io/rubias/reference/turn_non_catch_to_minus_one.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate whether fish are part of the catch or not — turn_non_catch_to_minus_one","title":"Simulate whether fish are part of the catch or not — turn_non_catch_to_minus_one","text":"variable_prob_is_catch == TRUE scenario. simply go vector Z allocations. one, simulate uniform RV.  RV greater corresponding term P, turn Z -1, counted tabulate_allocations().  NC returns number part catch reference.","code":""},{"path":"https://eriqande.github.io/rubias/reference/turn_non_catch_to_minus_one.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate whether fish are part of the catch or not — turn_non_catch_to_minus_one","text":"","code":"turn_non_catch_to_minus_one(Z, P, NC)"},{"path":"https://eriqande.github.io/rubias/reference/turn_non_catch_to_minus_one.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate whether fish are part of the catch or not — turn_non_catch_to_minus_one","text":"Z vector categories taking values 1,...,n P probabilities considered \"catch\" mixure samples NC output reference number fish considered actually catch.","code":""},{"path":"https://eriqande.github.io/rubias/reference/write_gsi_sim_mixture.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a mixture data frame to gsi_sim format baseline and repunits file — write_gsi_sim_mixture","title":"Write a mixture data frame to gsi_sim format baseline and repunits file — write_gsi_sim_mixture","text":"Note, intended work integer-valued alleles, moment. just written testing verifying things working correctly.","code":""},{"path":"https://eriqande.github.io/rubias/reference/write_gsi_sim_mixture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a mixture data frame to gsi_sim format baseline and repunits file — write_gsi_sim_mixture","text":"","code":"write_gsi_sim_mixture(mix, gen_start_col, mixprefix)"},{"path":"https://eriqande.github.io/rubias/reference/write_gsi_sim_mixture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a mixture data frame to gsi_sim format baseline and repunits file — write_gsi_sim_mixture","text":"mix mixture data frame gen_start_col column genetic data start mixprefix path write mixture file .  mixture collection name + .txt appended .  path can include directories exist.  example \"./my_gsi_data/mixture\". required argument.","code":""},{"path":"https://eriqande.github.io/rubias/reference/write_gsi_sim_mixture.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a mixture data frame to gsi_sim format baseline and repunits file — write_gsi_sim_mixture","text":"","code":"# this writes to file prefix \"mixfile\" in a temporary directory dd <- tempdir() prefix <- file.path(dd, \"mixfile\")  # print that prefix #> [1] \"/var/folders/ln/5brnn1wx0vj58fhlbbdjm8h40000gp/T//Rtmpa3IDcs/mixfile\"  # note that in practice you will probably want to specify # your own directory...  # run the function write_gsi_sim_mixture(chinook_mix, 5, prefix)  # see where those files live: dir(dd, pattern = \"mixfile*\", full.names = TRUE) #> [1] \"/var/folders/ln/5brnn1wx0vj58fhlbbdjm8h40000gp/T//Rtmpa3IDcs/mixfile-rec1.txt\" #> [2] \"/var/folders/ln/5brnn1wx0vj58fhlbbdjm8h40000gp/T//Rtmpa3IDcs/mixfile-rec2.txt\" #> [3] \"/var/folders/ln/5brnn1wx0vj58fhlbbdjm8h40000gp/T//Rtmpa3IDcs/mixfile-rec3.txt\""},{"path":"https://eriqande.github.io/rubias/reference/write_gsi_sim_reference.html","id":null,"dir":"Reference","previous_headings":"","what":"Write a reference data frame to gsi_sim format baseline and repunits file — write_gsi_sim_reference","title":"Write a reference data frame to gsi_sim format baseline and repunits file — write_gsi_sim_reference","text":"Note, intended work integer-valued alleles, moment. just written testing verifying things working correctly.","code":""},{"path":"https://eriqande.github.io/rubias/reference/write_gsi_sim_reference.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write a reference data frame to gsi_sim format baseline and repunits file — write_gsi_sim_reference","text":"","code":"write_gsi_sim_reference(   ref,   gen_start_col,   baseout = \"baseline.txt\",   repout = \"repunits.txt\" )"},{"path":"https://eriqande.github.io/rubias/reference/write_gsi_sim_reference.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write a reference data frame to gsi_sim format baseline and repunits file — write_gsi_sim_reference","text":"ref reference data frame gen_start_col column genetic data start baseout path write baseline file . Required. repout path write repunits file . Required.","code":""},{"path":"https://eriqande.github.io/rubias/reference/write_gsi_sim_reference.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write a reference data frame to gsi_sim format baseline and repunits file — write_gsi_sim_reference","text":"","code":"# create a temp directory to put example outputs dd <- tempdir() basefile <- file.path(dd, \"baseline.txt\") repunitsfile <- file.path(dd, \"repunits.txt\")  # print those basefile #> [1] \"/var/folders/ln/5brnn1wx0vj58fhlbbdjm8h40000gp/T//Rtmpa3IDcs/baseline.txt\" repunitsfile #> [1] \"/var/folders/ln/5brnn1wx0vj58fhlbbdjm8h40000gp/T//Rtmpa3IDcs/repunits.txt\"  # note that in practice you will probably want to specify # your own filepaths...  # run the function write_gsi_sim_reference(alewife, 17, basefile, repunitsfile)"},{"path":"https://eriqande.github.io/rubias/news/index.html","id":"rubias-040","dir":"Changelog","previous_headings":"","what":"rubias 0.4.0","title":"rubias 0.4.0","text":"Added functionality simulate posterior predictive distribution better summarize uncertainty stock-specific total catch.","code":""},{"path":"https://eriqande.github.io/rubias/news/index.html","id":"rubias-034","dir":"Changelog","previous_headings":"","what":"rubias 0.3.4","title":"rubias 0.3.4","text":"CRAN release: 2024-01-24 Small patch update deal CRAN check NOTES: removed documented parameter used function removed explicit dependence C++11 Makevars updated CITATION format bibentry","code":""},{"path":"https://eriqande.github.io/rubias/news/index.html","id":"rubias-033","dir":"Changelog","previous_headings":"","what":"rubias 0.3.3","title":"rubias 0.3.3","text":"CRAN release: 2022-02-09","code":""},{"path":"https://eriqande.github.io/rubias/news/index.html","id":"changes-0-3-3","dir":"Changelog","previous_headings":"","what":"Changes","title":"rubias 0.3.3","text":"Overhauled haploid vs diploid ploidy determination deal gracefully mixture samples missing data individuals locus. Using dplyr::slice_sample() instead dplyr::sample_n(), latter superseded former, latter also causing error new sample.int() sanity check.","code":""},{"path":"https://eriqande.github.io/rubias/news/index.html","id":"rubias-032","dir":"Changelog","previous_headings":"","what":"rubias 0.3.2","title":"rubias 0.3.2","text":"CRAN release: 2021-01-15","code":""},{"path":"https://eriqande.github.io/rubias/news/index.html","id":"changes-0-3-2","dir":"Changelog","previous_headings":"","what":"Changes","title":"rubias 0.3.2","text":"Corrected underflow issues self_assign() function many loci. Edited DOI address paper CRAN compliant.","code":""},{"path":"https://eriqande.github.io/rubias/news/index.html","id":"rubias-031","dir":"Changelog","previous_headings":"","what":"rubias 0.3.1","title":"rubias 0.3.1","text":"CRAN release: 2020-04-02","code":""},{"path":"https://eriqande.github.io/rubias/news/index.html","id":"changes-0-3-1","dir":"Changelog","previous_headings":"","what":"Changes","title":"rubias 0.3.1","text":"Tiny tweak one function fix breaking change tibble 3.0.0.","code":""},{"path":"https://eriqande.github.io/rubias/news/index.html","id":"rubias-030","dir":"Changelog","previous_headings":"","what":"rubias 0.3.0","title":"rubias 0.3.0","text":"CRAN release: 2019-06-10","code":""},{"path":"https://eriqande.github.io/rubias/news/index.html","id":"changes-0-3-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"rubias 0.3.0","text":"Added option infer_mixture() fully-Bayesian version. fully Bayesian version, fish within mixture allocated (particular step MCMC) one reference samples alleles added reference sample.","code":""},{"path":"https://eriqande.github.io/rubias/news/index.html","id":"rubias-020","dir":"Changelog","previous_headings":"","what":"rubias 0.2.0","title":"rubias 0.2.0","text":"CRAN release: 2019-02-02","code":""},{"path":"https://eriqande.github.io/rubias/news/index.html","id":"changes-0-2-0","dir":"Changelog","previous_headings":"","what":"Changes","title":"rubias 0.2.0","text":"Added support haploid markers (#14, @krshedd). Added support individuals known origin (.e. identified great accuracy using parentage-based tagging) mixtures (#12). Allow user specify total weight symmetrical Dirichlet prior mixing proportions infer_mixture(). Enforced requirement fish sample_type == “mixture” must NA repunit. things aren’t NA, infer_mixture() throw error method == “PB” extra factor levels floating around. process allow repunit column either character logical setting NA always make logical part data frame non-missing character values . Modified vignette don’t put tidyverse Suggests Added support user specified parameters Dirichlet prior mixing proportions Added support user-specified initial starting values pi parameter (mixing proportions collections) function infer_mixture(). Added simple function, close_matching_samples(), tabulate pairs individuals small number mismatching genotypes. useful identifying accidentally duplicated samples. (#23) Made changes compatible dplyr 0.8.0, longer discards empty factor levels. Mostly involved filtering 0’s group_by() tally() count() calls. looks like things working (passing tests building vignettes right.)","code":""},{"path":"https://eriqande.github.io/rubias/news/index.html","id":"rubias-010","dir":"Changelog","previous_headings":"","what":"rubias 0.1.0","title":"rubias 0.1.0","text":"CRAN release: 2018-01-29 first version submitted CRAN.","code":""}]
